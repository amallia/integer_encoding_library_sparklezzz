/*
 * simd_kscheme_1bit_binary2_unpack.hpp
 *
 *  Created on: 2013-6-9
 *      Author: zxd
 */

#ifndef SIMD_KSCHEME_1BIT_BINARY2_UNPACK_HPP_
#define SIMD_KSCHEME_1BIT_BINARY2_UNPACK_HPP_

#ifdef USE_SSE_INSTRUCTION

#include <stdint.h>

namespace paradise {
namespace index {

struct SIMDK1B2UnpackInfo{
	void (*m_subFunc)(uint32_t *des, const uint32_t *src);
	uint8_t m_totalBitCount;
};

static const struct kscheme_1bit_binary2_val_31{
uint32_t a[4];
}kscheme_1bit_binary2_val_31 __attribute__((aligned(16))) = {{0x1f,0x0,0x0,0x0},};
static const struct kscheme_1bit_binary2_val_32{
uint32_t a[4];
}kscheme_1bit_binary2_val_32 __attribute__((aligned(16))) = {{0x20,0x0,0x0,0x0},};

template<typename T>
void simd_kscheme_1bit_binary2_unpack_prepare() {
	__asm__(
			"pxor %%xmm11,%%xmm11\n"
			"pxor %%xmm12,%%xmm12\n"
			"pxor %%xmm13,%%xmm13\n"
			"movdqa %0,%%xmm14\n"
			"movdqa %1,%%xmm15\n"
			::"m"(kscheme_1bit_binary2_val_31.a[0]),"m"(kscheme_1bit_binary2_val_32.a[0])
			:"memory");
}

template<typename T>
void simd_kscheme_1bit_binary2_unpack_0(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $2,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $3,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_2(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $4,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_3(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $5,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_4(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $6,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_5(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $7,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_6(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $8,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_7(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $9,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_8(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $10,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_9(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_10(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_11(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_12(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_13(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_14(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_15(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_16(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_17(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_18(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_19(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_20(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_21(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_22(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_23(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_24(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_25(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_26(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_27(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $4,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_28(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $3,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_29(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $2,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_30(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $1,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_31(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $31,%%xmm3\n"
			"psrld $31,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_32(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $3,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_33(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $4,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_34(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $5,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_35(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $6,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_36(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $7,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_37(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $8,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_38(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $9,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_39(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $10,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_40(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_41(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_42(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_43(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_44(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_45(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_46(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_47(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_48(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_49(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_50(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_51(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_52(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_53(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_54(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_55(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_56(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_57(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_58(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_59(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $4,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_60(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $3,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_61(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $2,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_62(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $30,%%xmm3\n"
			"psrld $30,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_63(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $30,%%xmm3\n"
			"psrld $30,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_64(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $4,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_65(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $5,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_66(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $6,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_67(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $7,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_68(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $8,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_69(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $9,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_70(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $10,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_71(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_72(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_73(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_74(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_75(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_76(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_77(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_78(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_79(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_80(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_81(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_82(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_83(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_84(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_85(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_86(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_87(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_88(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_89(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_90(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_91(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $4,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_92(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $3,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_93(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $29,%%xmm3\n"
			"psrld $29,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_94(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $29,%%xmm3\n"
			"psrld $29,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_95(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $29,%%xmm3\n"
			"psrld $29,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_96(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $5,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_97(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $6,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_98(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $7,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_99(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $8,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_100(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $9,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_101(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $10,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_102(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_103(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_104(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_105(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_106(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_107(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_108(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_109(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_110(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_111(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_112(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_113(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_114(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_115(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_116(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_117(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_118(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_119(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_120(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_121(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_122(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_123(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $4,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_124(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $28,%%xmm3\n"
			"psrld $28,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_125(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $28,%%xmm3\n"
			"psrld $28,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_126(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $28,%%xmm3\n"
			"psrld $28,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_127(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $28,%%xmm3\n"
			"psrld $28,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_128(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $6,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_129(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $7,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_130(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $8,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_131(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $9,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_132(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $10,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_133(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_134(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_135(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_136(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_137(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_138(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_139(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_140(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_141(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_142(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_143(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_144(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_145(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_146(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_147(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_148(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_149(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_150(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_151(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_152(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_153(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_154(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_155(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_156(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_157(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_158(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_159(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_160(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $7,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_161(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $8,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_162(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $9,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_163(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $10,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_164(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_165(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_166(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_167(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_168(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_169(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_170(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_171(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_172(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_173(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_174(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_175(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_176(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_177(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_178(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_179(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_180(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_181(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_182(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_183(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_184(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_185(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_186(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_187(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_188(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_189(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_190(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_191(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_192(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $8,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_193(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $9,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_194(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $10,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_195(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_196(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_197(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_198(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_199(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_200(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_201(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_202(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_203(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_204(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_205(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_206(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_207(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_208(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_209(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_210(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_211(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_212(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_213(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_214(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_215(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_216(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_217(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_218(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_219(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_220(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_221(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_222(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_223(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_224(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $9,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_225(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $10,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_226(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_227(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_228(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_229(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_230(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_231(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_232(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_233(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_234(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_235(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_236(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_237(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_238(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_239(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_240(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_241(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_242(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_243(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_244(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_245(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_246(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_247(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_248(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_249(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_250(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_251(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_252(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_253(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_254(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_255(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_256(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $10,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_257(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_258(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_259(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_260(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_261(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_262(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_263(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_264(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_265(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_266(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_267(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_268(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_269(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_270(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_271(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_272(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_273(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_274(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_275(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_276(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_277(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_278(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_279(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_280(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_281(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_282(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_283(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_284(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_285(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_286(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_287(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_288(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $11,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_289(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_290(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_291(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_292(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_293(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_294(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_295(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_296(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_297(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_298(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_299(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_300(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_301(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_302(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_303(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_304(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_305(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_306(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_307(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_308(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_309(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_310(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_311(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_312(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_313(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_314(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_315(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_316(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_317(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_318(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_319(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_320(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $12,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_321(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_322(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_323(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_324(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_325(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_326(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_327(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_328(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_329(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_330(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_331(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_332(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_333(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_334(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_335(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_336(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_337(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_338(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_339(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_340(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_341(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_342(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_343(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_344(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_345(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_346(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_347(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_348(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_349(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_350(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_351(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_352(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $13,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_353(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_354(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_355(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_356(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_357(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_358(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_359(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_360(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_361(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_362(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_363(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_364(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_365(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_366(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_367(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_368(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_369(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_370(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_371(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_372(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_373(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_374(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_375(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_376(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_377(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_378(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_379(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_380(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_381(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_382(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_383(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_384(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $14,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_385(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_386(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_387(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_388(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_389(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_390(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_391(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_392(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_393(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_394(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_395(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_396(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_397(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_398(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_399(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_400(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_401(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_402(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_403(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_404(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_405(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_406(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_407(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_408(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_409(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_410(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_411(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_412(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_413(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_414(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_415(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_416(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $15,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_417(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_418(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_419(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_420(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_421(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_422(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_423(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_424(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_425(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_426(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_427(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_428(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_429(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_430(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_431(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_432(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_433(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_434(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_435(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_436(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_437(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_438(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_439(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_440(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_441(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_442(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_443(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_444(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_445(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_446(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_447(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_448(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $16,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_449(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_450(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_451(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_452(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_453(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_454(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_455(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_456(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_457(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_458(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_459(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_460(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_461(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_462(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_463(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_464(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_465(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_466(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_467(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_468(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_469(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_470(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_471(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_472(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_473(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_474(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_475(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_476(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_477(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_478(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_479(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_480(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $17,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_481(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_482(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_483(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_484(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_485(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_486(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_487(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_488(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_489(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_490(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_491(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_492(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_493(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_494(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_495(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"pslld $16,%%xmm2\n"
			"psrld $16,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_496(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_497(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_498(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_499(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_500(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_501(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_502(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_503(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_504(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_505(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_506(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_507(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_508(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_509(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_510(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_511(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_512(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $18,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_513(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_514(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_515(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_516(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_517(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_518(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_519(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_520(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_521(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_522(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_523(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_524(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_525(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_526(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $17,%%xmm2\n"
			"psrld $17,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"pslld $15,%%xmm2\n"
			"psrld $15,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_527(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_528(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_529(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_530(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_531(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_532(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_533(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_534(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_535(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_536(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_537(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_538(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_539(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_540(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_541(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_542(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_543(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_544(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $19,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_545(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_546(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_547(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_548(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_549(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_550(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_551(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_552(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_553(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_554(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_555(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_556(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_557(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $18,%%xmm2\n"
			"psrld $18,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"pslld $14,%%xmm2\n"
			"psrld $14,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_558(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_559(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_560(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_561(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_562(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_563(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_564(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_565(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_566(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_567(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_568(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_569(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_570(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_571(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_572(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_573(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_574(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_575(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_576(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $20,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_577(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_578(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_579(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_580(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_581(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_582(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_583(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_584(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_585(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_586(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_587(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_588(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $19,%%xmm2\n"
			"psrld $19,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"pslld $13,%%xmm2\n"
			"psrld $13,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_589(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_590(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_591(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_592(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_593(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_594(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_595(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_596(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_597(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_598(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_599(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_600(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_601(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_602(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_603(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_604(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_605(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_606(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_607(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_608(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $21,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_609(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_610(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_611(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_612(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_613(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_614(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_615(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_616(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_617(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_618(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_619(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $20,%%xmm2\n"
			"psrld $20,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"pslld $12,%%xmm2\n"
			"psrld $12,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_620(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_621(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_622(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_623(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_624(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_625(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_626(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_627(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_628(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_629(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_630(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_631(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_632(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_633(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_634(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_635(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_636(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_637(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_638(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_639(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_640(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $22,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_641(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_642(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_643(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_644(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_645(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_646(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_647(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_648(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_649(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_650(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $21,%%xmm2\n"
			"psrld $21,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"pslld $11,%%xmm2\n"
			"psrld $11,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_651(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_652(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_653(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_654(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_655(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_656(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_657(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_658(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_659(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_660(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_661(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_662(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_663(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_664(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_665(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_666(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_667(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_668(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_669(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_670(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_671(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_672(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $23,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_673(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_674(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_675(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_676(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_677(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_678(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_679(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_680(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_681(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $22,%%xmm2\n"
			"psrld $22,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"pslld $10,%%xmm2\n"
			"psrld $10,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_682(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_683(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_684(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_685(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_686(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_687(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_688(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_689(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_690(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_691(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_692(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_693(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_694(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_695(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_696(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_697(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_698(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_699(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_700(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_701(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_702(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_703(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_704(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $24,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_705(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_706(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_707(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_708(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_709(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_710(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_711(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_712(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $23,%%xmm2\n"
			"psrld $23,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"pslld $9,%%xmm2\n"
			"psrld $9,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_713(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_714(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_715(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_716(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_717(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_718(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_719(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_720(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_721(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_722(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_723(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_724(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_725(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_726(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_727(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_728(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_729(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_730(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_731(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_732(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_733(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_734(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_735(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_736(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $25,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_737(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_738(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_739(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_740(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_741(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_742(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_743(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $24,%%xmm2\n"
			"psrld $24,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"pslld $8,%%xmm2\n"
			"psrld $8,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_744(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $9,%%xmm3\n"
			"pslld $23,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_745(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_746(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_747(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_748(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_749(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_750(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_751(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_752(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_753(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_754(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_755(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_756(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_757(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_758(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_759(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_760(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_761(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_762(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_763(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_764(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_765(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_766(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_767(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $56,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_768(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $26,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_769(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_770(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_771(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_772(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_773(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_774(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $25,%%xmm2\n"
			"psrld $25,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"pslld $7,%%xmm2\n"
			"psrld $7,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_775(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $8,%%xmm3\n"
			"pslld $24,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_776(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $9,%%xmm3\n"
			"pslld $23,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_777(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_778(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_779(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_780(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_781(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_782(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_783(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_784(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_785(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_786(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_787(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_788(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_789(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_790(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_791(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_792(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_793(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_794(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_795(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_796(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_797(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_798(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $56,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_799(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $57,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_800(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $27,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_801(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_802(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_803(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_804(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_805(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $26,%%xmm2\n"
			"psrld $26,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"pslld $6,%%xmm2\n"
			"psrld $6,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_806(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $7,%%xmm3\n"
			"pslld $25,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_807(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $8,%%xmm3\n"
			"pslld $24,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_808(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $9,%%xmm3\n"
			"pslld $23,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_809(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_810(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_811(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_812(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_813(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_814(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_815(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_816(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_817(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_818(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_819(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_820(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_821(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_822(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_823(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_824(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_825(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_826(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_827(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_828(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_829(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $56,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_830(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $57,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_831(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $58,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_832(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $28,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_833(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_834(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_835(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_836(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $27,%%xmm2\n"
			"psrld $27,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"pslld $5,%%xmm2\n"
			"psrld $5,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_837(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $6,%%xmm3\n"
			"pslld $26,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_838(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $7,%%xmm3\n"
			"pslld $25,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_839(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $8,%%xmm3\n"
			"pslld $24,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_840(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $9,%%xmm3\n"
			"pslld $23,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_841(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_842(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_843(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_844(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_845(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_846(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_847(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_848(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_849(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_850(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_851(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_852(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_853(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_854(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_855(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_856(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_857(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_858(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_859(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_860(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $56,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_861(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $57,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_862(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $58,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_863(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $59,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_864(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $4,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $29,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_865(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $4,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_866(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $4,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_867(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $28,%%xmm2\n"
			"psrld $28,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"pslld $4,%%xmm2\n"
			"psrld $4,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_868(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $5,%%xmm3\n"
			"pslld $27,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_869(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $6,%%xmm3\n"
			"pslld $26,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_870(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $7,%%xmm3\n"
			"pslld $25,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_871(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $8,%%xmm3\n"
			"pslld $24,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_872(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $9,%%xmm3\n"
			"pslld $23,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_873(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_874(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_875(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_876(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_877(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_878(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_879(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_880(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_881(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_882(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_883(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_884(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_885(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_886(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_887(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_888(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_889(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_890(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_891(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $56,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_892(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $57,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_893(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $58,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_894(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $59,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_895(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $60,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_896(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $3,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $30,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_897(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $3,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_898(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $29,%%xmm2\n"
			"psrld $29,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"pslld $3,%%xmm2\n"
			"psrld $3,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_899(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $28,%%xmm3\n"
			"psrld $28,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $4,%%xmm3\n"
			"pslld $28,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_900(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $5,%%xmm3\n"
			"pslld $27,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_901(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $6,%%xmm3\n"
			"pslld $26,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_902(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $7,%%xmm3\n"
			"pslld $25,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_903(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $8,%%xmm3\n"
			"pslld $24,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_904(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $9,%%xmm3\n"
			"pslld $23,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_905(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_906(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_907(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_908(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_909(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_910(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_911(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_912(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_913(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_914(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_915(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_916(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_917(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_918(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_919(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_920(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_921(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_922(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $56,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_923(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $57,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_924(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $58,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_925(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $59,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_926(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $60,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_927(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $61,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_928(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $2,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $31,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_929(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $30,%%xmm2\n"
			"psrld $30,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"pslld $2,%%xmm2\n"
			"psrld $2,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_930(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $29,%%xmm3\n"
			"psrld $29,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $3,%%xmm3\n"
			"pslld $29,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_931(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $28,%%xmm3\n"
			"psrld $28,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $4,%%xmm3\n"
			"pslld $28,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_932(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $5,%%xmm3\n"
			"pslld $27,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_933(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $6,%%xmm3\n"
			"pslld $26,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_934(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $7,%%xmm3\n"
			"pslld $25,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_935(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $8,%%xmm3\n"
			"pslld $24,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_936(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $9,%%xmm3\n"
			"pslld $23,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_937(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_938(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_939(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_940(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_941(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_942(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_943(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_944(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_945(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_946(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_947(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_948(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_949(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_950(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_951(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_952(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_953(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $56,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_954(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $57,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_955(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $58,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_956(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $59,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_957(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $60,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_958(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $61,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_959(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $62,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_960(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqa %%xmm1,%%xmm2\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm2\n"
			"por %%xmm2,%%xmm0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"pslld $31,%%xmm2\n"
			"psrld $31,%%xmm2\n"
			"movdqu %%xmm2,%0\n"
			"movdqa %%xmm0,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"pslld $1,%%xmm2\n"
			"psrld $1,%%xmm2\n"
			"movdqu %%xmm2,%1\n"
			"movl $32,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_961(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $30,%%xmm3\n"
			"psrld $30,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $2,%%xmm3\n"
			"pslld $30,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_962(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $29,%%xmm3\n"
			"psrld $29,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $3,%%xmm3\n"
			"pslld $29,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_963(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $28,%%xmm3\n"
			"psrld $28,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $4,%%xmm3\n"
			"pslld $28,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_964(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $5,%%xmm3\n"
			"pslld $27,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_965(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $6,%%xmm3\n"
			"pslld $26,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_966(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $7,%%xmm3\n"
			"pslld $25,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_967(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $8,%%xmm3\n"
			"pslld $24,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_968(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $9,%%xmm3\n"
			"pslld $23,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_969(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_970(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_971(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_972(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_973(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_974(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_975(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_976(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_977(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_978(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_979(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_980(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_981(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_982(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_983(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_984(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $56,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_985(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $57,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_986(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $58,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_987(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $59,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_988(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $60,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_989(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $61,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_990(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $62,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_991(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $63,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_992(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $31,%%xmm3\n"
			"psrld $31,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $1,%%xmm3\n"
			"pslld $31,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $33,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_993(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $30,%%xmm3\n"
			"psrld $30,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $2,%%xmm3\n"
			"pslld $30,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $34,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_994(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $29,%%xmm3\n"
			"psrld $29,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $3,%%xmm3\n"
			"pslld $29,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $35,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_995(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $28,%%xmm3\n"
			"psrld $28,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $4,%%xmm3\n"
			"pslld $28,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $36,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_996(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $27,%%xmm3\n"
			"psrld $27,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $5,%%xmm3\n"
			"pslld $27,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $37,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_997(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $26,%%xmm3\n"
			"psrld $26,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $6,%%xmm3\n"
			"pslld $26,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $38,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_998(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $25,%%xmm3\n"
			"psrld $25,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $7,%%xmm3\n"
			"pslld $25,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $39,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_999(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $24,%%xmm3\n"
			"psrld $24,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $8,%%xmm3\n"
			"pslld $24,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $40,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1000(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $23,%%xmm3\n"
			"psrld $23,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $9,%%xmm3\n"
			"pslld $23,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $41,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1001(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $22,%%xmm3\n"
			"psrld $22,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $10,%%xmm3\n"
			"pslld $22,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $42,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1002(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $21,%%xmm3\n"
			"psrld $21,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $11,%%xmm3\n"
			"pslld $21,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $43,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1003(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $20,%%xmm3\n"
			"psrld $20,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $12,%%xmm3\n"
			"pslld $20,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $44,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1004(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $19,%%xmm3\n"
			"psrld $19,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $13,%%xmm3\n"
			"pslld $19,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $45,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1005(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $18,%%xmm3\n"
			"psrld $18,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $14,%%xmm3\n"
			"pslld $18,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $46,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1006(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $17,%%xmm3\n"
			"psrld $17,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $15,%%xmm3\n"
			"pslld $17,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $47,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1007(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $16,%%xmm3\n"
			"psrld $16,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $16,%%xmm3\n"
			"pslld $16,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $48,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1008(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $15,%%xmm3\n"
			"psrld $15,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $17,%%xmm3\n"
			"pslld $15,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $49,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1009(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $14,%%xmm3\n"
			"psrld $14,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $18,%%xmm3\n"
			"pslld $14,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $50,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1010(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $13,%%xmm3\n"
			"psrld $13,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $19,%%xmm3\n"
			"pslld $13,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $51,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1011(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $12,%%xmm3\n"
			"psrld $12,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $20,%%xmm3\n"
			"pslld $12,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $52,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1012(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $11,%%xmm3\n"
			"psrld $11,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $21,%%xmm3\n"
			"pslld $11,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $53,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1013(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $10,%%xmm3\n"
			"psrld $10,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $22,%%xmm3\n"
			"pslld $10,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $54,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1014(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $9,%%xmm3\n"
			"psrld $9,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $23,%%xmm3\n"
			"pslld $9,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $55,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1015(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $8,%%xmm3\n"
			"psrld $8,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $24,%%xmm3\n"
			"pslld $8,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $56,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1016(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $7,%%xmm3\n"
			"psrld $7,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $25,%%xmm3\n"
			"pslld $7,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $57,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1017(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $6,%%xmm3\n"
			"psrld $6,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $26,%%xmm3\n"
			"pslld $6,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $58,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1018(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $5,%%xmm3\n"
			"psrld $5,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $27,%%xmm3\n"
			"pslld $5,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $59,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1019(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $4,%%xmm3\n"
			"psrld $4,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $28,%%xmm3\n"
			"pslld $4,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $60,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1020(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $3,%%xmm3\n"
			"psrld $3,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $29,%%xmm3\n"
			"pslld $3,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $61,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1021(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $2,%%xmm3\n"
			"psrld $2,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $30,%%xmm3\n"
			"pslld $2,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $62,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1022(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"pslld $1,%%xmm3\n"
			"psrld $1,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqa %%xmm1,%%xmm4\n"
			"psrld $31,%%xmm3\n"
			"pslld $1,%%xmm4\n"
			"por %%xmm4,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $63,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}
template<typename T>
void simd_kscheme_1bit_binary2_unpack_1023(T* des, const uint32_t* src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqa %%xmm15,%%xmm13\n"
			"psubd %%xmm12,%%xmm13\n"
			"movdqu %2,%%xmm0\n"
			"movdqu %3,%%xmm1\n"
			"movdqu %4,%%xmm2\n"
			"movdqa %%xmm1,%%xmm3\n"
			"psrld %%xmm12,%%xmm0\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm0\n"
			"movdqa %%xmm2,%%xmm3\n"
			"psrld %%xmm12,%%xmm1\n"
			"pslld %%xmm13,%%xmm3\n"
			"por %%xmm3,%%xmm1\n"
			"movdqa %%xmm0,%%xmm3\n"
			"movdqu %%xmm3,%0\n"
			"movdqa %%xmm1,%%xmm3\n"
			"movdqu %%xmm3,%1\n"
			"movl $64,%%eax\n"
			"movd %%eax,%%xmm11\n"
			"paddd %%xmm11,%%xmm12\n"
			"pand %%xmm14,%%xmm12\n"
			:"=m"(des[0]),"=m"(des[4])
			:"m"(src[0]),"m"(src[4]),"m"(src[8])
			:"memory", "eax");
}

static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_0 = { simd_kscheme_1bit_binary2_unpack_0<uint32_t>, 2  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1 = { simd_kscheme_1bit_binary2_unpack_1<uint32_t>, 3  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_2 = { simd_kscheme_1bit_binary2_unpack_2<uint32_t>, 4  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_3 = { simd_kscheme_1bit_binary2_unpack_3<uint32_t>, 5  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_4 = { simd_kscheme_1bit_binary2_unpack_4<uint32_t>, 6  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_5 = { simd_kscheme_1bit_binary2_unpack_5<uint32_t>, 7  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_6 = { simd_kscheme_1bit_binary2_unpack_6<uint32_t>, 8  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_7 = { simd_kscheme_1bit_binary2_unpack_7<uint32_t>, 9  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_8 = { simd_kscheme_1bit_binary2_unpack_8<uint32_t>, 10  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_9 = { simd_kscheme_1bit_binary2_unpack_9<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_10 = { simd_kscheme_1bit_binary2_unpack_10<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_11 = { simd_kscheme_1bit_binary2_unpack_11<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_12 = { simd_kscheme_1bit_binary2_unpack_12<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_13 = { simd_kscheme_1bit_binary2_unpack_13<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_14 = { simd_kscheme_1bit_binary2_unpack_14<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_15 = { simd_kscheme_1bit_binary2_unpack_15<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_16 = { simd_kscheme_1bit_binary2_unpack_16<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_17 = { simd_kscheme_1bit_binary2_unpack_17<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_18 = { simd_kscheme_1bit_binary2_unpack_18<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_19 = { simd_kscheme_1bit_binary2_unpack_19<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_20 = { simd_kscheme_1bit_binary2_unpack_20<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_21 = { simd_kscheme_1bit_binary2_unpack_21<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_22 = { simd_kscheme_1bit_binary2_unpack_22<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_23 = { simd_kscheme_1bit_binary2_unpack_23<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_24 = { simd_kscheme_1bit_binary2_unpack_24<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_25 = { simd_kscheme_1bit_binary2_unpack_25<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_26 = { simd_kscheme_1bit_binary2_unpack_26<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_27 = { simd_kscheme_1bit_binary2_unpack_27<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_28 = { simd_kscheme_1bit_binary2_unpack_28<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_29 = { simd_kscheme_1bit_binary2_unpack_29<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_30 = { simd_kscheme_1bit_binary2_unpack_30<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_31 = { simd_kscheme_1bit_binary2_unpack_31<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_32 = { simd_kscheme_1bit_binary2_unpack_32<uint32_t>, 3  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_33 = { simd_kscheme_1bit_binary2_unpack_33<uint32_t>, 4  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_34 = { simd_kscheme_1bit_binary2_unpack_34<uint32_t>, 5  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_35 = { simd_kscheme_1bit_binary2_unpack_35<uint32_t>, 6  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_36 = { simd_kscheme_1bit_binary2_unpack_36<uint32_t>, 7  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_37 = { simd_kscheme_1bit_binary2_unpack_37<uint32_t>, 8  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_38 = { simd_kscheme_1bit_binary2_unpack_38<uint32_t>, 9  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_39 = { simd_kscheme_1bit_binary2_unpack_39<uint32_t>, 10  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_40 = { simd_kscheme_1bit_binary2_unpack_40<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_41 = { simd_kscheme_1bit_binary2_unpack_41<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_42 = { simd_kscheme_1bit_binary2_unpack_42<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_43 = { simd_kscheme_1bit_binary2_unpack_43<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_44 = { simd_kscheme_1bit_binary2_unpack_44<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_45 = { simd_kscheme_1bit_binary2_unpack_45<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_46 = { simd_kscheme_1bit_binary2_unpack_46<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_47 = { simd_kscheme_1bit_binary2_unpack_47<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_48 = { simd_kscheme_1bit_binary2_unpack_48<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_49 = { simd_kscheme_1bit_binary2_unpack_49<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_50 = { simd_kscheme_1bit_binary2_unpack_50<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_51 = { simd_kscheme_1bit_binary2_unpack_51<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_52 = { simd_kscheme_1bit_binary2_unpack_52<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_53 = { simd_kscheme_1bit_binary2_unpack_53<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_54 = { simd_kscheme_1bit_binary2_unpack_54<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_55 = { simd_kscheme_1bit_binary2_unpack_55<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_56 = { simd_kscheme_1bit_binary2_unpack_56<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_57 = { simd_kscheme_1bit_binary2_unpack_57<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_58 = { simd_kscheme_1bit_binary2_unpack_58<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_59 = { simd_kscheme_1bit_binary2_unpack_59<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_60 = { simd_kscheme_1bit_binary2_unpack_60<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_61 = { simd_kscheme_1bit_binary2_unpack_61<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_62 = { simd_kscheme_1bit_binary2_unpack_62<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_63 = { simd_kscheme_1bit_binary2_unpack_63<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_64 = { simd_kscheme_1bit_binary2_unpack_64<uint32_t>, 4  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_65 = { simd_kscheme_1bit_binary2_unpack_65<uint32_t>, 5  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_66 = { simd_kscheme_1bit_binary2_unpack_66<uint32_t>, 6  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_67 = { simd_kscheme_1bit_binary2_unpack_67<uint32_t>, 7  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_68 = { simd_kscheme_1bit_binary2_unpack_68<uint32_t>, 8  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_69 = { simd_kscheme_1bit_binary2_unpack_69<uint32_t>, 9  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_70 = { simd_kscheme_1bit_binary2_unpack_70<uint32_t>, 10  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_71 = { simd_kscheme_1bit_binary2_unpack_71<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_72 = { simd_kscheme_1bit_binary2_unpack_72<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_73 = { simd_kscheme_1bit_binary2_unpack_73<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_74 = { simd_kscheme_1bit_binary2_unpack_74<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_75 = { simd_kscheme_1bit_binary2_unpack_75<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_76 = { simd_kscheme_1bit_binary2_unpack_76<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_77 = { simd_kscheme_1bit_binary2_unpack_77<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_78 = { simd_kscheme_1bit_binary2_unpack_78<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_79 = { simd_kscheme_1bit_binary2_unpack_79<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_80 = { simd_kscheme_1bit_binary2_unpack_80<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_81 = { simd_kscheme_1bit_binary2_unpack_81<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_82 = { simd_kscheme_1bit_binary2_unpack_82<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_83 = { simd_kscheme_1bit_binary2_unpack_83<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_84 = { simd_kscheme_1bit_binary2_unpack_84<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_85 = { simd_kscheme_1bit_binary2_unpack_85<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_86 = { simd_kscheme_1bit_binary2_unpack_86<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_87 = { simd_kscheme_1bit_binary2_unpack_87<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_88 = { simd_kscheme_1bit_binary2_unpack_88<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_89 = { simd_kscheme_1bit_binary2_unpack_89<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_90 = { simd_kscheme_1bit_binary2_unpack_90<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_91 = { simd_kscheme_1bit_binary2_unpack_91<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_92 = { simd_kscheme_1bit_binary2_unpack_92<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_93 = { simd_kscheme_1bit_binary2_unpack_93<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_94 = { simd_kscheme_1bit_binary2_unpack_94<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_95 = { simd_kscheme_1bit_binary2_unpack_95<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_96 = { simd_kscheme_1bit_binary2_unpack_96<uint32_t>, 5  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_97 = { simd_kscheme_1bit_binary2_unpack_97<uint32_t>, 6  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_98 = { simd_kscheme_1bit_binary2_unpack_98<uint32_t>, 7  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_99 = { simd_kscheme_1bit_binary2_unpack_99<uint32_t>, 8  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_100 = { simd_kscheme_1bit_binary2_unpack_100<uint32_t>, 9  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_101 = { simd_kscheme_1bit_binary2_unpack_101<uint32_t>, 10  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_102 = { simd_kscheme_1bit_binary2_unpack_102<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_103 = { simd_kscheme_1bit_binary2_unpack_103<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_104 = { simd_kscheme_1bit_binary2_unpack_104<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_105 = { simd_kscheme_1bit_binary2_unpack_105<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_106 = { simd_kscheme_1bit_binary2_unpack_106<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_107 = { simd_kscheme_1bit_binary2_unpack_107<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_108 = { simd_kscheme_1bit_binary2_unpack_108<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_109 = { simd_kscheme_1bit_binary2_unpack_109<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_110 = { simd_kscheme_1bit_binary2_unpack_110<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_111 = { simd_kscheme_1bit_binary2_unpack_111<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_112 = { simd_kscheme_1bit_binary2_unpack_112<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_113 = { simd_kscheme_1bit_binary2_unpack_113<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_114 = { simd_kscheme_1bit_binary2_unpack_114<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_115 = { simd_kscheme_1bit_binary2_unpack_115<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_116 = { simd_kscheme_1bit_binary2_unpack_116<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_117 = { simd_kscheme_1bit_binary2_unpack_117<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_118 = { simd_kscheme_1bit_binary2_unpack_118<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_119 = { simd_kscheme_1bit_binary2_unpack_119<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_120 = { simd_kscheme_1bit_binary2_unpack_120<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_121 = { simd_kscheme_1bit_binary2_unpack_121<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_122 = { simd_kscheme_1bit_binary2_unpack_122<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_123 = { simd_kscheme_1bit_binary2_unpack_123<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_124 = { simd_kscheme_1bit_binary2_unpack_124<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_125 = { simd_kscheme_1bit_binary2_unpack_125<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_126 = { simd_kscheme_1bit_binary2_unpack_126<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_127 = { simd_kscheme_1bit_binary2_unpack_127<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_128 = { simd_kscheme_1bit_binary2_unpack_128<uint32_t>, 6  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_129 = { simd_kscheme_1bit_binary2_unpack_129<uint32_t>, 7  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_130 = { simd_kscheme_1bit_binary2_unpack_130<uint32_t>, 8  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_131 = { simd_kscheme_1bit_binary2_unpack_131<uint32_t>, 9  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_132 = { simd_kscheme_1bit_binary2_unpack_132<uint32_t>, 10  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_133 = { simd_kscheme_1bit_binary2_unpack_133<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_134 = { simd_kscheme_1bit_binary2_unpack_134<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_135 = { simd_kscheme_1bit_binary2_unpack_135<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_136 = { simd_kscheme_1bit_binary2_unpack_136<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_137 = { simd_kscheme_1bit_binary2_unpack_137<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_138 = { simd_kscheme_1bit_binary2_unpack_138<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_139 = { simd_kscheme_1bit_binary2_unpack_139<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_140 = { simd_kscheme_1bit_binary2_unpack_140<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_141 = { simd_kscheme_1bit_binary2_unpack_141<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_142 = { simd_kscheme_1bit_binary2_unpack_142<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_143 = { simd_kscheme_1bit_binary2_unpack_143<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_144 = { simd_kscheme_1bit_binary2_unpack_144<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_145 = { simd_kscheme_1bit_binary2_unpack_145<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_146 = { simd_kscheme_1bit_binary2_unpack_146<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_147 = { simd_kscheme_1bit_binary2_unpack_147<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_148 = { simd_kscheme_1bit_binary2_unpack_148<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_149 = { simd_kscheme_1bit_binary2_unpack_149<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_150 = { simd_kscheme_1bit_binary2_unpack_150<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_151 = { simd_kscheme_1bit_binary2_unpack_151<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_152 = { simd_kscheme_1bit_binary2_unpack_152<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_153 = { simd_kscheme_1bit_binary2_unpack_153<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_154 = { simd_kscheme_1bit_binary2_unpack_154<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_155 = { simd_kscheme_1bit_binary2_unpack_155<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_156 = { simd_kscheme_1bit_binary2_unpack_156<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_157 = { simd_kscheme_1bit_binary2_unpack_157<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_158 = { simd_kscheme_1bit_binary2_unpack_158<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_159 = { simd_kscheme_1bit_binary2_unpack_159<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_160 = { simd_kscheme_1bit_binary2_unpack_160<uint32_t>, 7  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_161 = { simd_kscheme_1bit_binary2_unpack_161<uint32_t>, 8  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_162 = { simd_kscheme_1bit_binary2_unpack_162<uint32_t>, 9  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_163 = { simd_kscheme_1bit_binary2_unpack_163<uint32_t>, 10  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_164 = { simd_kscheme_1bit_binary2_unpack_164<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_165 = { simd_kscheme_1bit_binary2_unpack_165<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_166 = { simd_kscheme_1bit_binary2_unpack_166<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_167 = { simd_kscheme_1bit_binary2_unpack_167<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_168 = { simd_kscheme_1bit_binary2_unpack_168<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_169 = { simd_kscheme_1bit_binary2_unpack_169<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_170 = { simd_kscheme_1bit_binary2_unpack_170<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_171 = { simd_kscheme_1bit_binary2_unpack_171<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_172 = { simd_kscheme_1bit_binary2_unpack_172<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_173 = { simd_kscheme_1bit_binary2_unpack_173<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_174 = { simd_kscheme_1bit_binary2_unpack_174<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_175 = { simd_kscheme_1bit_binary2_unpack_175<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_176 = { simd_kscheme_1bit_binary2_unpack_176<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_177 = { simd_kscheme_1bit_binary2_unpack_177<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_178 = { simd_kscheme_1bit_binary2_unpack_178<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_179 = { simd_kscheme_1bit_binary2_unpack_179<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_180 = { simd_kscheme_1bit_binary2_unpack_180<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_181 = { simd_kscheme_1bit_binary2_unpack_181<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_182 = { simd_kscheme_1bit_binary2_unpack_182<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_183 = { simd_kscheme_1bit_binary2_unpack_183<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_184 = { simd_kscheme_1bit_binary2_unpack_184<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_185 = { simd_kscheme_1bit_binary2_unpack_185<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_186 = { simd_kscheme_1bit_binary2_unpack_186<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_187 = { simd_kscheme_1bit_binary2_unpack_187<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_188 = { simd_kscheme_1bit_binary2_unpack_188<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_189 = { simd_kscheme_1bit_binary2_unpack_189<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_190 = { simd_kscheme_1bit_binary2_unpack_190<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_191 = { simd_kscheme_1bit_binary2_unpack_191<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_192 = { simd_kscheme_1bit_binary2_unpack_192<uint32_t>, 8  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_193 = { simd_kscheme_1bit_binary2_unpack_193<uint32_t>, 9  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_194 = { simd_kscheme_1bit_binary2_unpack_194<uint32_t>, 10  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_195 = { simd_kscheme_1bit_binary2_unpack_195<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_196 = { simd_kscheme_1bit_binary2_unpack_196<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_197 = { simd_kscheme_1bit_binary2_unpack_197<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_198 = { simd_kscheme_1bit_binary2_unpack_198<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_199 = { simd_kscheme_1bit_binary2_unpack_199<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_200 = { simd_kscheme_1bit_binary2_unpack_200<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_201 = { simd_kscheme_1bit_binary2_unpack_201<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_202 = { simd_kscheme_1bit_binary2_unpack_202<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_203 = { simd_kscheme_1bit_binary2_unpack_203<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_204 = { simd_kscheme_1bit_binary2_unpack_204<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_205 = { simd_kscheme_1bit_binary2_unpack_205<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_206 = { simd_kscheme_1bit_binary2_unpack_206<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_207 = { simd_kscheme_1bit_binary2_unpack_207<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_208 = { simd_kscheme_1bit_binary2_unpack_208<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_209 = { simd_kscheme_1bit_binary2_unpack_209<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_210 = { simd_kscheme_1bit_binary2_unpack_210<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_211 = { simd_kscheme_1bit_binary2_unpack_211<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_212 = { simd_kscheme_1bit_binary2_unpack_212<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_213 = { simd_kscheme_1bit_binary2_unpack_213<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_214 = { simd_kscheme_1bit_binary2_unpack_214<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_215 = { simd_kscheme_1bit_binary2_unpack_215<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_216 = { simd_kscheme_1bit_binary2_unpack_216<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_217 = { simd_kscheme_1bit_binary2_unpack_217<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_218 = { simd_kscheme_1bit_binary2_unpack_218<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_219 = { simd_kscheme_1bit_binary2_unpack_219<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_220 = { simd_kscheme_1bit_binary2_unpack_220<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_221 = { simd_kscheme_1bit_binary2_unpack_221<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_222 = { simd_kscheme_1bit_binary2_unpack_222<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_223 = { simd_kscheme_1bit_binary2_unpack_223<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_224 = { simd_kscheme_1bit_binary2_unpack_224<uint32_t>, 9  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_225 = { simd_kscheme_1bit_binary2_unpack_225<uint32_t>, 10  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_226 = { simd_kscheme_1bit_binary2_unpack_226<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_227 = { simd_kscheme_1bit_binary2_unpack_227<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_228 = { simd_kscheme_1bit_binary2_unpack_228<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_229 = { simd_kscheme_1bit_binary2_unpack_229<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_230 = { simd_kscheme_1bit_binary2_unpack_230<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_231 = { simd_kscheme_1bit_binary2_unpack_231<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_232 = { simd_kscheme_1bit_binary2_unpack_232<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_233 = { simd_kscheme_1bit_binary2_unpack_233<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_234 = { simd_kscheme_1bit_binary2_unpack_234<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_235 = { simd_kscheme_1bit_binary2_unpack_235<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_236 = { simd_kscheme_1bit_binary2_unpack_236<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_237 = { simd_kscheme_1bit_binary2_unpack_237<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_238 = { simd_kscheme_1bit_binary2_unpack_238<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_239 = { simd_kscheme_1bit_binary2_unpack_239<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_240 = { simd_kscheme_1bit_binary2_unpack_240<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_241 = { simd_kscheme_1bit_binary2_unpack_241<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_242 = { simd_kscheme_1bit_binary2_unpack_242<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_243 = { simd_kscheme_1bit_binary2_unpack_243<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_244 = { simd_kscheme_1bit_binary2_unpack_244<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_245 = { simd_kscheme_1bit_binary2_unpack_245<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_246 = { simd_kscheme_1bit_binary2_unpack_246<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_247 = { simd_kscheme_1bit_binary2_unpack_247<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_248 = { simd_kscheme_1bit_binary2_unpack_248<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_249 = { simd_kscheme_1bit_binary2_unpack_249<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_250 = { simd_kscheme_1bit_binary2_unpack_250<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_251 = { simd_kscheme_1bit_binary2_unpack_251<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_252 = { simd_kscheme_1bit_binary2_unpack_252<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_253 = { simd_kscheme_1bit_binary2_unpack_253<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_254 = { simd_kscheme_1bit_binary2_unpack_254<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_255 = { simd_kscheme_1bit_binary2_unpack_255<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_256 = { simd_kscheme_1bit_binary2_unpack_256<uint32_t>, 10  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_257 = { simd_kscheme_1bit_binary2_unpack_257<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_258 = { simd_kscheme_1bit_binary2_unpack_258<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_259 = { simd_kscheme_1bit_binary2_unpack_259<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_260 = { simd_kscheme_1bit_binary2_unpack_260<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_261 = { simd_kscheme_1bit_binary2_unpack_261<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_262 = { simd_kscheme_1bit_binary2_unpack_262<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_263 = { simd_kscheme_1bit_binary2_unpack_263<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_264 = { simd_kscheme_1bit_binary2_unpack_264<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_265 = { simd_kscheme_1bit_binary2_unpack_265<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_266 = { simd_kscheme_1bit_binary2_unpack_266<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_267 = { simd_kscheme_1bit_binary2_unpack_267<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_268 = { simd_kscheme_1bit_binary2_unpack_268<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_269 = { simd_kscheme_1bit_binary2_unpack_269<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_270 = { simd_kscheme_1bit_binary2_unpack_270<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_271 = { simd_kscheme_1bit_binary2_unpack_271<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_272 = { simd_kscheme_1bit_binary2_unpack_272<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_273 = { simd_kscheme_1bit_binary2_unpack_273<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_274 = { simd_kscheme_1bit_binary2_unpack_274<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_275 = { simd_kscheme_1bit_binary2_unpack_275<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_276 = { simd_kscheme_1bit_binary2_unpack_276<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_277 = { simd_kscheme_1bit_binary2_unpack_277<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_278 = { simd_kscheme_1bit_binary2_unpack_278<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_279 = { simd_kscheme_1bit_binary2_unpack_279<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_280 = { simd_kscheme_1bit_binary2_unpack_280<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_281 = { simd_kscheme_1bit_binary2_unpack_281<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_282 = { simd_kscheme_1bit_binary2_unpack_282<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_283 = { simd_kscheme_1bit_binary2_unpack_283<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_284 = { simd_kscheme_1bit_binary2_unpack_284<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_285 = { simd_kscheme_1bit_binary2_unpack_285<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_286 = { simd_kscheme_1bit_binary2_unpack_286<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_287 = { simd_kscheme_1bit_binary2_unpack_287<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_288 = { simd_kscheme_1bit_binary2_unpack_288<uint32_t>, 11  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_289 = { simd_kscheme_1bit_binary2_unpack_289<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_290 = { simd_kscheme_1bit_binary2_unpack_290<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_291 = { simd_kscheme_1bit_binary2_unpack_291<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_292 = { simd_kscheme_1bit_binary2_unpack_292<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_293 = { simd_kscheme_1bit_binary2_unpack_293<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_294 = { simd_kscheme_1bit_binary2_unpack_294<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_295 = { simd_kscheme_1bit_binary2_unpack_295<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_296 = { simd_kscheme_1bit_binary2_unpack_296<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_297 = { simd_kscheme_1bit_binary2_unpack_297<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_298 = { simd_kscheme_1bit_binary2_unpack_298<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_299 = { simd_kscheme_1bit_binary2_unpack_299<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_300 = { simd_kscheme_1bit_binary2_unpack_300<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_301 = { simd_kscheme_1bit_binary2_unpack_301<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_302 = { simd_kscheme_1bit_binary2_unpack_302<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_303 = { simd_kscheme_1bit_binary2_unpack_303<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_304 = { simd_kscheme_1bit_binary2_unpack_304<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_305 = { simd_kscheme_1bit_binary2_unpack_305<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_306 = { simd_kscheme_1bit_binary2_unpack_306<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_307 = { simd_kscheme_1bit_binary2_unpack_307<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_308 = { simd_kscheme_1bit_binary2_unpack_308<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_309 = { simd_kscheme_1bit_binary2_unpack_309<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_310 = { simd_kscheme_1bit_binary2_unpack_310<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_311 = { simd_kscheme_1bit_binary2_unpack_311<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_312 = { simd_kscheme_1bit_binary2_unpack_312<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_313 = { simd_kscheme_1bit_binary2_unpack_313<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_314 = { simd_kscheme_1bit_binary2_unpack_314<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_315 = { simd_kscheme_1bit_binary2_unpack_315<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_316 = { simd_kscheme_1bit_binary2_unpack_316<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_317 = { simd_kscheme_1bit_binary2_unpack_317<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_318 = { simd_kscheme_1bit_binary2_unpack_318<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_319 = { simd_kscheme_1bit_binary2_unpack_319<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_320 = { simd_kscheme_1bit_binary2_unpack_320<uint32_t>, 12  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_321 = { simd_kscheme_1bit_binary2_unpack_321<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_322 = { simd_kscheme_1bit_binary2_unpack_322<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_323 = { simd_kscheme_1bit_binary2_unpack_323<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_324 = { simd_kscheme_1bit_binary2_unpack_324<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_325 = { simd_kscheme_1bit_binary2_unpack_325<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_326 = { simd_kscheme_1bit_binary2_unpack_326<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_327 = { simd_kscheme_1bit_binary2_unpack_327<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_328 = { simd_kscheme_1bit_binary2_unpack_328<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_329 = { simd_kscheme_1bit_binary2_unpack_329<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_330 = { simd_kscheme_1bit_binary2_unpack_330<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_331 = { simd_kscheme_1bit_binary2_unpack_331<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_332 = { simd_kscheme_1bit_binary2_unpack_332<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_333 = { simd_kscheme_1bit_binary2_unpack_333<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_334 = { simd_kscheme_1bit_binary2_unpack_334<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_335 = { simd_kscheme_1bit_binary2_unpack_335<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_336 = { simd_kscheme_1bit_binary2_unpack_336<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_337 = { simd_kscheme_1bit_binary2_unpack_337<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_338 = { simd_kscheme_1bit_binary2_unpack_338<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_339 = { simd_kscheme_1bit_binary2_unpack_339<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_340 = { simd_kscheme_1bit_binary2_unpack_340<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_341 = { simd_kscheme_1bit_binary2_unpack_341<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_342 = { simd_kscheme_1bit_binary2_unpack_342<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_343 = { simd_kscheme_1bit_binary2_unpack_343<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_344 = { simd_kscheme_1bit_binary2_unpack_344<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_345 = { simd_kscheme_1bit_binary2_unpack_345<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_346 = { simd_kscheme_1bit_binary2_unpack_346<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_347 = { simd_kscheme_1bit_binary2_unpack_347<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_348 = { simd_kscheme_1bit_binary2_unpack_348<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_349 = { simd_kscheme_1bit_binary2_unpack_349<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_350 = { simd_kscheme_1bit_binary2_unpack_350<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_351 = { simd_kscheme_1bit_binary2_unpack_351<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_352 = { simd_kscheme_1bit_binary2_unpack_352<uint32_t>, 13  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_353 = { simd_kscheme_1bit_binary2_unpack_353<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_354 = { simd_kscheme_1bit_binary2_unpack_354<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_355 = { simd_kscheme_1bit_binary2_unpack_355<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_356 = { simd_kscheme_1bit_binary2_unpack_356<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_357 = { simd_kscheme_1bit_binary2_unpack_357<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_358 = { simd_kscheme_1bit_binary2_unpack_358<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_359 = { simd_kscheme_1bit_binary2_unpack_359<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_360 = { simd_kscheme_1bit_binary2_unpack_360<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_361 = { simd_kscheme_1bit_binary2_unpack_361<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_362 = { simd_kscheme_1bit_binary2_unpack_362<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_363 = { simd_kscheme_1bit_binary2_unpack_363<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_364 = { simd_kscheme_1bit_binary2_unpack_364<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_365 = { simd_kscheme_1bit_binary2_unpack_365<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_366 = { simd_kscheme_1bit_binary2_unpack_366<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_367 = { simd_kscheme_1bit_binary2_unpack_367<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_368 = { simd_kscheme_1bit_binary2_unpack_368<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_369 = { simd_kscheme_1bit_binary2_unpack_369<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_370 = { simd_kscheme_1bit_binary2_unpack_370<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_371 = { simd_kscheme_1bit_binary2_unpack_371<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_372 = { simd_kscheme_1bit_binary2_unpack_372<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_373 = { simd_kscheme_1bit_binary2_unpack_373<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_374 = { simd_kscheme_1bit_binary2_unpack_374<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_375 = { simd_kscheme_1bit_binary2_unpack_375<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_376 = { simd_kscheme_1bit_binary2_unpack_376<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_377 = { simd_kscheme_1bit_binary2_unpack_377<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_378 = { simd_kscheme_1bit_binary2_unpack_378<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_379 = { simd_kscheme_1bit_binary2_unpack_379<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_380 = { simd_kscheme_1bit_binary2_unpack_380<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_381 = { simd_kscheme_1bit_binary2_unpack_381<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_382 = { simd_kscheme_1bit_binary2_unpack_382<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_383 = { simd_kscheme_1bit_binary2_unpack_383<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_384 = { simd_kscheme_1bit_binary2_unpack_384<uint32_t>, 14  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_385 = { simd_kscheme_1bit_binary2_unpack_385<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_386 = { simd_kscheme_1bit_binary2_unpack_386<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_387 = { simd_kscheme_1bit_binary2_unpack_387<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_388 = { simd_kscheme_1bit_binary2_unpack_388<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_389 = { simd_kscheme_1bit_binary2_unpack_389<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_390 = { simd_kscheme_1bit_binary2_unpack_390<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_391 = { simd_kscheme_1bit_binary2_unpack_391<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_392 = { simd_kscheme_1bit_binary2_unpack_392<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_393 = { simd_kscheme_1bit_binary2_unpack_393<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_394 = { simd_kscheme_1bit_binary2_unpack_394<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_395 = { simd_kscheme_1bit_binary2_unpack_395<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_396 = { simd_kscheme_1bit_binary2_unpack_396<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_397 = { simd_kscheme_1bit_binary2_unpack_397<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_398 = { simd_kscheme_1bit_binary2_unpack_398<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_399 = { simd_kscheme_1bit_binary2_unpack_399<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_400 = { simd_kscheme_1bit_binary2_unpack_400<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_401 = { simd_kscheme_1bit_binary2_unpack_401<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_402 = { simd_kscheme_1bit_binary2_unpack_402<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_403 = { simd_kscheme_1bit_binary2_unpack_403<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_404 = { simd_kscheme_1bit_binary2_unpack_404<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_405 = { simd_kscheme_1bit_binary2_unpack_405<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_406 = { simd_kscheme_1bit_binary2_unpack_406<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_407 = { simd_kscheme_1bit_binary2_unpack_407<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_408 = { simd_kscheme_1bit_binary2_unpack_408<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_409 = { simd_kscheme_1bit_binary2_unpack_409<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_410 = { simd_kscheme_1bit_binary2_unpack_410<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_411 = { simd_kscheme_1bit_binary2_unpack_411<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_412 = { simd_kscheme_1bit_binary2_unpack_412<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_413 = { simd_kscheme_1bit_binary2_unpack_413<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_414 = { simd_kscheme_1bit_binary2_unpack_414<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_415 = { simd_kscheme_1bit_binary2_unpack_415<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_416 = { simd_kscheme_1bit_binary2_unpack_416<uint32_t>, 15  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_417 = { simd_kscheme_1bit_binary2_unpack_417<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_418 = { simd_kscheme_1bit_binary2_unpack_418<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_419 = { simd_kscheme_1bit_binary2_unpack_419<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_420 = { simd_kscheme_1bit_binary2_unpack_420<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_421 = { simd_kscheme_1bit_binary2_unpack_421<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_422 = { simd_kscheme_1bit_binary2_unpack_422<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_423 = { simd_kscheme_1bit_binary2_unpack_423<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_424 = { simd_kscheme_1bit_binary2_unpack_424<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_425 = { simd_kscheme_1bit_binary2_unpack_425<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_426 = { simd_kscheme_1bit_binary2_unpack_426<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_427 = { simd_kscheme_1bit_binary2_unpack_427<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_428 = { simd_kscheme_1bit_binary2_unpack_428<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_429 = { simd_kscheme_1bit_binary2_unpack_429<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_430 = { simd_kscheme_1bit_binary2_unpack_430<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_431 = { simd_kscheme_1bit_binary2_unpack_431<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_432 = { simd_kscheme_1bit_binary2_unpack_432<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_433 = { simd_kscheme_1bit_binary2_unpack_433<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_434 = { simd_kscheme_1bit_binary2_unpack_434<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_435 = { simd_kscheme_1bit_binary2_unpack_435<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_436 = { simd_kscheme_1bit_binary2_unpack_436<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_437 = { simd_kscheme_1bit_binary2_unpack_437<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_438 = { simd_kscheme_1bit_binary2_unpack_438<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_439 = { simd_kscheme_1bit_binary2_unpack_439<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_440 = { simd_kscheme_1bit_binary2_unpack_440<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_441 = { simd_kscheme_1bit_binary2_unpack_441<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_442 = { simd_kscheme_1bit_binary2_unpack_442<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_443 = { simd_kscheme_1bit_binary2_unpack_443<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_444 = { simd_kscheme_1bit_binary2_unpack_444<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_445 = { simd_kscheme_1bit_binary2_unpack_445<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_446 = { simd_kscheme_1bit_binary2_unpack_446<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_447 = { simd_kscheme_1bit_binary2_unpack_447<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_448 = { simd_kscheme_1bit_binary2_unpack_448<uint32_t>, 16  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_449 = { simd_kscheme_1bit_binary2_unpack_449<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_450 = { simd_kscheme_1bit_binary2_unpack_450<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_451 = { simd_kscheme_1bit_binary2_unpack_451<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_452 = { simd_kscheme_1bit_binary2_unpack_452<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_453 = { simd_kscheme_1bit_binary2_unpack_453<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_454 = { simd_kscheme_1bit_binary2_unpack_454<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_455 = { simd_kscheme_1bit_binary2_unpack_455<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_456 = { simd_kscheme_1bit_binary2_unpack_456<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_457 = { simd_kscheme_1bit_binary2_unpack_457<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_458 = { simd_kscheme_1bit_binary2_unpack_458<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_459 = { simd_kscheme_1bit_binary2_unpack_459<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_460 = { simd_kscheme_1bit_binary2_unpack_460<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_461 = { simd_kscheme_1bit_binary2_unpack_461<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_462 = { simd_kscheme_1bit_binary2_unpack_462<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_463 = { simd_kscheme_1bit_binary2_unpack_463<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_464 = { simd_kscheme_1bit_binary2_unpack_464<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_465 = { simd_kscheme_1bit_binary2_unpack_465<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_466 = { simd_kscheme_1bit_binary2_unpack_466<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_467 = { simd_kscheme_1bit_binary2_unpack_467<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_468 = { simd_kscheme_1bit_binary2_unpack_468<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_469 = { simd_kscheme_1bit_binary2_unpack_469<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_470 = { simd_kscheme_1bit_binary2_unpack_470<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_471 = { simd_kscheme_1bit_binary2_unpack_471<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_472 = { simd_kscheme_1bit_binary2_unpack_472<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_473 = { simd_kscheme_1bit_binary2_unpack_473<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_474 = { simd_kscheme_1bit_binary2_unpack_474<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_475 = { simd_kscheme_1bit_binary2_unpack_475<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_476 = { simd_kscheme_1bit_binary2_unpack_476<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_477 = { simd_kscheme_1bit_binary2_unpack_477<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_478 = { simd_kscheme_1bit_binary2_unpack_478<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_479 = { simd_kscheme_1bit_binary2_unpack_479<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_480 = { simd_kscheme_1bit_binary2_unpack_480<uint32_t>, 17  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_481 = { simd_kscheme_1bit_binary2_unpack_481<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_482 = { simd_kscheme_1bit_binary2_unpack_482<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_483 = { simd_kscheme_1bit_binary2_unpack_483<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_484 = { simd_kscheme_1bit_binary2_unpack_484<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_485 = { simd_kscheme_1bit_binary2_unpack_485<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_486 = { simd_kscheme_1bit_binary2_unpack_486<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_487 = { simd_kscheme_1bit_binary2_unpack_487<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_488 = { simd_kscheme_1bit_binary2_unpack_488<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_489 = { simd_kscheme_1bit_binary2_unpack_489<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_490 = { simd_kscheme_1bit_binary2_unpack_490<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_491 = { simd_kscheme_1bit_binary2_unpack_491<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_492 = { simd_kscheme_1bit_binary2_unpack_492<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_493 = { simd_kscheme_1bit_binary2_unpack_493<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_494 = { simd_kscheme_1bit_binary2_unpack_494<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_495 = { simd_kscheme_1bit_binary2_unpack_495<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_496 = { simd_kscheme_1bit_binary2_unpack_496<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_497 = { simd_kscheme_1bit_binary2_unpack_497<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_498 = { simd_kscheme_1bit_binary2_unpack_498<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_499 = { simd_kscheme_1bit_binary2_unpack_499<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_500 = { simd_kscheme_1bit_binary2_unpack_500<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_501 = { simd_kscheme_1bit_binary2_unpack_501<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_502 = { simd_kscheme_1bit_binary2_unpack_502<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_503 = { simd_kscheme_1bit_binary2_unpack_503<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_504 = { simd_kscheme_1bit_binary2_unpack_504<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_505 = { simd_kscheme_1bit_binary2_unpack_505<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_506 = { simd_kscheme_1bit_binary2_unpack_506<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_507 = { simd_kscheme_1bit_binary2_unpack_507<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_508 = { simd_kscheme_1bit_binary2_unpack_508<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_509 = { simd_kscheme_1bit_binary2_unpack_509<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_510 = { simd_kscheme_1bit_binary2_unpack_510<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_511 = { simd_kscheme_1bit_binary2_unpack_511<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_512 = { simd_kscheme_1bit_binary2_unpack_512<uint32_t>, 18  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_513 = { simd_kscheme_1bit_binary2_unpack_513<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_514 = { simd_kscheme_1bit_binary2_unpack_514<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_515 = { simd_kscheme_1bit_binary2_unpack_515<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_516 = { simd_kscheme_1bit_binary2_unpack_516<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_517 = { simd_kscheme_1bit_binary2_unpack_517<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_518 = { simd_kscheme_1bit_binary2_unpack_518<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_519 = { simd_kscheme_1bit_binary2_unpack_519<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_520 = { simd_kscheme_1bit_binary2_unpack_520<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_521 = { simd_kscheme_1bit_binary2_unpack_521<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_522 = { simd_kscheme_1bit_binary2_unpack_522<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_523 = { simd_kscheme_1bit_binary2_unpack_523<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_524 = { simd_kscheme_1bit_binary2_unpack_524<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_525 = { simd_kscheme_1bit_binary2_unpack_525<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_526 = { simd_kscheme_1bit_binary2_unpack_526<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_527 = { simd_kscheme_1bit_binary2_unpack_527<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_528 = { simd_kscheme_1bit_binary2_unpack_528<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_529 = { simd_kscheme_1bit_binary2_unpack_529<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_530 = { simd_kscheme_1bit_binary2_unpack_530<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_531 = { simd_kscheme_1bit_binary2_unpack_531<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_532 = { simd_kscheme_1bit_binary2_unpack_532<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_533 = { simd_kscheme_1bit_binary2_unpack_533<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_534 = { simd_kscheme_1bit_binary2_unpack_534<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_535 = { simd_kscheme_1bit_binary2_unpack_535<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_536 = { simd_kscheme_1bit_binary2_unpack_536<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_537 = { simd_kscheme_1bit_binary2_unpack_537<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_538 = { simd_kscheme_1bit_binary2_unpack_538<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_539 = { simd_kscheme_1bit_binary2_unpack_539<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_540 = { simd_kscheme_1bit_binary2_unpack_540<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_541 = { simd_kscheme_1bit_binary2_unpack_541<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_542 = { simd_kscheme_1bit_binary2_unpack_542<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_543 = { simd_kscheme_1bit_binary2_unpack_543<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_544 = { simd_kscheme_1bit_binary2_unpack_544<uint32_t>, 19  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_545 = { simd_kscheme_1bit_binary2_unpack_545<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_546 = { simd_kscheme_1bit_binary2_unpack_546<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_547 = { simd_kscheme_1bit_binary2_unpack_547<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_548 = { simd_kscheme_1bit_binary2_unpack_548<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_549 = { simd_kscheme_1bit_binary2_unpack_549<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_550 = { simd_kscheme_1bit_binary2_unpack_550<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_551 = { simd_kscheme_1bit_binary2_unpack_551<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_552 = { simd_kscheme_1bit_binary2_unpack_552<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_553 = { simd_kscheme_1bit_binary2_unpack_553<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_554 = { simd_kscheme_1bit_binary2_unpack_554<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_555 = { simd_kscheme_1bit_binary2_unpack_555<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_556 = { simd_kscheme_1bit_binary2_unpack_556<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_557 = { simd_kscheme_1bit_binary2_unpack_557<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_558 = { simd_kscheme_1bit_binary2_unpack_558<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_559 = { simd_kscheme_1bit_binary2_unpack_559<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_560 = { simd_kscheme_1bit_binary2_unpack_560<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_561 = { simd_kscheme_1bit_binary2_unpack_561<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_562 = { simd_kscheme_1bit_binary2_unpack_562<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_563 = { simd_kscheme_1bit_binary2_unpack_563<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_564 = { simd_kscheme_1bit_binary2_unpack_564<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_565 = { simd_kscheme_1bit_binary2_unpack_565<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_566 = { simd_kscheme_1bit_binary2_unpack_566<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_567 = { simd_kscheme_1bit_binary2_unpack_567<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_568 = { simd_kscheme_1bit_binary2_unpack_568<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_569 = { simd_kscheme_1bit_binary2_unpack_569<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_570 = { simd_kscheme_1bit_binary2_unpack_570<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_571 = { simd_kscheme_1bit_binary2_unpack_571<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_572 = { simd_kscheme_1bit_binary2_unpack_572<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_573 = { simd_kscheme_1bit_binary2_unpack_573<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_574 = { simd_kscheme_1bit_binary2_unpack_574<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_575 = { simd_kscheme_1bit_binary2_unpack_575<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_576 = { simd_kscheme_1bit_binary2_unpack_576<uint32_t>, 20  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_577 = { simd_kscheme_1bit_binary2_unpack_577<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_578 = { simd_kscheme_1bit_binary2_unpack_578<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_579 = { simd_kscheme_1bit_binary2_unpack_579<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_580 = { simd_kscheme_1bit_binary2_unpack_580<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_581 = { simd_kscheme_1bit_binary2_unpack_581<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_582 = { simd_kscheme_1bit_binary2_unpack_582<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_583 = { simd_kscheme_1bit_binary2_unpack_583<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_584 = { simd_kscheme_1bit_binary2_unpack_584<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_585 = { simd_kscheme_1bit_binary2_unpack_585<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_586 = { simd_kscheme_1bit_binary2_unpack_586<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_587 = { simd_kscheme_1bit_binary2_unpack_587<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_588 = { simd_kscheme_1bit_binary2_unpack_588<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_589 = { simd_kscheme_1bit_binary2_unpack_589<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_590 = { simd_kscheme_1bit_binary2_unpack_590<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_591 = { simd_kscheme_1bit_binary2_unpack_591<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_592 = { simd_kscheme_1bit_binary2_unpack_592<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_593 = { simd_kscheme_1bit_binary2_unpack_593<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_594 = { simd_kscheme_1bit_binary2_unpack_594<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_595 = { simd_kscheme_1bit_binary2_unpack_595<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_596 = { simd_kscheme_1bit_binary2_unpack_596<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_597 = { simd_kscheme_1bit_binary2_unpack_597<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_598 = { simd_kscheme_1bit_binary2_unpack_598<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_599 = { simd_kscheme_1bit_binary2_unpack_599<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_600 = { simd_kscheme_1bit_binary2_unpack_600<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_601 = { simd_kscheme_1bit_binary2_unpack_601<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_602 = { simd_kscheme_1bit_binary2_unpack_602<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_603 = { simd_kscheme_1bit_binary2_unpack_603<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_604 = { simd_kscheme_1bit_binary2_unpack_604<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_605 = { simd_kscheme_1bit_binary2_unpack_605<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_606 = { simd_kscheme_1bit_binary2_unpack_606<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_607 = { simd_kscheme_1bit_binary2_unpack_607<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_608 = { simd_kscheme_1bit_binary2_unpack_608<uint32_t>, 21  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_609 = { simd_kscheme_1bit_binary2_unpack_609<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_610 = { simd_kscheme_1bit_binary2_unpack_610<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_611 = { simd_kscheme_1bit_binary2_unpack_611<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_612 = { simd_kscheme_1bit_binary2_unpack_612<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_613 = { simd_kscheme_1bit_binary2_unpack_613<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_614 = { simd_kscheme_1bit_binary2_unpack_614<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_615 = { simd_kscheme_1bit_binary2_unpack_615<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_616 = { simd_kscheme_1bit_binary2_unpack_616<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_617 = { simd_kscheme_1bit_binary2_unpack_617<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_618 = { simd_kscheme_1bit_binary2_unpack_618<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_619 = { simd_kscheme_1bit_binary2_unpack_619<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_620 = { simd_kscheme_1bit_binary2_unpack_620<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_621 = { simd_kscheme_1bit_binary2_unpack_621<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_622 = { simd_kscheme_1bit_binary2_unpack_622<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_623 = { simd_kscheme_1bit_binary2_unpack_623<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_624 = { simd_kscheme_1bit_binary2_unpack_624<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_625 = { simd_kscheme_1bit_binary2_unpack_625<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_626 = { simd_kscheme_1bit_binary2_unpack_626<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_627 = { simd_kscheme_1bit_binary2_unpack_627<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_628 = { simd_kscheme_1bit_binary2_unpack_628<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_629 = { simd_kscheme_1bit_binary2_unpack_629<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_630 = { simd_kscheme_1bit_binary2_unpack_630<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_631 = { simd_kscheme_1bit_binary2_unpack_631<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_632 = { simd_kscheme_1bit_binary2_unpack_632<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_633 = { simd_kscheme_1bit_binary2_unpack_633<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_634 = { simd_kscheme_1bit_binary2_unpack_634<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_635 = { simd_kscheme_1bit_binary2_unpack_635<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_636 = { simd_kscheme_1bit_binary2_unpack_636<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_637 = { simd_kscheme_1bit_binary2_unpack_637<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_638 = { simd_kscheme_1bit_binary2_unpack_638<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_639 = { simd_kscheme_1bit_binary2_unpack_639<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_640 = { simd_kscheme_1bit_binary2_unpack_640<uint32_t>, 22  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_641 = { simd_kscheme_1bit_binary2_unpack_641<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_642 = { simd_kscheme_1bit_binary2_unpack_642<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_643 = { simd_kscheme_1bit_binary2_unpack_643<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_644 = { simd_kscheme_1bit_binary2_unpack_644<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_645 = { simd_kscheme_1bit_binary2_unpack_645<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_646 = { simd_kscheme_1bit_binary2_unpack_646<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_647 = { simd_kscheme_1bit_binary2_unpack_647<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_648 = { simd_kscheme_1bit_binary2_unpack_648<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_649 = { simd_kscheme_1bit_binary2_unpack_649<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_650 = { simd_kscheme_1bit_binary2_unpack_650<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_651 = { simd_kscheme_1bit_binary2_unpack_651<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_652 = { simd_kscheme_1bit_binary2_unpack_652<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_653 = { simd_kscheme_1bit_binary2_unpack_653<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_654 = { simd_kscheme_1bit_binary2_unpack_654<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_655 = { simd_kscheme_1bit_binary2_unpack_655<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_656 = { simd_kscheme_1bit_binary2_unpack_656<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_657 = { simd_kscheme_1bit_binary2_unpack_657<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_658 = { simd_kscheme_1bit_binary2_unpack_658<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_659 = { simd_kscheme_1bit_binary2_unpack_659<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_660 = { simd_kscheme_1bit_binary2_unpack_660<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_661 = { simd_kscheme_1bit_binary2_unpack_661<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_662 = { simd_kscheme_1bit_binary2_unpack_662<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_663 = { simd_kscheme_1bit_binary2_unpack_663<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_664 = { simd_kscheme_1bit_binary2_unpack_664<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_665 = { simd_kscheme_1bit_binary2_unpack_665<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_666 = { simd_kscheme_1bit_binary2_unpack_666<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_667 = { simd_kscheme_1bit_binary2_unpack_667<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_668 = { simd_kscheme_1bit_binary2_unpack_668<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_669 = { simd_kscheme_1bit_binary2_unpack_669<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_670 = { simd_kscheme_1bit_binary2_unpack_670<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_671 = { simd_kscheme_1bit_binary2_unpack_671<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_672 = { simd_kscheme_1bit_binary2_unpack_672<uint32_t>, 23  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_673 = { simd_kscheme_1bit_binary2_unpack_673<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_674 = { simd_kscheme_1bit_binary2_unpack_674<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_675 = { simd_kscheme_1bit_binary2_unpack_675<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_676 = { simd_kscheme_1bit_binary2_unpack_676<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_677 = { simd_kscheme_1bit_binary2_unpack_677<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_678 = { simd_kscheme_1bit_binary2_unpack_678<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_679 = { simd_kscheme_1bit_binary2_unpack_679<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_680 = { simd_kscheme_1bit_binary2_unpack_680<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_681 = { simd_kscheme_1bit_binary2_unpack_681<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_682 = { simd_kscheme_1bit_binary2_unpack_682<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_683 = { simd_kscheme_1bit_binary2_unpack_683<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_684 = { simd_kscheme_1bit_binary2_unpack_684<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_685 = { simd_kscheme_1bit_binary2_unpack_685<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_686 = { simd_kscheme_1bit_binary2_unpack_686<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_687 = { simd_kscheme_1bit_binary2_unpack_687<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_688 = { simd_kscheme_1bit_binary2_unpack_688<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_689 = { simd_kscheme_1bit_binary2_unpack_689<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_690 = { simd_kscheme_1bit_binary2_unpack_690<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_691 = { simd_kscheme_1bit_binary2_unpack_691<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_692 = { simd_kscheme_1bit_binary2_unpack_692<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_693 = { simd_kscheme_1bit_binary2_unpack_693<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_694 = { simd_kscheme_1bit_binary2_unpack_694<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_695 = { simd_kscheme_1bit_binary2_unpack_695<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_696 = { simd_kscheme_1bit_binary2_unpack_696<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_697 = { simd_kscheme_1bit_binary2_unpack_697<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_698 = { simd_kscheme_1bit_binary2_unpack_698<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_699 = { simd_kscheme_1bit_binary2_unpack_699<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_700 = { simd_kscheme_1bit_binary2_unpack_700<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_701 = { simd_kscheme_1bit_binary2_unpack_701<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_702 = { simd_kscheme_1bit_binary2_unpack_702<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_703 = { simd_kscheme_1bit_binary2_unpack_703<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_704 = { simd_kscheme_1bit_binary2_unpack_704<uint32_t>, 24  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_705 = { simd_kscheme_1bit_binary2_unpack_705<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_706 = { simd_kscheme_1bit_binary2_unpack_706<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_707 = { simd_kscheme_1bit_binary2_unpack_707<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_708 = { simd_kscheme_1bit_binary2_unpack_708<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_709 = { simd_kscheme_1bit_binary2_unpack_709<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_710 = { simd_kscheme_1bit_binary2_unpack_710<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_711 = { simd_kscheme_1bit_binary2_unpack_711<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_712 = { simd_kscheme_1bit_binary2_unpack_712<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_713 = { simd_kscheme_1bit_binary2_unpack_713<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_714 = { simd_kscheme_1bit_binary2_unpack_714<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_715 = { simd_kscheme_1bit_binary2_unpack_715<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_716 = { simd_kscheme_1bit_binary2_unpack_716<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_717 = { simd_kscheme_1bit_binary2_unpack_717<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_718 = { simd_kscheme_1bit_binary2_unpack_718<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_719 = { simd_kscheme_1bit_binary2_unpack_719<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_720 = { simd_kscheme_1bit_binary2_unpack_720<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_721 = { simd_kscheme_1bit_binary2_unpack_721<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_722 = { simd_kscheme_1bit_binary2_unpack_722<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_723 = { simd_kscheme_1bit_binary2_unpack_723<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_724 = { simd_kscheme_1bit_binary2_unpack_724<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_725 = { simd_kscheme_1bit_binary2_unpack_725<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_726 = { simd_kscheme_1bit_binary2_unpack_726<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_727 = { simd_kscheme_1bit_binary2_unpack_727<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_728 = { simd_kscheme_1bit_binary2_unpack_728<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_729 = { simd_kscheme_1bit_binary2_unpack_729<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_730 = { simd_kscheme_1bit_binary2_unpack_730<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_731 = { simd_kscheme_1bit_binary2_unpack_731<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_732 = { simd_kscheme_1bit_binary2_unpack_732<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_733 = { simd_kscheme_1bit_binary2_unpack_733<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_734 = { simd_kscheme_1bit_binary2_unpack_734<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_735 = { simd_kscheme_1bit_binary2_unpack_735<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_736 = { simd_kscheme_1bit_binary2_unpack_736<uint32_t>, 25  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_737 = { simd_kscheme_1bit_binary2_unpack_737<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_738 = { simd_kscheme_1bit_binary2_unpack_738<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_739 = { simd_kscheme_1bit_binary2_unpack_739<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_740 = { simd_kscheme_1bit_binary2_unpack_740<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_741 = { simd_kscheme_1bit_binary2_unpack_741<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_742 = { simd_kscheme_1bit_binary2_unpack_742<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_743 = { simd_kscheme_1bit_binary2_unpack_743<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_744 = { simd_kscheme_1bit_binary2_unpack_744<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_745 = { simd_kscheme_1bit_binary2_unpack_745<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_746 = { simd_kscheme_1bit_binary2_unpack_746<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_747 = { simd_kscheme_1bit_binary2_unpack_747<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_748 = { simd_kscheme_1bit_binary2_unpack_748<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_749 = { simd_kscheme_1bit_binary2_unpack_749<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_750 = { simd_kscheme_1bit_binary2_unpack_750<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_751 = { simd_kscheme_1bit_binary2_unpack_751<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_752 = { simd_kscheme_1bit_binary2_unpack_752<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_753 = { simd_kscheme_1bit_binary2_unpack_753<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_754 = { simd_kscheme_1bit_binary2_unpack_754<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_755 = { simd_kscheme_1bit_binary2_unpack_755<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_756 = { simd_kscheme_1bit_binary2_unpack_756<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_757 = { simd_kscheme_1bit_binary2_unpack_757<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_758 = { simd_kscheme_1bit_binary2_unpack_758<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_759 = { simd_kscheme_1bit_binary2_unpack_759<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_760 = { simd_kscheme_1bit_binary2_unpack_760<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_761 = { simd_kscheme_1bit_binary2_unpack_761<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_762 = { simd_kscheme_1bit_binary2_unpack_762<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_763 = { simd_kscheme_1bit_binary2_unpack_763<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_764 = { simd_kscheme_1bit_binary2_unpack_764<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_765 = { simd_kscheme_1bit_binary2_unpack_765<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_766 = { simd_kscheme_1bit_binary2_unpack_766<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_767 = { simd_kscheme_1bit_binary2_unpack_767<uint32_t>, 56  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_768 = { simd_kscheme_1bit_binary2_unpack_768<uint32_t>, 26  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_769 = { simd_kscheme_1bit_binary2_unpack_769<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_770 = { simd_kscheme_1bit_binary2_unpack_770<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_771 = { simd_kscheme_1bit_binary2_unpack_771<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_772 = { simd_kscheme_1bit_binary2_unpack_772<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_773 = { simd_kscheme_1bit_binary2_unpack_773<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_774 = { simd_kscheme_1bit_binary2_unpack_774<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_775 = { simd_kscheme_1bit_binary2_unpack_775<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_776 = { simd_kscheme_1bit_binary2_unpack_776<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_777 = { simd_kscheme_1bit_binary2_unpack_777<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_778 = { simd_kscheme_1bit_binary2_unpack_778<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_779 = { simd_kscheme_1bit_binary2_unpack_779<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_780 = { simd_kscheme_1bit_binary2_unpack_780<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_781 = { simd_kscheme_1bit_binary2_unpack_781<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_782 = { simd_kscheme_1bit_binary2_unpack_782<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_783 = { simd_kscheme_1bit_binary2_unpack_783<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_784 = { simd_kscheme_1bit_binary2_unpack_784<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_785 = { simd_kscheme_1bit_binary2_unpack_785<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_786 = { simd_kscheme_1bit_binary2_unpack_786<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_787 = { simd_kscheme_1bit_binary2_unpack_787<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_788 = { simd_kscheme_1bit_binary2_unpack_788<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_789 = { simd_kscheme_1bit_binary2_unpack_789<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_790 = { simd_kscheme_1bit_binary2_unpack_790<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_791 = { simd_kscheme_1bit_binary2_unpack_791<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_792 = { simd_kscheme_1bit_binary2_unpack_792<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_793 = { simd_kscheme_1bit_binary2_unpack_793<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_794 = { simd_kscheme_1bit_binary2_unpack_794<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_795 = { simd_kscheme_1bit_binary2_unpack_795<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_796 = { simd_kscheme_1bit_binary2_unpack_796<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_797 = { simd_kscheme_1bit_binary2_unpack_797<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_798 = { simd_kscheme_1bit_binary2_unpack_798<uint32_t>, 56  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_799 = { simd_kscheme_1bit_binary2_unpack_799<uint32_t>, 57  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_800 = { simd_kscheme_1bit_binary2_unpack_800<uint32_t>, 27  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_801 = { simd_kscheme_1bit_binary2_unpack_801<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_802 = { simd_kscheme_1bit_binary2_unpack_802<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_803 = { simd_kscheme_1bit_binary2_unpack_803<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_804 = { simd_kscheme_1bit_binary2_unpack_804<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_805 = { simd_kscheme_1bit_binary2_unpack_805<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_806 = { simd_kscheme_1bit_binary2_unpack_806<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_807 = { simd_kscheme_1bit_binary2_unpack_807<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_808 = { simd_kscheme_1bit_binary2_unpack_808<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_809 = { simd_kscheme_1bit_binary2_unpack_809<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_810 = { simd_kscheme_1bit_binary2_unpack_810<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_811 = { simd_kscheme_1bit_binary2_unpack_811<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_812 = { simd_kscheme_1bit_binary2_unpack_812<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_813 = { simd_kscheme_1bit_binary2_unpack_813<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_814 = { simd_kscheme_1bit_binary2_unpack_814<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_815 = { simd_kscheme_1bit_binary2_unpack_815<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_816 = { simd_kscheme_1bit_binary2_unpack_816<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_817 = { simd_kscheme_1bit_binary2_unpack_817<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_818 = { simd_kscheme_1bit_binary2_unpack_818<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_819 = { simd_kscheme_1bit_binary2_unpack_819<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_820 = { simd_kscheme_1bit_binary2_unpack_820<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_821 = { simd_kscheme_1bit_binary2_unpack_821<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_822 = { simd_kscheme_1bit_binary2_unpack_822<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_823 = { simd_kscheme_1bit_binary2_unpack_823<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_824 = { simd_kscheme_1bit_binary2_unpack_824<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_825 = { simd_kscheme_1bit_binary2_unpack_825<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_826 = { simd_kscheme_1bit_binary2_unpack_826<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_827 = { simd_kscheme_1bit_binary2_unpack_827<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_828 = { simd_kscheme_1bit_binary2_unpack_828<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_829 = { simd_kscheme_1bit_binary2_unpack_829<uint32_t>, 56  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_830 = { simd_kscheme_1bit_binary2_unpack_830<uint32_t>, 57  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_831 = { simd_kscheme_1bit_binary2_unpack_831<uint32_t>, 58  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_832 = { simd_kscheme_1bit_binary2_unpack_832<uint32_t>, 28  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_833 = { simd_kscheme_1bit_binary2_unpack_833<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_834 = { simd_kscheme_1bit_binary2_unpack_834<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_835 = { simd_kscheme_1bit_binary2_unpack_835<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_836 = { simd_kscheme_1bit_binary2_unpack_836<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_837 = { simd_kscheme_1bit_binary2_unpack_837<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_838 = { simd_kscheme_1bit_binary2_unpack_838<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_839 = { simd_kscheme_1bit_binary2_unpack_839<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_840 = { simd_kscheme_1bit_binary2_unpack_840<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_841 = { simd_kscheme_1bit_binary2_unpack_841<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_842 = { simd_kscheme_1bit_binary2_unpack_842<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_843 = { simd_kscheme_1bit_binary2_unpack_843<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_844 = { simd_kscheme_1bit_binary2_unpack_844<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_845 = { simd_kscheme_1bit_binary2_unpack_845<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_846 = { simd_kscheme_1bit_binary2_unpack_846<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_847 = { simd_kscheme_1bit_binary2_unpack_847<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_848 = { simd_kscheme_1bit_binary2_unpack_848<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_849 = { simd_kscheme_1bit_binary2_unpack_849<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_850 = { simd_kscheme_1bit_binary2_unpack_850<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_851 = { simd_kscheme_1bit_binary2_unpack_851<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_852 = { simd_kscheme_1bit_binary2_unpack_852<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_853 = { simd_kscheme_1bit_binary2_unpack_853<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_854 = { simd_kscheme_1bit_binary2_unpack_854<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_855 = { simd_kscheme_1bit_binary2_unpack_855<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_856 = { simd_kscheme_1bit_binary2_unpack_856<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_857 = { simd_kscheme_1bit_binary2_unpack_857<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_858 = { simd_kscheme_1bit_binary2_unpack_858<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_859 = { simd_kscheme_1bit_binary2_unpack_859<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_860 = { simd_kscheme_1bit_binary2_unpack_860<uint32_t>, 56  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_861 = { simd_kscheme_1bit_binary2_unpack_861<uint32_t>, 57  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_862 = { simd_kscheme_1bit_binary2_unpack_862<uint32_t>, 58  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_863 = { simd_kscheme_1bit_binary2_unpack_863<uint32_t>, 59  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_864 = { simd_kscheme_1bit_binary2_unpack_864<uint32_t>, 29  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_865 = { simd_kscheme_1bit_binary2_unpack_865<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_866 = { simd_kscheme_1bit_binary2_unpack_866<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_867 = { simd_kscheme_1bit_binary2_unpack_867<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_868 = { simd_kscheme_1bit_binary2_unpack_868<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_869 = { simd_kscheme_1bit_binary2_unpack_869<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_870 = { simd_kscheme_1bit_binary2_unpack_870<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_871 = { simd_kscheme_1bit_binary2_unpack_871<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_872 = { simd_kscheme_1bit_binary2_unpack_872<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_873 = { simd_kscheme_1bit_binary2_unpack_873<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_874 = { simd_kscheme_1bit_binary2_unpack_874<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_875 = { simd_kscheme_1bit_binary2_unpack_875<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_876 = { simd_kscheme_1bit_binary2_unpack_876<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_877 = { simd_kscheme_1bit_binary2_unpack_877<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_878 = { simd_kscheme_1bit_binary2_unpack_878<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_879 = { simd_kscheme_1bit_binary2_unpack_879<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_880 = { simd_kscheme_1bit_binary2_unpack_880<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_881 = { simd_kscheme_1bit_binary2_unpack_881<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_882 = { simd_kscheme_1bit_binary2_unpack_882<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_883 = { simd_kscheme_1bit_binary2_unpack_883<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_884 = { simd_kscheme_1bit_binary2_unpack_884<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_885 = { simd_kscheme_1bit_binary2_unpack_885<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_886 = { simd_kscheme_1bit_binary2_unpack_886<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_887 = { simd_kscheme_1bit_binary2_unpack_887<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_888 = { simd_kscheme_1bit_binary2_unpack_888<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_889 = { simd_kscheme_1bit_binary2_unpack_889<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_890 = { simd_kscheme_1bit_binary2_unpack_890<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_891 = { simd_kscheme_1bit_binary2_unpack_891<uint32_t>, 56  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_892 = { simd_kscheme_1bit_binary2_unpack_892<uint32_t>, 57  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_893 = { simd_kscheme_1bit_binary2_unpack_893<uint32_t>, 58  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_894 = { simd_kscheme_1bit_binary2_unpack_894<uint32_t>, 59  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_895 = { simd_kscheme_1bit_binary2_unpack_895<uint32_t>, 60  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_896 = { simd_kscheme_1bit_binary2_unpack_896<uint32_t>, 30  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_897 = { simd_kscheme_1bit_binary2_unpack_897<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_898 = { simd_kscheme_1bit_binary2_unpack_898<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_899 = { simd_kscheme_1bit_binary2_unpack_899<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_900 = { simd_kscheme_1bit_binary2_unpack_900<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_901 = { simd_kscheme_1bit_binary2_unpack_901<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_902 = { simd_kscheme_1bit_binary2_unpack_902<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_903 = { simd_kscheme_1bit_binary2_unpack_903<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_904 = { simd_kscheme_1bit_binary2_unpack_904<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_905 = { simd_kscheme_1bit_binary2_unpack_905<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_906 = { simd_kscheme_1bit_binary2_unpack_906<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_907 = { simd_kscheme_1bit_binary2_unpack_907<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_908 = { simd_kscheme_1bit_binary2_unpack_908<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_909 = { simd_kscheme_1bit_binary2_unpack_909<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_910 = { simd_kscheme_1bit_binary2_unpack_910<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_911 = { simd_kscheme_1bit_binary2_unpack_911<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_912 = { simd_kscheme_1bit_binary2_unpack_912<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_913 = { simd_kscheme_1bit_binary2_unpack_913<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_914 = { simd_kscheme_1bit_binary2_unpack_914<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_915 = { simd_kscheme_1bit_binary2_unpack_915<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_916 = { simd_kscheme_1bit_binary2_unpack_916<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_917 = { simd_kscheme_1bit_binary2_unpack_917<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_918 = { simd_kscheme_1bit_binary2_unpack_918<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_919 = { simd_kscheme_1bit_binary2_unpack_919<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_920 = { simd_kscheme_1bit_binary2_unpack_920<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_921 = { simd_kscheme_1bit_binary2_unpack_921<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_922 = { simd_kscheme_1bit_binary2_unpack_922<uint32_t>, 56  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_923 = { simd_kscheme_1bit_binary2_unpack_923<uint32_t>, 57  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_924 = { simd_kscheme_1bit_binary2_unpack_924<uint32_t>, 58  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_925 = { simd_kscheme_1bit_binary2_unpack_925<uint32_t>, 59  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_926 = { simd_kscheme_1bit_binary2_unpack_926<uint32_t>, 60  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_927 = { simd_kscheme_1bit_binary2_unpack_927<uint32_t>, 61  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_928 = { simd_kscheme_1bit_binary2_unpack_928<uint32_t>, 31  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_929 = { simd_kscheme_1bit_binary2_unpack_929<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_930 = { simd_kscheme_1bit_binary2_unpack_930<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_931 = { simd_kscheme_1bit_binary2_unpack_931<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_932 = { simd_kscheme_1bit_binary2_unpack_932<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_933 = { simd_kscheme_1bit_binary2_unpack_933<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_934 = { simd_kscheme_1bit_binary2_unpack_934<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_935 = { simd_kscheme_1bit_binary2_unpack_935<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_936 = { simd_kscheme_1bit_binary2_unpack_936<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_937 = { simd_kscheme_1bit_binary2_unpack_937<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_938 = { simd_kscheme_1bit_binary2_unpack_938<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_939 = { simd_kscheme_1bit_binary2_unpack_939<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_940 = { simd_kscheme_1bit_binary2_unpack_940<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_941 = { simd_kscheme_1bit_binary2_unpack_941<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_942 = { simd_kscheme_1bit_binary2_unpack_942<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_943 = { simd_kscheme_1bit_binary2_unpack_943<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_944 = { simd_kscheme_1bit_binary2_unpack_944<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_945 = { simd_kscheme_1bit_binary2_unpack_945<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_946 = { simd_kscheme_1bit_binary2_unpack_946<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_947 = { simd_kscheme_1bit_binary2_unpack_947<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_948 = { simd_kscheme_1bit_binary2_unpack_948<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_949 = { simd_kscheme_1bit_binary2_unpack_949<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_950 = { simd_kscheme_1bit_binary2_unpack_950<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_951 = { simd_kscheme_1bit_binary2_unpack_951<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_952 = { simd_kscheme_1bit_binary2_unpack_952<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_953 = { simd_kscheme_1bit_binary2_unpack_953<uint32_t>, 56  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_954 = { simd_kscheme_1bit_binary2_unpack_954<uint32_t>, 57  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_955 = { simd_kscheme_1bit_binary2_unpack_955<uint32_t>, 58  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_956 = { simd_kscheme_1bit_binary2_unpack_956<uint32_t>, 59  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_957 = { simd_kscheme_1bit_binary2_unpack_957<uint32_t>, 60  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_958 = { simd_kscheme_1bit_binary2_unpack_958<uint32_t>, 61  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_959 = { simd_kscheme_1bit_binary2_unpack_959<uint32_t>, 62  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_960 = { simd_kscheme_1bit_binary2_unpack_960<uint32_t>, 32  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_961 = { simd_kscheme_1bit_binary2_unpack_961<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_962 = { simd_kscheme_1bit_binary2_unpack_962<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_963 = { simd_kscheme_1bit_binary2_unpack_963<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_964 = { simd_kscheme_1bit_binary2_unpack_964<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_965 = { simd_kscheme_1bit_binary2_unpack_965<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_966 = { simd_kscheme_1bit_binary2_unpack_966<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_967 = { simd_kscheme_1bit_binary2_unpack_967<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_968 = { simd_kscheme_1bit_binary2_unpack_968<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_969 = { simd_kscheme_1bit_binary2_unpack_969<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_970 = { simd_kscheme_1bit_binary2_unpack_970<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_971 = { simd_kscheme_1bit_binary2_unpack_971<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_972 = { simd_kscheme_1bit_binary2_unpack_972<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_973 = { simd_kscheme_1bit_binary2_unpack_973<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_974 = { simd_kscheme_1bit_binary2_unpack_974<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_975 = { simd_kscheme_1bit_binary2_unpack_975<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_976 = { simd_kscheme_1bit_binary2_unpack_976<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_977 = { simd_kscheme_1bit_binary2_unpack_977<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_978 = { simd_kscheme_1bit_binary2_unpack_978<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_979 = { simd_kscheme_1bit_binary2_unpack_979<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_980 = { simd_kscheme_1bit_binary2_unpack_980<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_981 = { simd_kscheme_1bit_binary2_unpack_981<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_982 = { simd_kscheme_1bit_binary2_unpack_982<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_983 = { simd_kscheme_1bit_binary2_unpack_983<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_984 = { simd_kscheme_1bit_binary2_unpack_984<uint32_t>, 56  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_985 = { simd_kscheme_1bit_binary2_unpack_985<uint32_t>, 57  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_986 = { simd_kscheme_1bit_binary2_unpack_986<uint32_t>, 58  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_987 = { simd_kscheme_1bit_binary2_unpack_987<uint32_t>, 59  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_988 = { simd_kscheme_1bit_binary2_unpack_988<uint32_t>, 60  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_989 = { simd_kscheme_1bit_binary2_unpack_989<uint32_t>, 61  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_990 = { simd_kscheme_1bit_binary2_unpack_990<uint32_t>, 62  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_991 = { simd_kscheme_1bit_binary2_unpack_991<uint32_t>, 63  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_992 = { simd_kscheme_1bit_binary2_unpack_992<uint32_t>, 33  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_993 = { simd_kscheme_1bit_binary2_unpack_993<uint32_t>, 34  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_994 = { simd_kscheme_1bit_binary2_unpack_994<uint32_t>, 35  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_995 = { simd_kscheme_1bit_binary2_unpack_995<uint32_t>, 36  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_996 = { simd_kscheme_1bit_binary2_unpack_996<uint32_t>, 37  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_997 = { simd_kscheme_1bit_binary2_unpack_997<uint32_t>, 38  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_998 = { simd_kscheme_1bit_binary2_unpack_998<uint32_t>, 39  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_999 = { simd_kscheme_1bit_binary2_unpack_999<uint32_t>, 40  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1000 = { simd_kscheme_1bit_binary2_unpack_1000<uint32_t>, 41  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1001 = { simd_kscheme_1bit_binary2_unpack_1001<uint32_t>, 42  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1002 = { simd_kscheme_1bit_binary2_unpack_1002<uint32_t>, 43  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1003 = { simd_kscheme_1bit_binary2_unpack_1003<uint32_t>, 44  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1004 = { simd_kscheme_1bit_binary2_unpack_1004<uint32_t>, 45  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1005 = { simd_kscheme_1bit_binary2_unpack_1005<uint32_t>, 46  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1006 = { simd_kscheme_1bit_binary2_unpack_1006<uint32_t>, 47  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1007 = { simd_kscheme_1bit_binary2_unpack_1007<uint32_t>, 48  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1008 = { simd_kscheme_1bit_binary2_unpack_1008<uint32_t>, 49  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1009 = { simd_kscheme_1bit_binary2_unpack_1009<uint32_t>, 50  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1010 = { simd_kscheme_1bit_binary2_unpack_1010<uint32_t>, 51  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1011 = { simd_kscheme_1bit_binary2_unpack_1011<uint32_t>, 52  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1012 = { simd_kscheme_1bit_binary2_unpack_1012<uint32_t>, 53  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1013 = { simd_kscheme_1bit_binary2_unpack_1013<uint32_t>, 54  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1014 = { simd_kscheme_1bit_binary2_unpack_1014<uint32_t>, 55  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1015 = { simd_kscheme_1bit_binary2_unpack_1015<uint32_t>, 56  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1016 = { simd_kscheme_1bit_binary2_unpack_1016<uint32_t>, 57  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1017 = { simd_kscheme_1bit_binary2_unpack_1017<uint32_t>, 58  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1018 = { simd_kscheme_1bit_binary2_unpack_1018<uint32_t>, 59  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1019 = { simd_kscheme_1bit_binary2_unpack_1019<uint32_t>, 60  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1020 = { simd_kscheme_1bit_binary2_unpack_1020<uint32_t>, 61  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1021 = { simd_kscheme_1bit_binary2_unpack_1021<uint32_t>, 62  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1022 = { simd_kscheme_1bit_binary2_unpack_1022<uint32_t>, 63  };
static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfo_1023 = { simd_kscheme_1bit_binary2_unpack_1023<uint32_t>, 64  };

static SIMDK1B2UnpackInfo SIMDK1B2UnpackInfoArr[1024] = {
			SIMDK1B2UnpackInfo_0, SIMDK1B2UnpackInfo_1, SIMDK1B2UnpackInfo_2, SIMDK1B2UnpackInfo_3,
			SIMDK1B2UnpackInfo_4, SIMDK1B2UnpackInfo_5, SIMDK1B2UnpackInfo_6, SIMDK1B2UnpackInfo_7,
			SIMDK1B2UnpackInfo_8, SIMDK1B2UnpackInfo_9, SIMDK1B2UnpackInfo_10, SIMDK1B2UnpackInfo_11,
			SIMDK1B2UnpackInfo_12, SIMDK1B2UnpackInfo_13, SIMDK1B2UnpackInfo_14, SIMDK1B2UnpackInfo_15,
			SIMDK1B2UnpackInfo_16, SIMDK1B2UnpackInfo_17, SIMDK1B2UnpackInfo_18, SIMDK1B2UnpackInfo_19,
			SIMDK1B2UnpackInfo_20, SIMDK1B2UnpackInfo_21, SIMDK1B2UnpackInfo_22, SIMDK1B2UnpackInfo_23,
			SIMDK1B2UnpackInfo_24, SIMDK1B2UnpackInfo_25, SIMDK1B2UnpackInfo_26, SIMDK1B2UnpackInfo_27,
			SIMDK1B2UnpackInfo_28, SIMDK1B2UnpackInfo_29, SIMDK1B2UnpackInfo_30, SIMDK1B2UnpackInfo_31,
			SIMDK1B2UnpackInfo_32, SIMDK1B2UnpackInfo_33, SIMDK1B2UnpackInfo_34, SIMDK1B2UnpackInfo_35,
			SIMDK1B2UnpackInfo_36, SIMDK1B2UnpackInfo_37, SIMDK1B2UnpackInfo_38, SIMDK1B2UnpackInfo_39,
			SIMDK1B2UnpackInfo_40, SIMDK1B2UnpackInfo_41, SIMDK1B2UnpackInfo_42, SIMDK1B2UnpackInfo_43,
			SIMDK1B2UnpackInfo_44, SIMDK1B2UnpackInfo_45, SIMDK1B2UnpackInfo_46, SIMDK1B2UnpackInfo_47,
			SIMDK1B2UnpackInfo_48, SIMDK1B2UnpackInfo_49, SIMDK1B2UnpackInfo_50, SIMDK1B2UnpackInfo_51,
			SIMDK1B2UnpackInfo_52, SIMDK1B2UnpackInfo_53, SIMDK1B2UnpackInfo_54, SIMDK1B2UnpackInfo_55,
			SIMDK1B2UnpackInfo_56, SIMDK1B2UnpackInfo_57, SIMDK1B2UnpackInfo_58, SIMDK1B2UnpackInfo_59,
			SIMDK1B2UnpackInfo_60, SIMDK1B2UnpackInfo_61, SIMDK1B2UnpackInfo_62, SIMDK1B2UnpackInfo_63,
			SIMDK1B2UnpackInfo_64, SIMDK1B2UnpackInfo_65, SIMDK1B2UnpackInfo_66, SIMDK1B2UnpackInfo_67,
			SIMDK1B2UnpackInfo_68, SIMDK1B2UnpackInfo_69, SIMDK1B2UnpackInfo_70, SIMDK1B2UnpackInfo_71,
			SIMDK1B2UnpackInfo_72, SIMDK1B2UnpackInfo_73, SIMDK1B2UnpackInfo_74, SIMDK1B2UnpackInfo_75,
			SIMDK1B2UnpackInfo_76, SIMDK1B2UnpackInfo_77, SIMDK1B2UnpackInfo_78, SIMDK1B2UnpackInfo_79,
			SIMDK1B2UnpackInfo_80, SIMDK1B2UnpackInfo_81, SIMDK1B2UnpackInfo_82, SIMDK1B2UnpackInfo_83,
			SIMDK1B2UnpackInfo_84, SIMDK1B2UnpackInfo_85, SIMDK1B2UnpackInfo_86, SIMDK1B2UnpackInfo_87,
			SIMDK1B2UnpackInfo_88, SIMDK1B2UnpackInfo_89, SIMDK1B2UnpackInfo_90, SIMDK1B2UnpackInfo_91,
			SIMDK1B2UnpackInfo_92, SIMDK1B2UnpackInfo_93, SIMDK1B2UnpackInfo_94, SIMDK1B2UnpackInfo_95,
			SIMDK1B2UnpackInfo_96, SIMDK1B2UnpackInfo_97, SIMDK1B2UnpackInfo_98, SIMDK1B2UnpackInfo_99,
			SIMDK1B2UnpackInfo_100, SIMDK1B2UnpackInfo_101, SIMDK1B2UnpackInfo_102, SIMDK1B2UnpackInfo_103,
			SIMDK1B2UnpackInfo_104, SIMDK1B2UnpackInfo_105, SIMDK1B2UnpackInfo_106, SIMDK1B2UnpackInfo_107,
			SIMDK1B2UnpackInfo_108, SIMDK1B2UnpackInfo_109, SIMDK1B2UnpackInfo_110, SIMDK1B2UnpackInfo_111,
			SIMDK1B2UnpackInfo_112, SIMDK1B2UnpackInfo_113, SIMDK1B2UnpackInfo_114, SIMDK1B2UnpackInfo_115,
			SIMDK1B2UnpackInfo_116, SIMDK1B2UnpackInfo_117, SIMDK1B2UnpackInfo_118, SIMDK1B2UnpackInfo_119,
			SIMDK1B2UnpackInfo_120, SIMDK1B2UnpackInfo_121, SIMDK1B2UnpackInfo_122, SIMDK1B2UnpackInfo_123,
			SIMDK1B2UnpackInfo_124, SIMDK1B2UnpackInfo_125, SIMDK1B2UnpackInfo_126, SIMDK1B2UnpackInfo_127,
			SIMDK1B2UnpackInfo_128, SIMDK1B2UnpackInfo_129, SIMDK1B2UnpackInfo_130, SIMDK1B2UnpackInfo_131,
			SIMDK1B2UnpackInfo_132, SIMDK1B2UnpackInfo_133, SIMDK1B2UnpackInfo_134, SIMDK1B2UnpackInfo_135,
			SIMDK1B2UnpackInfo_136, SIMDK1B2UnpackInfo_137, SIMDK1B2UnpackInfo_138, SIMDK1B2UnpackInfo_139,
			SIMDK1B2UnpackInfo_140, SIMDK1B2UnpackInfo_141, SIMDK1B2UnpackInfo_142, SIMDK1B2UnpackInfo_143,
			SIMDK1B2UnpackInfo_144, SIMDK1B2UnpackInfo_145, SIMDK1B2UnpackInfo_146, SIMDK1B2UnpackInfo_147,
			SIMDK1B2UnpackInfo_148, SIMDK1B2UnpackInfo_149, SIMDK1B2UnpackInfo_150, SIMDK1B2UnpackInfo_151,
			SIMDK1B2UnpackInfo_152, SIMDK1B2UnpackInfo_153, SIMDK1B2UnpackInfo_154, SIMDK1B2UnpackInfo_155,
			SIMDK1B2UnpackInfo_156, SIMDK1B2UnpackInfo_157, SIMDK1B2UnpackInfo_158, SIMDK1B2UnpackInfo_159,
			SIMDK1B2UnpackInfo_160, SIMDK1B2UnpackInfo_161, SIMDK1B2UnpackInfo_162, SIMDK1B2UnpackInfo_163,
			SIMDK1B2UnpackInfo_164, SIMDK1B2UnpackInfo_165, SIMDK1B2UnpackInfo_166, SIMDK1B2UnpackInfo_167,
			SIMDK1B2UnpackInfo_168, SIMDK1B2UnpackInfo_169, SIMDK1B2UnpackInfo_170, SIMDK1B2UnpackInfo_171,
			SIMDK1B2UnpackInfo_172, SIMDK1B2UnpackInfo_173, SIMDK1B2UnpackInfo_174, SIMDK1B2UnpackInfo_175,
			SIMDK1B2UnpackInfo_176, SIMDK1B2UnpackInfo_177, SIMDK1B2UnpackInfo_178, SIMDK1B2UnpackInfo_179,
			SIMDK1B2UnpackInfo_180, SIMDK1B2UnpackInfo_181, SIMDK1B2UnpackInfo_182, SIMDK1B2UnpackInfo_183,
			SIMDK1B2UnpackInfo_184, SIMDK1B2UnpackInfo_185, SIMDK1B2UnpackInfo_186, SIMDK1B2UnpackInfo_187,
			SIMDK1B2UnpackInfo_188, SIMDK1B2UnpackInfo_189, SIMDK1B2UnpackInfo_190, SIMDK1B2UnpackInfo_191,
			SIMDK1B2UnpackInfo_192, SIMDK1B2UnpackInfo_193, SIMDK1B2UnpackInfo_194, SIMDK1B2UnpackInfo_195,
			SIMDK1B2UnpackInfo_196, SIMDK1B2UnpackInfo_197, SIMDK1B2UnpackInfo_198, SIMDK1B2UnpackInfo_199,
			SIMDK1B2UnpackInfo_200, SIMDK1B2UnpackInfo_201, SIMDK1B2UnpackInfo_202, SIMDK1B2UnpackInfo_203,
			SIMDK1B2UnpackInfo_204, SIMDK1B2UnpackInfo_205, SIMDK1B2UnpackInfo_206, SIMDK1B2UnpackInfo_207,
			SIMDK1B2UnpackInfo_208, SIMDK1B2UnpackInfo_209, SIMDK1B2UnpackInfo_210, SIMDK1B2UnpackInfo_211,
			SIMDK1B2UnpackInfo_212, SIMDK1B2UnpackInfo_213, SIMDK1B2UnpackInfo_214, SIMDK1B2UnpackInfo_215,
			SIMDK1B2UnpackInfo_216, SIMDK1B2UnpackInfo_217, SIMDK1B2UnpackInfo_218, SIMDK1B2UnpackInfo_219,
			SIMDK1B2UnpackInfo_220, SIMDK1B2UnpackInfo_221, SIMDK1B2UnpackInfo_222, SIMDK1B2UnpackInfo_223,
			SIMDK1B2UnpackInfo_224, SIMDK1B2UnpackInfo_225, SIMDK1B2UnpackInfo_226, SIMDK1B2UnpackInfo_227,
			SIMDK1B2UnpackInfo_228, SIMDK1B2UnpackInfo_229, SIMDK1B2UnpackInfo_230, SIMDK1B2UnpackInfo_231,
			SIMDK1B2UnpackInfo_232, SIMDK1B2UnpackInfo_233, SIMDK1B2UnpackInfo_234, SIMDK1B2UnpackInfo_235,
			SIMDK1B2UnpackInfo_236, SIMDK1B2UnpackInfo_237, SIMDK1B2UnpackInfo_238, SIMDK1B2UnpackInfo_239,
			SIMDK1B2UnpackInfo_240, SIMDK1B2UnpackInfo_241, SIMDK1B2UnpackInfo_242, SIMDK1B2UnpackInfo_243,
			SIMDK1B2UnpackInfo_244, SIMDK1B2UnpackInfo_245, SIMDK1B2UnpackInfo_246, SIMDK1B2UnpackInfo_247,
			SIMDK1B2UnpackInfo_248, SIMDK1B2UnpackInfo_249, SIMDK1B2UnpackInfo_250, SIMDK1B2UnpackInfo_251,
			SIMDK1B2UnpackInfo_252, SIMDK1B2UnpackInfo_253, SIMDK1B2UnpackInfo_254, SIMDK1B2UnpackInfo_255,
			SIMDK1B2UnpackInfo_256, SIMDK1B2UnpackInfo_257, SIMDK1B2UnpackInfo_258, SIMDK1B2UnpackInfo_259,
			SIMDK1B2UnpackInfo_260, SIMDK1B2UnpackInfo_261, SIMDK1B2UnpackInfo_262, SIMDK1B2UnpackInfo_263,
			SIMDK1B2UnpackInfo_264, SIMDK1B2UnpackInfo_265, SIMDK1B2UnpackInfo_266, SIMDK1B2UnpackInfo_267,
			SIMDK1B2UnpackInfo_268, SIMDK1B2UnpackInfo_269, SIMDK1B2UnpackInfo_270, SIMDK1B2UnpackInfo_271,
			SIMDK1B2UnpackInfo_272, SIMDK1B2UnpackInfo_273, SIMDK1B2UnpackInfo_274, SIMDK1B2UnpackInfo_275,
			SIMDK1B2UnpackInfo_276, SIMDK1B2UnpackInfo_277, SIMDK1B2UnpackInfo_278, SIMDK1B2UnpackInfo_279,
			SIMDK1B2UnpackInfo_280, SIMDK1B2UnpackInfo_281, SIMDK1B2UnpackInfo_282, SIMDK1B2UnpackInfo_283,
			SIMDK1B2UnpackInfo_284, SIMDK1B2UnpackInfo_285, SIMDK1B2UnpackInfo_286, SIMDK1B2UnpackInfo_287,
			SIMDK1B2UnpackInfo_288, SIMDK1B2UnpackInfo_289, SIMDK1B2UnpackInfo_290, SIMDK1B2UnpackInfo_291,
			SIMDK1B2UnpackInfo_292, SIMDK1B2UnpackInfo_293, SIMDK1B2UnpackInfo_294, SIMDK1B2UnpackInfo_295,
			SIMDK1B2UnpackInfo_296, SIMDK1B2UnpackInfo_297, SIMDK1B2UnpackInfo_298, SIMDK1B2UnpackInfo_299,
			SIMDK1B2UnpackInfo_300, SIMDK1B2UnpackInfo_301, SIMDK1B2UnpackInfo_302, SIMDK1B2UnpackInfo_303,
			SIMDK1B2UnpackInfo_304, SIMDK1B2UnpackInfo_305, SIMDK1B2UnpackInfo_306, SIMDK1B2UnpackInfo_307,
			SIMDK1B2UnpackInfo_308, SIMDK1B2UnpackInfo_309, SIMDK1B2UnpackInfo_310, SIMDK1B2UnpackInfo_311,
			SIMDK1B2UnpackInfo_312, SIMDK1B2UnpackInfo_313, SIMDK1B2UnpackInfo_314, SIMDK1B2UnpackInfo_315,
			SIMDK1B2UnpackInfo_316, SIMDK1B2UnpackInfo_317, SIMDK1B2UnpackInfo_318, SIMDK1B2UnpackInfo_319,
			SIMDK1B2UnpackInfo_320, SIMDK1B2UnpackInfo_321, SIMDK1B2UnpackInfo_322, SIMDK1B2UnpackInfo_323,
			SIMDK1B2UnpackInfo_324, SIMDK1B2UnpackInfo_325, SIMDK1B2UnpackInfo_326, SIMDK1B2UnpackInfo_327,
			SIMDK1B2UnpackInfo_328, SIMDK1B2UnpackInfo_329, SIMDK1B2UnpackInfo_330, SIMDK1B2UnpackInfo_331,
			SIMDK1B2UnpackInfo_332, SIMDK1B2UnpackInfo_333, SIMDK1B2UnpackInfo_334, SIMDK1B2UnpackInfo_335,
			SIMDK1B2UnpackInfo_336, SIMDK1B2UnpackInfo_337, SIMDK1B2UnpackInfo_338, SIMDK1B2UnpackInfo_339,
			SIMDK1B2UnpackInfo_340, SIMDK1B2UnpackInfo_341, SIMDK1B2UnpackInfo_342, SIMDK1B2UnpackInfo_343,
			SIMDK1B2UnpackInfo_344, SIMDK1B2UnpackInfo_345, SIMDK1B2UnpackInfo_346, SIMDK1B2UnpackInfo_347,
			SIMDK1B2UnpackInfo_348, SIMDK1B2UnpackInfo_349, SIMDK1B2UnpackInfo_350, SIMDK1B2UnpackInfo_351,
			SIMDK1B2UnpackInfo_352, SIMDK1B2UnpackInfo_353, SIMDK1B2UnpackInfo_354, SIMDK1B2UnpackInfo_355,
			SIMDK1B2UnpackInfo_356, SIMDK1B2UnpackInfo_357, SIMDK1B2UnpackInfo_358, SIMDK1B2UnpackInfo_359,
			SIMDK1B2UnpackInfo_360, SIMDK1B2UnpackInfo_361, SIMDK1B2UnpackInfo_362, SIMDK1B2UnpackInfo_363,
			SIMDK1B2UnpackInfo_364, SIMDK1B2UnpackInfo_365, SIMDK1B2UnpackInfo_366, SIMDK1B2UnpackInfo_367,
			SIMDK1B2UnpackInfo_368, SIMDK1B2UnpackInfo_369, SIMDK1B2UnpackInfo_370, SIMDK1B2UnpackInfo_371,
			SIMDK1B2UnpackInfo_372, SIMDK1B2UnpackInfo_373, SIMDK1B2UnpackInfo_374, SIMDK1B2UnpackInfo_375,
			SIMDK1B2UnpackInfo_376, SIMDK1B2UnpackInfo_377, SIMDK1B2UnpackInfo_378, SIMDK1B2UnpackInfo_379,
			SIMDK1B2UnpackInfo_380, SIMDK1B2UnpackInfo_381, SIMDK1B2UnpackInfo_382, SIMDK1B2UnpackInfo_383,
			SIMDK1B2UnpackInfo_384, SIMDK1B2UnpackInfo_385, SIMDK1B2UnpackInfo_386, SIMDK1B2UnpackInfo_387,
			SIMDK1B2UnpackInfo_388, SIMDK1B2UnpackInfo_389, SIMDK1B2UnpackInfo_390, SIMDK1B2UnpackInfo_391,
			SIMDK1B2UnpackInfo_392, SIMDK1B2UnpackInfo_393, SIMDK1B2UnpackInfo_394, SIMDK1B2UnpackInfo_395,
			SIMDK1B2UnpackInfo_396, SIMDK1B2UnpackInfo_397, SIMDK1B2UnpackInfo_398, SIMDK1B2UnpackInfo_399,
			SIMDK1B2UnpackInfo_400, SIMDK1B2UnpackInfo_401, SIMDK1B2UnpackInfo_402, SIMDK1B2UnpackInfo_403,
			SIMDK1B2UnpackInfo_404, SIMDK1B2UnpackInfo_405, SIMDK1B2UnpackInfo_406, SIMDK1B2UnpackInfo_407,
			SIMDK1B2UnpackInfo_408, SIMDK1B2UnpackInfo_409, SIMDK1B2UnpackInfo_410, SIMDK1B2UnpackInfo_411,
			SIMDK1B2UnpackInfo_412, SIMDK1B2UnpackInfo_413, SIMDK1B2UnpackInfo_414, SIMDK1B2UnpackInfo_415,
			SIMDK1B2UnpackInfo_416, SIMDK1B2UnpackInfo_417, SIMDK1B2UnpackInfo_418, SIMDK1B2UnpackInfo_419,
			SIMDK1B2UnpackInfo_420, SIMDK1B2UnpackInfo_421, SIMDK1B2UnpackInfo_422, SIMDK1B2UnpackInfo_423,
			SIMDK1B2UnpackInfo_424, SIMDK1B2UnpackInfo_425, SIMDK1B2UnpackInfo_426, SIMDK1B2UnpackInfo_427,
			SIMDK1B2UnpackInfo_428, SIMDK1B2UnpackInfo_429, SIMDK1B2UnpackInfo_430, SIMDK1B2UnpackInfo_431,
			SIMDK1B2UnpackInfo_432, SIMDK1B2UnpackInfo_433, SIMDK1B2UnpackInfo_434, SIMDK1B2UnpackInfo_435,
			SIMDK1B2UnpackInfo_436, SIMDK1B2UnpackInfo_437, SIMDK1B2UnpackInfo_438, SIMDK1B2UnpackInfo_439,
			SIMDK1B2UnpackInfo_440, SIMDK1B2UnpackInfo_441, SIMDK1B2UnpackInfo_442, SIMDK1B2UnpackInfo_443,
			SIMDK1B2UnpackInfo_444, SIMDK1B2UnpackInfo_445, SIMDK1B2UnpackInfo_446, SIMDK1B2UnpackInfo_447,
			SIMDK1B2UnpackInfo_448, SIMDK1B2UnpackInfo_449, SIMDK1B2UnpackInfo_450, SIMDK1B2UnpackInfo_451,
			SIMDK1B2UnpackInfo_452, SIMDK1B2UnpackInfo_453, SIMDK1B2UnpackInfo_454, SIMDK1B2UnpackInfo_455,
			SIMDK1B2UnpackInfo_456, SIMDK1B2UnpackInfo_457, SIMDK1B2UnpackInfo_458, SIMDK1B2UnpackInfo_459,
			SIMDK1B2UnpackInfo_460, SIMDK1B2UnpackInfo_461, SIMDK1B2UnpackInfo_462, SIMDK1B2UnpackInfo_463,
			SIMDK1B2UnpackInfo_464, SIMDK1B2UnpackInfo_465, SIMDK1B2UnpackInfo_466, SIMDK1B2UnpackInfo_467,
			SIMDK1B2UnpackInfo_468, SIMDK1B2UnpackInfo_469, SIMDK1B2UnpackInfo_470, SIMDK1B2UnpackInfo_471,
			SIMDK1B2UnpackInfo_472, SIMDK1B2UnpackInfo_473, SIMDK1B2UnpackInfo_474, SIMDK1B2UnpackInfo_475,
			SIMDK1B2UnpackInfo_476, SIMDK1B2UnpackInfo_477, SIMDK1B2UnpackInfo_478, SIMDK1B2UnpackInfo_479,
			SIMDK1B2UnpackInfo_480, SIMDK1B2UnpackInfo_481, SIMDK1B2UnpackInfo_482, SIMDK1B2UnpackInfo_483,
			SIMDK1B2UnpackInfo_484, SIMDK1B2UnpackInfo_485, SIMDK1B2UnpackInfo_486, SIMDK1B2UnpackInfo_487,
			SIMDK1B2UnpackInfo_488, SIMDK1B2UnpackInfo_489, SIMDK1B2UnpackInfo_490, SIMDK1B2UnpackInfo_491,
			SIMDK1B2UnpackInfo_492, SIMDK1B2UnpackInfo_493, SIMDK1B2UnpackInfo_494, SIMDK1B2UnpackInfo_495,
			SIMDK1B2UnpackInfo_496, SIMDK1B2UnpackInfo_497, SIMDK1B2UnpackInfo_498, SIMDK1B2UnpackInfo_499,
			SIMDK1B2UnpackInfo_500, SIMDK1B2UnpackInfo_501, SIMDK1B2UnpackInfo_502, SIMDK1B2UnpackInfo_503,
			SIMDK1B2UnpackInfo_504, SIMDK1B2UnpackInfo_505, SIMDK1B2UnpackInfo_506, SIMDK1B2UnpackInfo_507,
			SIMDK1B2UnpackInfo_508, SIMDK1B2UnpackInfo_509, SIMDK1B2UnpackInfo_510, SIMDK1B2UnpackInfo_511,
			SIMDK1B2UnpackInfo_512, SIMDK1B2UnpackInfo_513, SIMDK1B2UnpackInfo_514, SIMDK1B2UnpackInfo_515,
			SIMDK1B2UnpackInfo_516, SIMDK1B2UnpackInfo_517, SIMDK1B2UnpackInfo_518, SIMDK1B2UnpackInfo_519,
			SIMDK1B2UnpackInfo_520, SIMDK1B2UnpackInfo_521, SIMDK1B2UnpackInfo_522, SIMDK1B2UnpackInfo_523,
			SIMDK1B2UnpackInfo_524, SIMDK1B2UnpackInfo_525, SIMDK1B2UnpackInfo_526, SIMDK1B2UnpackInfo_527,
			SIMDK1B2UnpackInfo_528, SIMDK1B2UnpackInfo_529, SIMDK1B2UnpackInfo_530, SIMDK1B2UnpackInfo_531,
			SIMDK1B2UnpackInfo_532, SIMDK1B2UnpackInfo_533, SIMDK1B2UnpackInfo_534, SIMDK1B2UnpackInfo_535,
			SIMDK1B2UnpackInfo_536, SIMDK1B2UnpackInfo_537, SIMDK1B2UnpackInfo_538, SIMDK1B2UnpackInfo_539,
			SIMDK1B2UnpackInfo_540, SIMDK1B2UnpackInfo_541, SIMDK1B2UnpackInfo_542, SIMDK1B2UnpackInfo_543,
			SIMDK1B2UnpackInfo_544, SIMDK1B2UnpackInfo_545, SIMDK1B2UnpackInfo_546, SIMDK1B2UnpackInfo_547,
			SIMDK1B2UnpackInfo_548, SIMDK1B2UnpackInfo_549, SIMDK1B2UnpackInfo_550, SIMDK1B2UnpackInfo_551,
			SIMDK1B2UnpackInfo_552, SIMDK1B2UnpackInfo_553, SIMDK1B2UnpackInfo_554, SIMDK1B2UnpackInfo_555,
			SIMDK1B2UnpackInfo_556, SIMDK1B2UnpackInfo_557, SIMDK1B2UnpackInfo_558, SIMDK1B2UnpackInfo_559,
			SIMDK1B2UnpackInfo_560, SIMDK1B2UnpackInfo_561, SIMDK1B2UnpackInfo_562, SIMDK1B2UnpackInfo_563,
			SIMDK1B2UnpackInfo_564, SIMDK1B2UnpackInfo_565, SIMDK1B2UnpackInfo_566, SIMDK1B2UnpackInfo_567,
			SIMDK1B2UnpackInfo_568, SIMDK1B2UnpackInfo_569, SIMDK1B2UnpackInfo_570, SIMDK1B2UnpackInfo_571,
			SIMDK1B2UnpackInfo_572, SIMDK1B2UnpackInfo_573, SIMDK1B2UnpackInfo_574, SIMDK1B2UnpackInfo_575,
			SIMDK1B2UnpackInfo_576, SIMDK1B2UnpackInfo_577, SIMDK1B2UnpackInfo_578, SIMDK1B2UnpackInfo_579,
			SIMDK1B2UnpackInfo_580, SIMDK1B2UnpackInfo_581, SIMDK1B2UnpackInfo_582, SIMDK1B2UnpackInfo_583,
			SIMDK1B2UnpackInfo_584, SIMDK1B2UnpackInfo_585, SIMDK1B2UnpackInfo_586, SIMDK1B2UnpackInfo_587,
			SIMDK1B2UnpackInfo_588, SIMDK1B2UnpackInfo_589, SIMDK1B2UnpackInfo_590, SIMDK1B2UnpackInfo_591,
			SIMDK1B2UnpackInfo_592, SIMDK1B2UnpackInfo_593, SIMDK1B2UnpackInfo_594, SIMDK1B2UnpackInfo_595,
			SIMDK1B2UnpackInfo_596, SIMDK1B2UnpackInfo_597, SIMDK1B2UnpackInfo_598, SIMDK1B2UnpackInfo_599,
			SIMDK1B2UnpackInfo_600, SIMDK1B2UnpackInfo_601, SIMDK1B2UnpackInfo_602, SIMDK1B2UnpackInfo_603,
			SIMDK1B2UnpackInfo_604, SIMDK1B2UnpackInfo_605, SIMDK1B2UnpackInfo_606, SIMDK1B2UnpackInfo_607,
			SIMDK1B2UnpackInfo_608, SIMDK1B2UnpackInfo_609, SIMDK1B2UnpackInfo_610, SIMDK1B2UnpackInfo_611,
			SIMDK1B2UnpackInfo_612, SIMDK1B2UnpackInfo_613, SIMDK1B2UnpackInfo_614, SIMDK1B2UnpackInfo_615,
			SIMDK1B2UnpackInfo_616, SIMDK1B2UnpackInfo_617, SIMDK1B2UnpackInfo_618, SIMDK1B2UnpackInfo_619,
			SIMDK1B2UnpackInfo_620, SIMDK1B2UnpackInfo_621, SIMDK1B2UnpackInfo_622, SIMDK1B2UnpackInfo_623,
			SIMDK1B2UnpackInfo_624, SIMDK1B2UnpackInfo_625, SIMDK1B2UnpackInfo_626, SIMDK1B2UnpackInfo_627,
			SIMDK1B2UnpackInfo_628, SIMDK1B2UnpackInfo_629, SIMDK1B2UnpackInfo_630, SIMDK1B2UnpackInfo_631,
			SIMDK1B2UnpackInfo_632, SIMDK1B2UnpackInfo_633, SIMDK1B2UnpackInfo_634, SIMDK1B2UnpackInfo_635,
			SIMDK1B2UnpackInfo_636, SIMDK1B2UnpackInfo_637, SIMDK1B2UnpackInfo_638, SIMDK1B2UnpackInfo_639,
			SIMDK1B2UnpackInfo_640, SIMDK1B2UnpackInfo_641, SIMDK1B2UnpackInfo_642, SIMDK1B2UnpackInfo_643,
			SIMDK1B2UnpackInfo_644, SIMDK1B2UnpackInfo_645, SIMDK1B2UnpackInfo_646, SIMDK1B2UnpackInfo_647,
			SIMDK1B2UnpackInfo_648, SIMDK1B2UnpackInfo_649, SIMDK1B2UnpackInfo_650, SIMDK1B2UnpackInfo_651,
			SIMDK1B2UnpackInfo_652, SIMDK1B2UnpackInfo_653, SIMDK1B2UnpackInfo_654, SIMDK1B2UnpackInfo_655,
			SIMDK1B2UnpackInfo_656, SIMDK1B2UnpackInfo_657, SIMDK1B2UnpackInfo_658, SIMDK1B2UnpackInfo_659,
			SIMDK1B2UnpackInfo_660, SIMDK1B2UnpackInfo_661, SIMDK1B2UnpackInfo_662, SIMDK1B2UnpackInfo_663,
			SIMDK1B2UnpackInfo_664, SIMDK1B2UnpackInfo_665, SIMDK1B2UnpackInfo_666, SIMDK1B2UnpackInfo_667,
			SIMDK1B2UnpackInfo_668, SIMDK1B2UnpackInfo_669, SIMDK1B2UnpackInfo_670, SIMDK1B2UnpackInfo_671,
			SIMDK1B2UnpackInfo_672, SIMDK1B2UnpackInfo_673, SIMDK1B2UnpackInfo_674, SIMDK1B2UnpackInfo_675,
			SIMDK1B2UnpackInfo_676, SIMDK1B2UnpackInfo_677, SIMDK1B2UnpackInfo_678, SIMDK1B2UnpackInfo_679,
			SIMDK1B2UnpackInfo_680, SIMDK1B2UnpackInfo_681, SIMDK1B2UnpackInfo_682, SIMDK1B2UnpackInfo_683,
			SIMDK1B2UnpackInfo_684, SIMDK1B2UnpackInfo_685, SIMDK1B2UnpackInfo_686, SIMDK1B2UnpackInfo_687,
			SIMDK1B2UnpackInfo_688, SIMDK1B2UnpackInfo_689, SIMDK1B2UnpackInfo_690, SIMDK1B2UnpackInfo_691,
			SIMDK1B2UnpackInfo_692, SIMDK1B2UnpackInfo_693, SIMDK1B2UnpackInfo_694, SIMDK1B2UnpackInfo_695,
			SIMDK1B2UnpackInfo_696, SIMDK1B2UnpackInfo_697, SIMDK1B2UnpackInfo_698, SIMDK1B2UnpackInfo_699,
			SIMDK1B2UnpackInfo_700, SIMDK1B2UnpackInfo_701, SIMDK1B2UnpackInfo_702, SIMDK1B2UnpackInfo_703,
			SIMDK1B2UnpackInfo_704, SIMDK1B2UnpackInfo_705, SIMDK1B2UnpackInfo_706, SIMDK1B2UnpackInfo_707,
			SIMDK1B2UnpackInfo_708, SIMDK1B2UnpackInfo_709, SIMDK1B2UnpackInfo_710, SIMDK1B2UnpackInfo_711,
			SIMDK1B2UnpackInfo_712, SIMDK1B2UnpackInfo_713, SIMDK1B2UnpackInfo_714, SIMDK1B2UnpackInfo_715,
			SIMDK1B2UnpackInfo_716, SIMDK1B2UnpackInfo_717, SIMDK1B2UnpackInfo_718, SIMDK1B2UnpackInfo_719,
			SIMDK1B2UnpackInfo_720, SIMDK1B2UnpackInfo_721, SIMDK1B2UnpackInfo_722, SIMDK1B2UnpackInfo_723,
			SIMDK1B2UnpackInfo_724, SIMDK1B2UnpackInfo_725, SIMDK1B2UnpackInfo_726, SIMDK1B2UnpackInfo_727,
			SIMDK1B2UnpackInfo_728, SIMDK1B2UnpackInfo_729, SIMDK1B2UnpackInfo_730, SIMDK1B2UnpackInfo_731,
			SIMDK1B2UnpackInfo_732, SIMDK1B2UnpackInfo_733, SIMDK1B2UnpackInfo_734, SIMDK1B2UnpackInfo_735,
			SIMDK1B2UnpackInfo_736, SIMDK1B2UnpackInfo_737, SIMDK1B2UnpackInfo_738, SIMDK1B2UnpackInfo_739,
			SIMDK1B2UnpackInfo_740, SIMDK1B2UnpackInfo_741, SIMDK1B2UnpackInfo_742, SIMDK1B2UnpackInfo_743,
			SIMDK1B2UnpackInfo_744, SIMDK1B2UnpackInfo_745, SIMDK1B2UnpackInfo_746, SIMDK1B2UnpackInfo_747,
			SIMDK1B2UnpackInfo_748, SIMDK1B2UnpackInfo_749, SIMDK1B2UnpackInfo_750, SIMDK1B2UnpackInfo_751,
			SIMDK1B2UnpackInfo_752, SIMDK1B2UnpackInfo_753, SIMDK1B2UnpackInfo_754, SIMDK1B2UnpackInfo_755,
			SIMDK1B2UnpackInfo_756, SIMDK1B2UnpackInfo_757, SIMDK1B2UnpackInfo_758, SIMDK1B2UnpackInfo_759,
			SIMDK1B2UnpackInfo_760, SIMDK1B2UnpackInfo_761, SIMDK1B2UnpackInfo_762, SIMDK1B2UnpackInfo_763,
			SIMDK1B2UnpackInfo_764, SIMDK1B2UnpackInfo_765, SIMDK1B2UnpackInfo_766, SIMDK1B2UnpackInfo_767,
			SIMDK1B2UnpackInfo_768, SIMDK1B2UnpackInfo_769, SIMDK1B2UnpackInfo_770, SIMDK1B2UnpackInfo_771,
			SIMDK1B2UnpackInfo_772, SIMDK1B2UnpackInfo_773, SIMDK1B2UnpackInfo_774, SIMDK1B2UnpackInfo_775,
			SIMDK1B2UnpackInfo_776, SIMDK1B2UnpackInfo_777, SIMDK1B2UnpackInfo_778, SIMDK1B2UnpackInfo_779,
			SIMDK1B2UnpackInfo_780, SIMDK1B2UnpackInfo_781, SIMDK1B2UnpackInfo_782, SIMDK1B2UnpackInfo_783,
			SIMDK1B2UnpackInfo_784, SIMDK1B2UnpackInfo_785, SIMDK1B2UnpackInfo_786, SIMDK1B2UnpackInfo_787,
			SIMDK1B2UnpackInfo_788, SIMDK1B2UnpackInfo_789, SIMDK1B2UnpackInfo_790, SIMDK1B2UnpackInfo_791,
			SIMDK1B2UnpackInfo_792, SIMDK1B2UnpackInfo_793, SIMDK1B2UnpackInfo_794, SIMDK1B2UnpackInfo_795,
			SIMDK1B2UnpackInfo_796, SIMDK1B2UnpackInfo_797, SIMDK1B2UnpackInfo_798, SIMDK1B2UnpackInfo_799,
			SIMDK1B2UnpackInfo_800, SIMDK1B2UnpackInfo_801, SIMDK1B2UnpackInfo_802, SIMDK1B2UnpackInfo_803,
			SIMDK1B2UnpackInfo_804, SIMDK1B2UnpackInfo_805, SIMDK1B2UnpackInfo_806, SIMDK1B2UnpackInfo_807,
			SIMDK1B2UnpackInfo_808, SIMDK1B2UnpackInfo_809, SIMDK1B2UnpackInfo_810, SIMDK1B2UnpackInfo_811,
			SIMDK1B2UnpackInfo_812, SIMDK1B2UnpackInfo_813, SIMDK1B2UnpackInfo_814, SIMDK1B2UnpackInfo_815,
			SIMDK1B2UnpackInfo_816, SIMDK1B2UnpackInfo_817, SIMDK1B2UnpackInfo_818, SIMDK1B2UnpackInfo_819,
			SIMDK1B2UnpackInfo_820, SIMDK1B2UnpackInfo_821, SIMDK1B2UnpackInfo_822, SIMDK1B2UnpackInfo_823,
			SIMDK1B2UnpackInfo_824, SIMDK1B2UnpackInfo_825, SIMDK1B2UnpackInfo_826, SIMDK1B2UnpackInfo_827,
			SIMDK1B2UnpackInfo_828, SIMDK1B2UnpackInfo_829, SIMDK1B2UnpackInfo_830, SIMDK1B2UnpackInfo_831,
			SIMDK1B2UnpackInfo_832, SIMDK1B2UnpackInfo_833, SIMDK1B2UnpackInfo_834, SIMDK1B2UnpackInfo_835,
			SIMDK1B2UnpackInfo_836, SIMDK1B2UnpackInfo_837, SIMDK1B2UnpackInfo_838, SIMDK1B2UnpackInfo_839,
			SIMDK1B2UnpackInfo_840, SIMDK1B2UnpackInfo_841, SIMDK1B2UnpackInfo_842, SIMDK1B2UnpackInfo_843,
			SIMDK1B2UnpackInfo_844, SIMDK1B2UnpackInfo_845, SIMDK1B2UnpackInfo_846, SIMDK1B2UnpackInfo_847,
			SIMDK1B2UnpackInfo_848, SIMDK1B2UnpackInfo_849, SIMDK1B2UnpackInfo_850, SIMDK1B2UnpackInfo_851,
			SIMDK1B2UnpackInfo_852, SIMDK1B2UnpackInfo_853, SIMDK1B2UnpackInfo_854, SIMDK1B2UnpackInfo_855,
			SIMDK1B2UnpackInfo_856, SIMDK1B2UnpackInfo_857, SIMDK1B2UnpackInfo_858, SIMDK1B2UnpackInfo_859,
			SIMDK1B2UnpackInfo_860, SIMDK1B2UnpackInfo_861, SIMDK1B2UnpackInfo_862, SIMDK1B2UnpackInfo_863,
			SIMDK1B2UnpackInfo_864, SIMDK1B2UnpackInfo_865, SIMDK1B2UnpackInfo_866, SIMDK1B2UnpackInfo_867,
			SIMDK1B2UnpackInfo_868, SIMDK1B2UnpackInfo_869, SIMDK1B2UnpackInfo_870, SIMDK1B2UnpackInfo_871,
			SIMDK1B2UnpackInfo_872, SIMDK1B2UnpackInfo_873, SIMDK1B2UnpackInfo_874, SIMDK1B2UnpackInfo_875,
			SIMDK1B2UnpackInfo_876, SIMDK1B2UnpackInfo_877, SIMDK1B2UnpackInfo_878, SIMDK1B2UnpackInfo_879,
			SIMDK1B2UnpackInfo_880, SIMDK1B2UnpackInfo_881, SIMDK1B2UnpackInfo_882, SIMDK1B2UnpackInfo_883,
			SIMDK1B2UnpackInfo_884, SIMDK1B2UnpackInfo_885, SIMDK1B2UnpackInfo_886, SIMDK1B2UnpackInfo_887,
			SIMDK1B2UnpackInfo_888, SIMDK1B2UnpackInfo_889, SIMDK1B2UnpackInfo_890, SIMDK1B2UnpackInfo_891,
			SIMDK1B2UnpackInfo_892, SIMDK1B2UnpackInfo_893, SIMDK1B2UnpackInfo_894, SIMDK1B2UnpackInfo_895,
			SIMDK1B2UnpackInfo_896, SIMDK1B2UnpackInfo_897, SIMDK1B2UnpackInfo_898, SIMDK1B2UnpackInfo_899,
			SIMDK1B2UnpackInfo_900, SIMDK1B2UnpackInfo_901, SIMDK1B2UnpackInfo_902, SIMDK1B2UnpackInfo_903,
			SIMDK1B2UnpackInfo_904, SIMDK1B2UnpackInfo_905, SIMDK1B2UnpackInfo_906, SIMDK1B2UnpackInfo_907,
			SIMDK1B2UnpackInfo_908, SIMDK1B2UnpackInfo_909, SIMDK1B2UnpackInfo_910, SIMDK1B2UnpackInfo_911,
			SIMDK1B2UnpackInfo_912, SIMDK1B2UnpackInfo_913, SIMDK1B2UnpackInfo_914, SIMDK1B2UnpackInfo_915,
			SIMDK1B2UnpackInfo_916, SIMDK1B2UnpackInfo_917, SIMDK1B2UnpackInfo_918, SIMDK1B2UnpackInfo_919,
			SIMDK1B2UnpackInfo_920, SIMDK1B2UnpackInfo_921, SIMDK1B2UnpackInfo_922, SIMDK1B2UnpackInfo_923,
			SIMDK1B2UnpackInfo_924, SIMDK1B2UnpackInfo_925, SIMDK1B2UnpackInfo_926, SIMDK1B2UnpackInfo_927,
			SIMDK1B2UnpackInfo_928, SIMDK1B2UnpackInfo_929, SIMDK1B2UnpackInfo_930, SIMDK1B2UnpackInfo_931,
			SIMDK1B2UnpackInfo_932, SIMDK1B2UnpackInfo_933, SIMDK1B2UnpackInfo_934, SIMDK1B2UnpackInfo_935,
			SIMDK1B2UnpackInfo_936, SIMDK1B2UnpackInfo_937, SIMDK1B2UnpackInfo_938, SIMDK1B2UnpackInfo_939,
			SIMDK1B2UnpackInfo_940, SIMDK1B2UnpackInfo_941, SIMDK1B2UnpackInfo_942, SIMDK1B2UnpackInfo_943,
			SIMDK1B2UnpackInfo_944, SIMDK1B2UnpackInfo_945, SIMDK1B2UnpackInfo_946, SIMDK1B2UnpackInfo_947,
			SIMDK1B2UnpackInfo_948, SIMDK1B2UnpackInfo_949, SIMDK1B2UnpackInfo_950, SIMDK1B2UnpackInfo_951,
			SIMDK1B2UnpackInfo_952, SIMDK1B2UnpackInfo_953, SIMDK1B2UnpackInfo_954, SIMDK1B2UnpackInfo_955,
			SIMDK1B2UnpackInfo_956, SIMDK1B2UnpackInfo_957, SIMDK1B2UnpackInfo_958, SIMDK1B2UnpackInfo_959,
			SIMDK1B2UnpackInfo_960, SIMDK1B2UnpackInfo_961, SIMDK1B2UnpackInfo_962, SIMDK1B2UnpackInfo_963,
			SIMDK1B2UnpackInfo_964, SIMDK1B2UnpackInfo_965, SIMDK1B2UnpackInfo_966, SIMDK1B2UnpackInfo_967,
			SIMDK1B2UnpackInfo_968, SIMDK1B2UnpackInfo_969, SIMDK1B2UnpackInfo_970, SIMDK1B2UnpackInfo_971,
			SIMDK1B2UnpackInfo_972, SIMDK1B2UnpackInfo_973, SIMDK1B2UnpackInfo_974, SIMDK1B2UnpackInfo_975,
			SIMDK1B2UnpackInfo_976, SIMDK1B2UnpackInfo_977, SIMDK1B2UnpackInfo_978, SIMDK1B2UnpackInfo_979,
			SIMDK1B2UnpackInfo_980, SIMDK1B2UnpackInfo_981, SIMDK1B2UnpackInfo_982, SIMDK1B2UnpackInfo_983,
			SIMDK1B2UnpackInfo_984, SIMDK1B2UnpackInfo_985, SIMDK1B2UnpackInfo_986, SIMDK1B2UnpackInfo_987,
			SIMDK1B2UnpackInfo_988, SIMDK1B2UnpackInfo_989, SIMDK1B2UnpackInfo_990, SIMDK1B2UnpackInfo_991,
			SIMDK1B2UnpackInfo_992, SIMDK1B2UnpackInfo_993, SIMDK1B2UnpackInfo_994, SIMDK1B2UnpackInfo_995,
			SIMDK1B2UnpackInfo_996, SIMDK1B2UnpackInfo_997, SIMDK1B2UnpackInfo_998, SIMDK1B2UnpackInfo_999,
			SIMDK1B2UnpackInfo_1000, SIMDK1B2UnpackInfo_1001, SIMDK1B2UnpackInfo_1002, SIMDK1B2UnpackInfo_1003,
			SIMDK1B2UnpackInfo_1004, SIMDK1B2UnpackInfo_1005, SIMDK1B2UnpackInfo_1006, SIMDK1B2UnpackInfo_1007,
			SIMDK1B2UnpackInfo_1008, SIMDK1B2UnpackInfo_1009, SIMDK1B2UnpackInfo_1010, SIMDK1B2UnpackInfo_1011,
			SIMDK1B2UnpackInfo_1012, SIMDK1B2UnpackInfo_1013, SIMDK1B2UnpackInfo_1014, SIMDK1B2UnpackInfo_1015,
			SIMDK1B2UnpackInfo_1016, SIMDK1B2UnpackInfo_1017, SIMDK1B2UnpackInfo_1018, SIMDK1B2UnpackInfo_1019,
			SIMDK1B2UnpackInfo_1020, SIMDK1B2UnpackInfo_1021, SIMDK1B2UnpackInfo_1022, SIMDK1B2UnpackInfo_1023
};

}
}

#endif

#endif /* SIMD_KSCHEME_1BIT_BINARY2_UNPACK_HPP_ */


