/*
 * SIMD_KAFOR_pack.hpp
 *
 *  Created on: 2013-11-18
 *      Author: zxd
 */

#ifndef SIMD_KAFOR_PACK_HPP_
#define SIMD_KAFOR_PACK_HPP_

namespace paradise {
namespace index {

struct SIMD_KAFORPackInfo {
	void (*m_subFunc)(uint32_t *des, const uint32_t *src);
	uint8_t m_offset;
	uint8_t m_newOffset;
	uint16_t m_wordSkipped;
	uint16_t m_intEncoded;
};

template<typename T>
void SIMD_KAFOR_pack_8len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_13bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_13bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_13bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_13bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_14bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_14bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_14bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_14bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_15bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_15bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_15bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_15bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_17bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_17bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_17bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_17bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_18bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_18bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_18bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_18bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_19bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_19bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_19bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_19bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_21bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_21bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_21bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_21bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_22bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_22bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_22bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_22bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_23bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_23bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_23bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_23bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_24bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_24bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_24bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_24bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_25bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_25bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_25bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_25bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_26bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_26bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_26bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_26bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_27bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_27bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_27bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_27bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_28bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_28bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_28bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_28bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_29bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_29bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_29bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_29bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_30bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_30bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_30bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_30bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_31bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_31bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_31bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_31bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_8len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_13bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_13bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_13bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_13bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_14bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_14bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_14bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_14bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_15bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_15bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_15bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_15bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_17bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_17bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_17bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_17bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_18bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_18bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_18bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_18bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_19bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_19bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_19bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_19bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_21bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_21bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_21bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_21bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_22bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_22bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_22bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_22bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_23bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_23bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_23bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_23bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_24bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_24bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_24bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_24bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_25bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_25bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_25bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_25bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_26bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_26bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_26bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_26bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_27bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_27bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_27bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_27bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_28bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_28bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_28bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_28bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_29bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_29bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_29bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_29bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_30bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_30bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_30bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_30bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_31bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_31bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_31bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_31bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_16len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $29,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[16])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[16])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[16])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[16])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[16])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $27,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[20])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[20])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[16])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[16])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[20])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $26,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[20])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[24])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[24])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[16])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[20])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[24])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $25,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[4])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[8])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[12])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[16])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[20])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[24])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %1,%%xmm3\n"
			"movdqu %2,%%xmm4\n"
			"movdqu %3,%%xmm5\n"
			"movdqu %4,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[28])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $23,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $22,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[40]), "=m"(des[44])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $21,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[40]), "=m"(des[44])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[4]), "=m"(des[8])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[40]), "=m"(des[44])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[44]), "=m"(des[48])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[44]), "=m"(des[48])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_13bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[12]), "=m"(des[16])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[44]), "=m"(des[48])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_13bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[40]), "=m"(des[44])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_13bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[40]), "=m"(des[44])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_13bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $19,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[48]), "=m"(des[52])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_14bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[20]), "=m"(des[24])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[48]), "=m"(des[52])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_14bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[28]), "=m"(des[32])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_14bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[36]), "=m"(des[40])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[44]), "=m"(des[48])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_14bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[44]), "=m"(des[48])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[52]), "=m"(des[56])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_15bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[52]), "=m"(des[56])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_15bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_15bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_15bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[40]), "=m"(des[44])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[48]), "=m"(des[52])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $17,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[8]), "=m"(des[12])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[16]), "=m"(des[20])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[24]), "=m"(des[28])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[32]), "=m"(des[36])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[40]), "=m"(des[44])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[48]), "=m"(des[52])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %2,%%xmm3\n"
			"movdqu %3,%%xmm4\n"
			"movdqu %4,%%xmm5\n"
			"movdqu %5,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[56]), "=m"(des[60])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_17bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_17bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_17bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_17bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_18bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_18bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_18bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_18bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_19bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_19bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_19bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_19bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_21bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_21bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_21bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_21bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_22bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_22bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_22bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_22bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_23bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[8]), "=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_23bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_23bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_23bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_24bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %3,%%xmm3\n"
			"movdqu %4,%%xmm4\n"
			"movdqu %5,%%xmm5\n"
			"movdqu %6,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_24bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_24bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_24bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_25bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_25bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_25bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_25bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_26bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_26bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_26bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_26bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_27bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[24]), "=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_27bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_27bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_27bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_28bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_28bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108]), "=m"(des[112])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_28bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[100]), "=m"(des[104]), "=m"(des[108]), "=m"(des[112])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_28bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[100]), "=m"(des[104]), "=m"(des[108]), "=m"(des[112])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_29bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[40]), "=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[100]), "=m"(des[104]), "=m"(des[108]), "=m"(des[112])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_29bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[56]), "=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[100]), "=m"(des[104]), "=m"(des[108]), "=m"(des[112]), "=m"(des[116])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_29bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[100]), "=m"(des[104]), "=m"(des[108]), "=m"(des[112]), "=m"(des[116])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_29bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[104]), "=m"(des[108]), "=m"(des[112]), "=m"(des[116])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_30bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[72]), "=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[104]), "=m"(des[108]), "=m"(des[112]), "=m"(des[116])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_30bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[88]), "=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[104]), "=m"(des[108]), "=m"(des[112]), "=m"(des[116]), "=m"(des[120])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_30bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[104]), "=m"(des[108]), "=m"(des[112]), "=m"(des[116]), "=m"(des[120])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_30bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[108]), "=m"(des[112]), "=m"(des[116]), "=m"(des[120])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_31bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[12]), "=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[28]), "=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[108]), "=m"(des[112]), "=m"(des[116]), "=m"(des[120])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_31bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[44]), "=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[60]), "=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[108]), "=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_31bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[76]), "=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[92]), "=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[108]), "=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_31bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $31,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[108]), "=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"pxor %%xmm7,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108]), "=m"(des[112])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124]), "=m"(des[128])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108]), "=m"(des[112])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124]), "=m"(des[128])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_pack_32len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12]), "=m"(des[16])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28]), "=m"(des[32])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44]), "=m"(des[48])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60]), "=m"(des[64])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76]), "=m"(des[80])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92]), "=m"(des[96])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108]), "=m"(des[112])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %5,%%xmm3\n"
			"movdqu %6,%%xmm4\n"
			"movdqu %7,%%xmm5\n"
			"movdqu %8,%%xmm6\n"
			"movdqu %0,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $0,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%4\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124]), "=m"(des[128])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}


static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_0 = { SIMD_KAFOR_pack_8len_1bw_0offset<uint32_t>, 0, 8, 0, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_1 = { SIMD_KAFOR_pack_8len_1bw_8offset<uint32_t>, 8, 16, 0, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_2 = { SIMD_KAFOR_pack_8len_1bw_16offset<uint32_t>, 16, 24, 0, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_3 = { SIMD_KAFOR_pack_8len_1bw_24offset<uint32_t>, 24, 0, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_4 = { SIMD_KAFOR_pack_8len_2bw_0offset<uint32_t>, 0, 16, 0, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_5 = { SIMD_KAFOR_pack_8len_2bw_8offset<uint32_t>, 8, 24, 0, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_6 = { SIMD_KAFOR_pack_8len_2bw_16offset<uint32_t>, 16, 0, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_7 = { SIMD_KAFOR_pack_8len_2bw_24offset<uint32_t>, 24, 8, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_8 = { SIMD_KAFOR_pack_8len_3bw_0offset<uint32_t>, 0, 24, 0, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_9 = { SIMD_KAFOR_pack_8len_3bw_8offset<uint32_t>, 8, 0, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_10 = { SIMD_KAFOR_pack_8len_3bw_16offset<uint32_t>, 16, 8, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_11 = { SIMD_KAFOR_pack_8len_3bw_24offset<uint32_t>, 24, 16, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_12 = { SIMD_KAFOR_pack_8len_4bw_0offset<uint32_t>, 0, 0, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_13 = { SIMD_KAFOR_pack_8len_4bw_8offset<uint32_t>, 8, 8, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_14 = { SIMD_KAFOR_pack_8len_4bw_16offset<uint32_t>, 16, 16, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_15 = { SIMD_KAFOR_pack_8len_4bw_24offset<uint32_t>, 24, 24, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_16 = { SIMD_KAFOR_pack_8len_5bw_0offset<uint32_t>, 0, 8, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_17 = { SIMD_KAFOR_pack_8len_5bw_8offset<uint32_t>, 8, 16, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_18 = { SIMD_KAFOR_pack_8len_5bw_16offset<uint32_t>, 16, 24, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_19 = { SIMD_KAFOR_pack_8len_5bw_24offset<uint32_t>, 24, 0, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_20 = { SIMD_KAFOR_pack_8len_6bw_0offset<uint32_t>, 0, 16, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_21 = { SIMD_KAFOR_pack_8len_6bw_8offset<uint32_t>, 8, 24, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_22 = { SIMD_KAFOR_pack_8len_6bw_16offset<uint32_t>, 16, 0, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_23 = { SIMD_KAFOR_pack_8len_6bw_24offset<uint32_t>, 24, 8, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_24 = { SIMD_KAFOR_pack_8len_7bw_0offset<uint32_t>, 0, 24, 4, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_25 = { SIMD_KAFOR_pack_8len_7bw_8offset<uint32_t>, 8, 0, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_26 = { SIMD_KAFOR_pack_8len_7bw_16offset<uint32_t>, 16, 8, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_27 = { SIMD_KAFOR_pack_8len_7bw_24offset<uint32_t>, 24, 16, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_28 = { SIMD_KAFOR_pack_8len_8bw_0offset<uint32_t>, 0, 0, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_29 = { SIMD_KAFOR_pack_8len_8bw_8offset<uint32_t>, 8, 8, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_30 = { SIMD_KAFOR_pack_8len_8bw_16offset<uint32_t>, 16, 16, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_31 = { SIMD_KAFOR_pack_8len_8bw_24offset<uint32_t>, 24, 24, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_32 = { SIMD_KAFOR_pack_8len_9bw_0offset<uint32_t>, 0, 8, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_33 = { SIMD_KAFOR_pack_8len_9bw_8offset<uint32_t>, 8, 16, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_34 = { SIMD_KAFOR_pack_8len_9bw_16offset<uint32_t>, 16, 24, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_35 = { SIMD_KAFOR_pack_8len_9bw_24offset<uint32_t>, 24, 0, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_36 = { SIMD_KAFOR_pack_8len_10bw_0offset<uint32_t>, 0, 16, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_37 = { SIMD_KAFOR_pack_8len_10bw_8offset<uint32_t>, 8, 24, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_38 = { SIMD_KAFOR_pack_8len_10bw_16offset<uint32_t>, 16, 0, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_39 = { SIMD_KAFOR_pack_8len_10bw_24offset<uint32_t>, 24, 8, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_40 = { SIMD_KAFOR_pack_8len_11bw_0offset<uint32_t>, 0, 24, 8, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_41 = { SIMD_KAFOR_pack_8len_11bw_8offset<uint32_t>, 8, 0, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_42 = { SIMD_KAFOR_pack_8len_11bw_16offset<uint32_t>, 16, 8, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_43 = { SIMD_KAFOR_pack_8len_11bw_24offset<uint32_t>, 24, 16, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_44 = { SIMD_KAFOR_pack_8len_12bw_0offset<uint32_t>, 0, 0, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_45 = { SIMD_KAFOR_pack_8len_12bw_8offset<uint32_t>, 8, 8, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_46 = { SIMD_KAFOR_pack_8len_12bw_16offset<uint32_t>, 16, 16, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_47 = { SIMD_KAFOR_pack_8len_12bw_24offset<uint32_t>, 24, 24, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_48 = { SIMD_KAFOR_pack_8len_13bw_0offset<uint32_t>, 0, 8, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_49 = { SIMD_KAFOR_pack_8len_13bw_8offset<uint32_t>, 8, 16, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_50 = { SIMD_KAFOR_pack_8len_13bw_16offset<uint32_t>, 16, 24, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_51 = { SIMD_KAFOR_pack_8len_13bw_24offset<uint32_t>, 24, 0, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_52 = { SIMD_KAFOR_pack_8len_14bw_0offset<uint32_t>, 0, 16, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_53 = { SIMD_KAFOR_pack_8len_14bw_8offset<uint32_t>, 8, 24, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_54 = { SIMD_KAFOR_pack_8len_14bw_16offset<uint32_t>, 16, 0, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_55 = { SIMD_KAFOR_pack_8len_14bw_24offset<uint32_t>, 24, 8, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_56 = { SIMD_KAFOR_pack_8len_15bw_0offset<uint32_t>, 0, 24, 12, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_57 = { SIMD_KAFOR_pack_8len_15bw_8offset<uint32_t>, 8, 0, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_58 = { SIMD_KAFOR_pack_8len_15bw_16offset<uint32_t>, 16, 8, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_59 = { SIMD_KAFOR_pack_8len_15bw_24offset<uint32_t>, 24, 16, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_60 = { SIMD_KAFOR_pack_8len_16bw_0offset<uint32_t>, 0, 0, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_61 = { SIMD_KAFOR_pack_8len_16bw_8offset<uint32_t>, 8, 8, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_62 = { SIMD_KAFOR_pack_8len_16bw_16offset<uint32_t>, 16, 16, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_63 = { SIMD_KAFOR_pack_8len_16bw_24offset<uint32_t>, 24, 24, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_64 = { SIMD_KAFOR_pack_8len_17bw_0offset<uint32_t>, 0, 8, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_65 = { SIMD_KAFOR_pack_8len_17bw_8offset<uint32_t>, 8, 16, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_66 = { SIMD_KAFOR_pack_8len_17bw_16offset<uint32_t>, 16, 24, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_67 = { SIMD_KAFOR_pack_8len_17bw_24offset<uint32_t>, 24, 0, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_68 = { SIMD_KAFOR_pack_8len_18bw_0offset<uint32_t>, 0, 16, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_69 = { SIMD_KAFOR_pack_8len_18bw_8offset<uint32_t>, 8, 24, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_70 = { SIMD_KAFOR_pack_8len_18bw_16offset<uint32_t>, 16, 0, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_71 = { SIMD_KAFOR_pack_8len_18bw_24offset<uint32_t>, 24, 8, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_72 = { SIMD_KAFOR_pack_8len_19bw_0offset<uint32_t>, 0, 24, 16, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_73 = { SIMD_KAFOR_pack_8len_19bw_8offset<uint32_t>, 8, 0, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_74 = { SIMD_KAFOR_pack_8len_19bw_16offset<uint32_t>, 16, 8, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_75 = { SIMD_KAFOR_pack_8len_19bw_24offset<uint32_t>, 24, 16, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_76 = { SIMD_KAFOR_pack_8len_20bw_0offset<uint32_t>, 0, 0, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_77 = { SIMD_KAFOR_pack_8len_20bw_8offset<uint32_t>, 8, 8, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_78 = { SIMD_KAFOR_pack_8len_20bw_16offset<uint32_t>, 16, 16, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_79 = { SIMD_KAFOR_pack_8len_20bw_24offset<uint32_t>, 24, 24, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_80 = { SIMD_KAFOR_pack_8len_21bw_0offset<uint32_t>, 0, 8, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_81 = { SIMD_KAFOR_pack_8len_21bw_8offset<uint32_t>, 8, 16, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_82 = { SIMD_KAFOR_pack_8len_21bw_16offset<uint32_t>, 16, 24, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_83 = { SIMD_KAFOR_pack_8len_21bw_24offset<uint32_t>, 24, 0, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_84 = { SIMD_KAFOR_pack_8len_22bw_0offset<uint32_t>, 0, 16, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_85 = { SIMD_KAFOR_pack_8len_22bw_8offset<uint32_t>, 8, 24, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_86 = { SIMD_KAFOR_pack_8len_22bw_16offset<uint32_t>, 16, 0, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_87 = { SIMD_KAFOR_pack_8len_22bw_24offset<uint32_t>, 24, 8, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_88 = { SIMD_KAFOR_pack_8len_23bw_0offset<uint32_t>, 0, 24, 20, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_89 = { SIMD_KAFOR_pack_8len_23bw_8offset<uint32_t>, 8, 0, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_90 = { SIMD_KAFOR_pack_8len_23bw_16offset<uint32_t>, 16, 8, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_91 = { SIMD_KAFOR_pack_8len_23bw_24offset<uint32_t>, 24, 16, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_92 = { SIMD_KAFOR_pack_8len_24bw_0offset<uint32_t>, 0, 0, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_93 = { SIMD_KAFOR_pack_8len_24bw_8offset<uint32_t>, 8, 8, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_94 = { SIMD_KAFOR_pack_8len_24bw_16offset<uint32_t>, 16, 16, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_95 = { SIMD_KAFOR_pack_8len_24bw_24offset<uint32_t>, 24, 24, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_96 = { SIMD_KAFOR_pack_8len_25bw_0offset<uint32_t>, 0, 8, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_97 = { SIMD_KAFOR_pack_8len_25bw_8offset<uint32_t>, 8, 16, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_98 = { SIMD_KAFOR_pack_8len_25bw_16offset<uint32_t>, 16, 24, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_99 = { SIMD_KAFOR_pack_8len_25bw_24offset<uint32_t>, 24, 0, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_100 = { SIMD_KAFOR_pack_8len_26bw_0offset<uint32_t>, 0, 16, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_101 = { SIMD_KAFOR_pack_8len_26bw_8offset<uint32_t>, 8, 24, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_102 = { SIMD_KAFOR_pack_8len_26bw_16offset<uint32_t>, 16, 0, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_103 = { SIMD_KAFOR_pack_8len_26bw_24offset<uint32_t>, 24, 8, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_104 = { SIMD_KAFOR_pack_8len_27bw_0offset<uint32_t>, 0, 24, 24, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_105 = { SIMD_KAFOR_pack_8len_27bw_8offset<uint32_t>, 8, 0, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_106 = { SIMD_KAFOR_pack_8len_27bw_16offset<uint32_t>, 16, 8, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_107 = { SIMD_KAFOR_pack_8len_27bw_24offset<uint32_t>, 24, 16, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_108 = { SIMD_KAFOR_pack_8len_28bw_0offset<uint32_t>, 0, 0, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_109 = { SIMD_KAFOR_pack_8len_28bw_8offset<uint32_t>, 8, 8, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_110 = { SIMD_KAFOR_pack_8len_28bw_16offset<uint32_t>, 16, 16, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_111 = { SIMD_KAFOR_pack_8len_28bw_24offset<uint32_t>, 24, 24, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_112 = { SIMD_KAFOR_pack_8len_29bw_0offset<uint32_t>, 0, 8, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_113 = { SIMD_KAFOR_pack_8len_29bw_8offset<uint32_t>, 8, 16, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_114 = { SIMD_KAFOR_pack_8len_29bw_16offset<uint32_t>, 16, 24, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_115 = { SIMD_KAFOR_pack_8len_29bw_24offset<uint32_t>, 24, 0, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_116 = { SIMD_KAFOR_pack_8len_30bw_0offset<uint32_t>, 0, 16, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_117 = { SIMD_KAFOR_pack_8len_30bw_8offset<uint32_t>, 8, 24, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_118 = { SIMD_KAFOR_pack_8len_30bw_16offset<uint32_t>, 16, 0, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_119 = { SIMD_KAFOR_pack_8len_30bw_24offset<uint32_t>, 24, 8, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_120 = { SIMD_KAFOR_pack_8len_31bw_0offset<uint32_t>, 0, 24, 28, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_121 = { SIMD_KAFOR_pack_8len_31bw_8offset<uint32_t>, 8, 0, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_122 = { SIMD_KAFOR_pack_8len_31bw_16offset<uint32_t>, 16, 8, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_123 = { SIMD_KAFOR_pack_8len_31bw_24offset<uint32_t>, 24, 16, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_124 = { SIMD_KAFOR_pack_8len_32bw_0offset<uint32_t>, 0, 0, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_125 = { SIMD_KAFOR_pack_8len_32bw_8offset<uint32_t>, 8, 8, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_126 = { SIMD_KAFOR_pack_8len_32bw_16offset<uint32_t>, 16, 16, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_127 = { SIMD_KAFOR_pack_8len_32bw_24offset<uint32_t>, 24, 24, 32, 32, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_128 = { SIMD_KAFOR_pack_16len_1bw_0offset<uint32_t>, 0, 16, 0, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_129 = { SIMD_KAFOR_pack_16len_1bw_8offset<uint32_t>, 8, 24, 0, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_130 = { SIMD_KAFOR_pack_16len_1bw_16offset<uint32_t>, 16, 0, 4, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_131 = { SIMD_KAFOR_pack_16len_1bw_24offset<uint32_t>, 24, 8, 4, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_132 = { SIMD_KAFOR_pack_16len_2bw_0offset<uint32_t>, 0, 0, 4, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_133 = { SIMD_KAFOR_pack_16len_2bw_8offset<uint32_t>, 8, 8, 4, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_134 = { SIMD_KAFOR_pack_16len_2bw_16offset<uint32_t>, 16, 16, 4, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_135 = { SIMD_KAFOR_pack_16len_2bw_24offset<uint32_t>, 24, 24, 4, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_136 = { SIMD_KAFOR_pack_16len_3bw_0offset<uint32_t>, 0, 16, 4, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_137 = { SIMD_KAFOR_pack_16len_3bw_8offset<uint32_t>, 8, 24, 4, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_138 = { SIMD_KAFOR_pack_16len_3bw_16offset<uint32_t>, 16, 0, 8, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_139 = { SIMD_KAFOR_pack_16len_3bw_24offset<uint32_t>, 24, 8, 8, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_140 = { SIMD_KAFOR_pack_16len_4bw_0offset<uint32_t>, 0, 0, 8, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_141 = { SIMD_KAFOR_pack_16len_4bw_8offset<uint32_t>, 8, 8, 8, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_142 = { SIMD_KAFOR_pack_16len_4bw_16offset<uint32_t>, 16, 16, 8, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_143 = { SIMD_KAFOR_pack_16len_4bw_24offset<uint32_t>, 24, 24, 8, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_144 = { SIMD_KAFOR_pack_16len_5bw_0offset<uint32_t>, 0, 16, 8, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_145 = { SIMD_KAFOR_pack_16len_5bw_8offset<uint32_t>, 8, 24, 8, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_146 = { SIMD_KAFOR_pack_16len_5bw_16offset<uint32_t>, 16, 0, 12, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_147 = { SIMD_KAFOR_pack_16len_5bw_24offset<uint32_t>, 24, 8, 12, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_148 = { SIMD_KAFOR_pack_16len_6bw_0offset<uint32_t>, 0, 0, 12, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_149 = { SIMD_KAFOR_pack_16len_6bw_8offset<uint32_t>, 8, 8, 12, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_150 = { SIMD_KAFOR_pack_16len_6bw_16offset<uint32_t>, 16, 16, 12, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_151 = { SIMD_KAFOR_pack_16len_6bw_24offset<uint32_t>, 24, 24, 12, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_152 = { SIMD_KAFOR_pack_16len_7bw_0offset<uint32_t>, 0, 16, 12, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_153 = { SIMD_KAFOR_pack_16len_7bw_8offset<uint32_t>, 8, 24, 12, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_154 = { SIMD_KAFOR_pack_16len_7bw_16offset<uint32_t>, 16, 0, 16, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_155 = { SIMD_KAFOR_pack_16len_7bw_24offset<uint32_t>, 24, 8, 16, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_156 = { SIMD_KAFOR_pack_16len_8bw_0offset<uint32_t>, 0, 0, 16, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_157 = { SIMD_KAFOR_pack_16len_8bw_8offset<uint32_t>, 8, 8, 16, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_158 = { SIMD_KAFOR_pack_16len_8bw_16offset<uint32_t>, 16, 16, 16, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_159 = { SIMD_KAFOR_pack_16len_8bw_24offset<uint32_t>, 24, 24, 16, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_160 = { SIMD_KAFOR_pack_16len_9bw_0offset<uint32_t>, 0, 16, 16, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_161 = { SIMD_KAFOR_pack_16len_9bw_8offset<uint32_t>, 8, 24, 16, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_162 = { SIMD_KAFOR_pack_16len_9bw_16offset<uint32_t>, 16, 0, 20, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_163 = { SIMD_KAFOR_pack_16len_9bw_24offset<uint32_t>, 24, 8, 20, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_164 = { SIMD_KAFOR_pack_16len_10bw_0offset<uint32_t>, 0, 0, 20, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_165 = { SIMD_KAFOR_pack_16len_10bw_8offset<uint32_t>, 8, 8, 20, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_166 = { SIMD_KAFOR_pack_16len_10bw_16offset<uint32_t>, 16, 16, 20, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_167 = { SIMD_KAFOR_pack_16len_10bw_24offset<uint32_t>, 24, 24, 20, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_168 = { SIMD_KAFOR_pack_16len_11bw_0offset<uint32_t>, 0, 16, 20, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_169 = { SIMD_KAFOR_pack_16len_11bw_8offset<uint32_t>, 8, 24, 20, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_170 = { SIMD_KAFOR_pack_16len_11bw_16offset<uint32_t>, 16, 0, 24, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_171 = { SIMD_KAFOR_pack_16len_11bw_24offset<uint32_t>, 24, 8, 24, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_172 = { SIMD_KAFOR_pack_16len_12bw_0offset<uint32_t>, 0, 0, 24, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_173 = { SIMD_KAFOR_pack_16len_12bw_8offset<uint32_t>, 8, 8, 24, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_174 = { SIMD_KAFOR_pack_16len_12bw_16offset<uint32_t>, 16, 16, 24, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_175 = { SIMD_KAFOR_pack_16len_12bw_24offset<uint32_t>, 24, 24, 24, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_176 = { SIMD_KAFOR_pack_16len_13bw_0offset<uint32_t>, 0, 16, 24, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_177 = { SIMD_KAFOR_pack_16len_13bw_8offset<uint32_t>, 8, 24, 24, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_178 = { SIMD_KAFOR_pack_16len_13bw_16offset<uint32_t>, 16, 0, 28, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_179 = { SIMD_KAFOR_pack_16len_13bw_24offset<uint32_t>, 24, 8, 28, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_180 = { SIMD_KAFOR_pack_16len_14bw_0offset<uint32_t>, 0, 0, 28, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_181 = { SIMD_KAFOR_pack_16len_14bw_8offset<uint32_t>, 8, 8, 28, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_182 = { SIMD_KAFOR_pack_16len_14bw_16offset<uint32_t>, 16, 16, 28, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_183 = { SIMD_KAFOR_pack_16len_14bw_24offset<uint32_t>, 24, 24, 28, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_184 = { SIMD_KAFOR_pack_16len_15bw_0offset<uint32_t>, 0, 16, 28, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_185 = { SIMD_KAFOR_pack_16len_15bw_8offset<uint32_t>, 8, 24, 28, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_186 = { SIMD_KAFOR_pack_16len_15bw_16offset<uint32_t>, 16, 0, 32, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_187 = { SIMD_KAFOR_pack_16len_15bw_24offset<uint32_t>, 24, 8, 32, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_188 = { SIMD_KAFOR_pack_16len_16bw_0offset<uint32_t>, 0, 0, 32, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_189 = { SIMD_KAFOR_pack_16len_16bw_8offset<uint32_t>, 8, 8, 32, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_190 = { SIMD_KAFOR_pack_16len_16bw_16offset<uint32_t>, 16, 16, 32, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_191 = { SIMD_KAFOR_pack_16len_16bw_24offset<uint32_t>, 24, 24, 32, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_192 = { SIMD_KAFOR_pack_16len_17bw_0offset<uint32_t>, 0, 16, 32, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_193 = { SIMD_KAFOR_pack_16len_17bw_8offset<uint32_t>, 8, 24, 32, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_194 = { SIMD_KAFOR_pack_16len_17bw_16offset<uint32_t>, 16, 0, 36, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_195 = { SIMD_KAFOR_pack_16len_17bw_24offset<uint32_t>, 24, 8, 36, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_196 = { SIMD_KAFOR_pack_16len_18bw_0offset<uint32_t>, 0, 0, 36, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_197 = { SIMD_KAFOR_pack_16len_18bw_8offset<uint32_t>, 8, 8, 36, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_198 = { SIMD_KAFOR_pack_16len_18bw_16offset<uint32_t>, 16, 16, 36, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_199 = { SIMD_KAFOR_pack_16len_18bw_24offset<uint32_t>, 24, 24, 36, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_200 = { SIMD_KAFOR_pack_16len_19bw_0offset<uint32_t>, 0, 16, 36, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_201 = { SIMD_KAFOR_pack_16len_19bw_8offset<uint32_t>, 8, 24, 36, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_202 = { SIMD_KAFOR_pack_16len_19bw_16offset<uint32_t>, 16, 0, 40, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_203 = { SIMD_KAFOR_pack_16len_19bw_24offset<uint32_t>, 24, 8, 40, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_204 = { SIMD_KAFOR_pack_16len_20bw_0offset<uint32_t>, 0, 0, 40, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_205 = { SIMD_KAFOR_pack_16len_20bw_8offset<uint32_t>, 8, 8, 40, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_206 = { SIMD_KAFOR_pack_16len_20bw_16offset<uint32_t>, 16, 16, 40, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_207 = { SIMD_KAFOR_pack_16len_20bw_24offset<uint32_t>, 24, 24, 40, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_208 = { SIMD_KAFOR_pack_16len_21bw_0offset<uint32_t>, 0, 16, 40, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_209 = { SIMD_KAFOR_pack_16len_21bw_8offset<uint32_t>, 8, 24, 40, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_210 = { SIMD_KAFOR_pack_16len_21bw_16offset<uint32_t>, 16, 0, 44, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_211 = { SIMD_KAFOR_pack_16len_21bw_24offset<uint32_t>, 24, 8, 44, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_212 = { SIMD_KAFOR_pack_16len_22bw_0offset<uint32_t>, 0, 0, 44, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_213 = { SIMD_KAFOR_pack_16len_22bw_8offset<uint32_t>, 8, 8, 44, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_214 = { SIMD_KAFOR_pack_16len_22bw_16offset<uint32_t>, 16, 16, 44, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_215 = { SIMD_KAFOR_pack_16len_22bw_24offset<uint32_t>, 24, 24, 44, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_216 = { SIMD_KAFOR_pack_16len_23bw_0offset<uint32_t>, 0, 16, 44, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_217 = { SIMD_KAFOR_pack_16len_23bw_8offset<uint32_t>, 8, 24, 44, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_218 = { SIMD_KAFOR_pack_16len_23bw_16offset<uint32_t>, 16, 0, 48, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_219 = { SIMD_KAFOR_pack_16len_23bw_24offset<uint32_t>, 24, 8, 48, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_220 = { SIMD_KAFOR_pack_16len_24bw_0offset<uint32_t>, 0, 0, 48, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_221 = { SIMD_KAFOR_pack_16len_24bw_8offset<uint32_t>, 8, 8, 48, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_222 = { SIMD_KAFOR_pack_16len_24bw_16offset<uint32_t>, 16, 16, 48, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_223 = { SIMD_KAFOR_pack_16len_24bw_24offset<uint32_t>, 24, 24, 48, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_224 = { SIMD_KAFOR_pack_16len_25bw_0offset<uint32_t>, 0, 16, 48, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_225 = { SIMD_KAFOR_pack_16len_25bw_8offset<uint32_t>, 8, 24, 48, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_226 = { SIMD_KAFOR_pack_16len_25bw_16offset<uint32_t>, 16, 0, 52, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_227 = { SIMD_KAFOR_pack_16len_25bw_24offset<uint32_t>, 24, 8, 52, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_228 = { SIMD_KAFOR_pack_16len_26bw_0offset<uint32_t>, 0, 0, 52, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_229 = { SIMD_KAFOR_pack_16len_26bw_8offset<uint32_t>, 8, 8, 52, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_230 = { SIMD_KAFOR_pack_16len_26bw_16offset<uint32_t>, 16, 16, 52, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_231 = { SIMD_KAFOR_pack_16len_26bw_24offset<uint32_t>, 24, 24, 52, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_232 = { SIMD_KAFOR_pack_16len_27bw_0offset<uint32_t>, 0, 16, 52, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_233 = { SIMD_KAFOR_pack_16len_27bw_8offset<uint32_t>, 8, 24, 52, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_234 = { SIMD_KAFOR_pack_16len_27bw_16offset<uint32_t>, 16, 0, 56, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_235 = { SIMD_KAFOR_pack_16len_27bw_24offset<uint32_t>, 24, 8, 56, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_236 = { SIMD_KAFOR_pack_16len_28bw_0offset<uint32_t>, 0, 0, 56, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_237 = { SIMD_KAFOR_pack_16len_28bw_8offset<uint32_t>, 8, 8, 56, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_238 = { SIMD_KAFOR_pack_16len_28bw_16offset<uint32_t>, 16, 16, 56, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_239 = { SIMD_KAFOR_pack_16len_28bw_24offset<uint32_t>, 24, 24, 56, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_240 = { SIMD_KAFOR_pack_16len_29bw_0offset<uint32_t>, 0, 16, 56, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_241 = { SIMD_KAFOR_pack_16len_29bw_8offset<uint32_t>, 8, 24, 56, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_242 = { SIMD_KAFOR_pack_16len_29bw_16offset<uint32_t>, 16, 0, 60, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_243 = { SIMD_KAFOR_pack_16len_29bw_24offset<uint32_t>, 24, 8, 60, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_244 = { SIMD_KAFOR_pack_16len_30bw_0offset<uint32_t>, 0, 0, 60, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_245 = { SIMD_KAFOR_pack_16len_30bw_8offset<uint32_t>, 8, 8, 60, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_246 = { SIMD_KAFOR_pack_16len_30bw_16offset<uint32_t>, 16, 16, 60, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_247 = { SIMD_KAFOR_pack_16len_30bw_24offset<uint32_t>, 24, 24, 60, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_248 = { SIMD_KAFOR_pack_16len_31bw_0offset<uint32_t>, 0, 16, 60, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_249 = { SIMD_KAFOR_pack_16len_31bw_8offset<uint32_t>, 8, 24, 60, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_250 = { SIMD_KAFOR_pack_16len_31bw_16offset<uint32_t>, 16, 0, 64, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_251 = { SIMD_KAFOR_pack_16len_31bw_24offset<uint32_t>, 24, 8, 64, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_252 = { SIMD_KAFOR_pack_16len_32bw_0offset<uint32_t>, 0, 0, 64, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_253 = { SIMD_KAFOR_pack_16len_32bw_8offset<uint32_t>, 8, 8, 64, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_254 = { SIMD_KAFOR_pack_16len_32bw_16offset<uint32_t>, 16, 16, 64, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_255 = { SIMD_KAFOR_pack_16len_32bw_24offset<uint32_t>, 24, 24, 64, 64, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_256 = { SIMD_KAFOR_pack_32len_1bw_0offset<uint32_t>, 0, 0, 4, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_257 = { SIMD_KAFOR_pack_32len_1bw_8offset<uint32_t>, 8, 8, 4, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_258 = { SIMD_KAFOR_pack_32len_1bw_16offset<uint32_t>, 16, 16, 4, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_259 = { SIMD_KAFOR_pack_32len_1bw_24offset<uint32_t>, 24, 24, 4, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_260 = { SIMD_KAFOR_pack_32len_2bw_0offset<uint32_t>, 0, 0, 8, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_261 = { SIMD_KAFOR_pack_32len_2bw_8offset<uint32_t>, 8, 8, 8, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_262 = { SIMD_KAFOR_pack_32len_2bw_16offset<uint32_t>, 16, 16, 8, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_263 = { SIMD_KAFOR_pack_32len_2bw_24offset<uint32_t>, 24, 24, 8, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_264 = { SIMD_KAFOR_pack_32len_3bw_0offset<uint32_t>, 0, 0, 12, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_265 = { SIMD_KAFOR_pack_32len_3bw_8offset<uint32_t>, 8, 8, 12, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_266 = { SIMD_KAFOR_pack_32len_3bw_16offset<uint32_t>, 16, 16, 12, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_267 = { SIMD_KAFOR_pack_32len_3bw_24offset<uint32_t>, 24, 24, 12, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_268 = { SIMD_KAFOR_pack_32len_4bw_0offset<uint32_t>, 0, 0, 16, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_269 = { SIMD_KAFOR_pack_32len_4bw_8offset<uint32_t>, 8, 8, 16, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_270 = { SIMD_KAFOR_pack_32len_4bw_16offset<uint32_t>, 16, 16, 16, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_271 = { SIMD_KAFOR_pack_32len_4bw_24offset<uint32_t>, 24, 24, 16, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_272 = { SIMD_KAFOR_pack_32len_5bw_0offset<uint32_t>, 0, 0, 20, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_273 = { SIMD_KAFOR_pack_32len_5bw_8offset<uint32_t>, 8, 8, 20, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_274 = { SIMD_KAFOR_pack_32len_5bw_16offset<uint32_t>, 16, 16, 20, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_275 = { SIMD_KAFOR_pack_32len_5bw_24offset<uint32_t>, 24, 24, 20, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_276 = { SIMD_KAFOR_pack_32len_6bw_0offset<uint32_t>, 0, 0, 24, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_277 = { SIMD_KAFOR_pack_32len_6bw_8offset<uint32_t>, 8, 8, 24, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_278 = { SIMD_KAFOR_pack_32len_6bw_16offset<uint32_t>, 16, 16, 24, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_279 = { SIMD_KAFOR_pack_32len_6bw_24offset<uint32_t>, 24, 24, 24, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_280 = { SIMD_KAFOR_pack_32len_7bw_0offset<uint32_t>, 0, 0, 28, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_281 = { SIMD_KAFOR_pack_32len_7bw_8offset<uint32_t>, 8, 8, 28, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_282 = { SIMD_KAFOR_pack_32len_7bw_16offset<uint32_t>, 16, 16, 28, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_283 = { SIMD_KAFOR_pack_32len_7bw_24offset<uint32_t>, 24, 24, 28, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_284 = { SIMD_KAFOR_pack_32len_8bw_0offset<uint32_t>, 0, 0, 32, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_285 = { SIMD_KAFOR_pack_32len_8bw_8offset<uint32_t>, 8, 8, 32, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_286 = { SIMD_KAFOR_pack_32len_8bw_16offset<uint32_t>, 16, 16, 32, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_287 = { SIMD_KAFOR_pack_32len_8bw_24offset<uint32_t>, 24, 24, 32, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_288 = { SIMD_KAFOR_pack_32len_9bw_0offset<uint32_t>, 0, 0, 36, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_289 = { SIMD_KAFOR_pack_32len_9bw_8offset<uint32_t>, 8, 8, 36, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_290 = { SIMD_KAFOR_pack_32len_9bw_16offset<uint32_t>, 16, 16, 36, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_291 = { SIMD_KAFOR_pack_32len_9bw_24offset<uint32_t>, 24, 24, 36, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_292 = { SIMD_KAFOR_pack_32len_10bw_0offset<uint32_t>, 0, 0, 40, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_293 = { SIMD_KAFOR_pack_32len_10bw_8offset<uint32_t>, 8, 8, 40, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_294 = { SIMD_KAFOR_pack_32len_10bw_16offset<uint32_t>, 16, 16, 40, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_295 = { SIMD_KAFOR_pack_32len_10bw_24offset<uint32_t>, 24, 24, 40, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_296 = { SIMD_KAFOR_pack_32len_11bw_0offset<uint32_t>, 0, 0, 44, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_297 = { SIMD_KAFOR_pack_32len_11bw_8offset<uint32_t>, 8, 8, 44, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_298 = { SIMD_KAFOR_pack_32len_11bw_16offset<uint32_t>, 16, 16, 44, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_299 = { SIMD_KAFOR_pack_32len_11bw_24offset<uint32_t>, 24, 24, 44, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_300 = { SIMD_KAFOR_pack_32len_12bw_0offset<uint32_t>, 0, 0, 48, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_301 = { SIMD_KAFOR_pack_32len_12bw_8offset<uint32_t>, 8, 8, 48, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_302 = { SIMD_KAFOR_pack_32len_12bw_16offset<uint32_t>, 16, 16, 48, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_303 = { SIMD_KAFOR_pack_32len_12bw_24offset<uint32_t>, 24, 24, 48, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_304 = { SIMD_KAFOR_pack_32len_13bw_0offset<uint32_t>, 0, 0, 52, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_305 = { SIMD_KAFOR_pack_32len_13bw_8offset<uint32_t>, 8, 8, 52, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_306 = { SIMD_KAFOR_pack_32len_13bw_16offset<uint32_t>, 16, 16, 52, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_307 = { SIMD_KAFOR_pack_32len_13bw_24offset<uint32_t>, 24, 24, 52, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_308 = { SIMD_KAFOR_pack_32len_14bw_0offset<uint32_t>, 0, 0, 56, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_309 = { SIMD_KAFOR_pack_32len_14bw_8offset<uint32_t>, 8, 8, 56, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_310 = { SIMD_KAFOR_pack_32len_14bw_16offset<uint32_t>, 16, 16, 56, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_311 = { SIMD_KAFOR_pack_32len_14bw_24offset<uint32_t>, 24, 24, 56, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_312 = { SIMD_KAFOR_pack_32len_15bw_0offset<uint32_t>, 0, 0, 60, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_313 = { SIMD_KAFOR_pack_32len_15bw_8offset<uint32_t>, 8, 8, 60, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_314 = { SIMD_KAFOR_pack_32len_15bw_16offset<uint32_t>, 16, 16, 60, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_315 = { SIMD_KAFOR_pack_32len_15bw_24offset<uint32_t>, 24, 24, 60, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_316 = { SIMD_KAFOR_pack_32len_16bw_0offset<uint32_t>, 0, 0, 64, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_317 = { SIMD_KAFOR_pack_32len_16bw_8offset<uint32_t>, 8, 8, 64, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_318 = { SIMD_KAFOR_pack_32len_16bw_16offset<uint32_t>, 16, 16, 64, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_319 = { SIMD_KAFOR_pack_32len_16bw_24offset<uint32_t>, 24, 24, 64, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_320 = { SIMD_KAFOR_pack_32len_17bw_0offset<uint32_t>, 0, 0, 68, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_321 = { SIMD_KAFOR_pack_32len_17bw_8offset<uint32_t>, 8, 8, 68, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_322 = { SIMD_KAFOR_pack_32len_17bw_16offset<uint32_t>, 16, 16, 68, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_323 = { SIMD_KAFOR_pack_32len_17bw_24offset<uint32_t>, 24, 24, 68, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_324 = { SIMD_KAFOR_pack_32len_18bw_0offset<uint32_t>, 0, 0, 72, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_325 = { SIMD_KAFOR_pack_32len_18bw_8offset<uint32_t>, 8, 8, 72, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_326 = { SIMD_KAFOR_pack_32len_18bw_16offset<uint32_t>, 16, 16, 72, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_327 = { SIMD_KAFOR_pack_32len_18bw_24offset<uint32_t>, 24, 24, 72, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_328 = { SIMD_KAFOR_pack_32len_19bw_0offset<uint32_t>, 0, 0, 76, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_329 = { SIMD_KAFOR_pack_32len_19bw_8offset<uint32_t>, 8, 8, 76, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_330 = { SIMD_KAFOR_pack_32len_19bw_16offset<uint32_t>, 16, 16, 76, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_331 = { SIMD_KAFOR_pack_32len_19bw_24offset<uint32_t>, 24, 24, 76, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_332 = { SIMD_KAFOR_pack_32len_20bw_0offset<uint32_t>, 0, 0, 80, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_333 = { SIMD_KAFOR_pack_32len_20bw_8offset<uint32_t>, 8, 8, 80, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_334 = { SIMD_KAFOR_pack_32len_20bw_16offset<uint32_t>, 16, 16, 80, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_335 = { SIMD_KAFOR_pack_32len_20bw_24offset<uint32_t>, 24, 24, 80, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_336 = { SIMD_KAFOR_pack_32len_21bw_0offset<uint32_t>, 0, 0, 84, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_337 = { SIMD_KAFOR_pack_32len_21bw_8offset<uint32_t>, 8, 8, 84, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_338 = { SIMD_KAFOR_pack_32len_21bw_16offset<uint32_t>, 16, 16, 84, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_339 = { SIMD_KAFOR_pack_32len_21bw_24offset<uint32_t>, 24, 24, 84, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_340 = { SIMD_KAFOR_pack_32len_22bw_0offset<uint32_t>, 0, 0, 88, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_341 = { SIMD_KAFOR_pack_32len_22bw_8offset<uint32_t>, 8, 8, 88, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_342 = { SIMD_KAFOR_pack_32len_22bw_16offset<uint32_t>, 16, 16, 88, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_343 = { SIMD_KAFOR_pack_32len_22bw_24offset<uint32_t>, 24, 24, 88, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_344 = { SIMD_KAFOR_pack_32len_23bw_0offset<uint32_t>, 0, 0, 92, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_345 = { SIMD_KAFOR_pack_32len_23bw_8offset<uint32_t>, 8, 8, 92, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_346 = { SIMD_KAFOR_pack_32len_23bw_16offset<uint32_t>, 16, 16, 92, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_347 = { SIMD_KAFOR_pack_32len_23bw_24offset<uint32_t>, 24, 24, 92, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_348 = { SIMD_KAFOR_pack_32len_24bw_0offset<uint32_t>, 0, 0, 96, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_349 = { SIMD_KAFOR_pack_32len_24bw_8offset<uint32_t>, 8, 8, 96, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_350 = { SIMD_KAFOR_pack_32len_24bw_16offset<uint32_t>, 16, 16, 96, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_351 = { SIMD_KAFOR_pack_32len_24bw_24offset<uint32_t>, 24, 24, 96, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_352 = { SIMD_KAFOR_pack_32len_25bw_0offset<uint32_t>, 0, 0, 100, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_353 = { SIMD_KAFOR_pack_32len_25bw_8offset<uint32_t>, 8, 8, 100, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_354 = { SIMD_KAFOR_pack_32len_25bw_16offset<uint32_t>, 16, 16, 100, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_355 = { SIMD_KAFOR_pack_32len_25bw_24offset<uint32_t>, 24, 24, 100, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_356 = { SIMD_KAFOR_pack_32len_26bw_0offset<uint32_t>, 0, 0, 104, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_357 = { SIMD_KAFOR_pack_32len_26bw_8offset<uint32_t>, 8, 8, 104, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_358 = { SIMD_KAFOR_pack_32len_26bw_16offset<uint32_t>, 16, 16, 104, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_359 = { SIMD_KAFOR_pack_32len_26bw_24offset<uint32_t>, 24, 24, 104, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_360 = { SIMD_KAFOR_pack_32len_27bw_0offset<uint32_t>, 0, 0, 108, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_361 = { SIMD_KAFOR_pack_32len_27bw_8offset<uint32_t>, 8, 8, 108, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_362 = { SIMD_KAFOR_pack_32len_27bw_16offset<uint32_t>, 16, 16, 108, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_363 = { SIMD_KAFOR_pack_32len_27bw_24offset<uint32_t>, 24, 24, 108, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_364 = { SIMD_KAFOR_pack_32len_28bw_0offset<uint32_t>, 0, 0, 112, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_365 = { SIMD_KAFOR_pack_32len_28bw_8offset<uint32_t>, 8, 8, 112, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_366 = { SIMD_KAFOR_pack_32len_28bw_16offset<uint32_t>, 16, 16, 112, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_367 = { SIMD_KAFOR_pack_32len_28bw_24offset<uint32_t>, 24, 24, 112, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_368 = { SIMD_KAFOR_pack_32len_29bw_0offset<uint32_t>, 0, 0, 116, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_369 = { SIMD_KAFOR_pack_32len_29bw_8offset<uint32_t>, 8, 8, 116, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_370 = { SIMD_KAFOR_pack_32len_29bw_16offset<uint32_t>, 16, 16, 116, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_371 = { SIMD_KAFOR_pack_32len_29bw_24offset<uint32_t>, 24, 24, 116, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_372 = { SIMD_KAFOR_pack_32len_30bw_0offset<uint32_t>, 0, 0, 120, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_373 = { SIMD_KAFOR_pack_32len_30bw_8offset<uint32_t>, 8, 8, 120, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_374 = { SIMD_KAFOR_pack_32len_30bw_16offset<uint32_t>, 16, 16, 120, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_375 = { SIMD_KAFOR_pack_32len_30bw_24offset<uint32_t>, 24, 24, 120, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_376 = { SIMD_KAFOR_pack_32len_31bw_0offset<uint32_t>, 0, 0, 124, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_377 = { SIMD_KAFOR_pack_32len_31bw_8offset<uint32_t>, 8, 8, 124, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_378 = { SIMD_KAFOR_pack_32len_31bw_16offset<uint32_t>, 16, 16, 124, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_379 = { SIMD_KAFOR_pack_32len_31bw_24offset<uint32_t>, 24, 24, 124, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_380 = { SIMD_KAFOR_pack_32len_32bw_0offset<uint32_t>, 0, 0, 128, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_381 = { SIMD_KAFOR_pack_32len_32bw_8offset<uint32_t>, 8, 8, 128, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_382 = { SIMD_KAFOR_pack_32len_32bw_16offset<uint32_t>, 16, 16, 128, 128, };
static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_383 = { SIMD_KAFOR_pack_32len_32bw_24offset<uint32_t>, 24, 24, 128, 128, };

static SIMD_KAFORPackInfo SIMD_KAFORPackInfoArr[384] = {
	SIMD_KAFORPackInfo_0, SIMD_KAFORPackInfo_1, SIMD_KAFORPackInfo_2, SIMD_KAFORPackInfo_3,
	SIMD_KAFORPackInfo_4, SIMD_KAFORPackInfo_5, SIMD_KAFORPackInfo_6, SIMD_KAFORPackInfo_7,
	SIMD_KAFORPackInfo_8, SIMD_KAFORPackInfo_9, SIMD_KAFORPackInfo_10, SIMD_KAFORPackInfo_11,
	SIMD_KAFORPackInfo_12, SIMD_KAFORPackInfo_13, SIMD_KAFORPackInfo_14, SIMD_KAFORPackInfo_15,
	SIMD_KAFORPackInfo_16, SIMD_KAFORPackInfo_17, SIMD_KAFORPackInfo_18, SIMD_KAFORPackInfo_19,
	SIMD_KAFORPackInfo_20, SIMD_KAFORPackInfo_21, SIMD_KAFORPackInfo_22, SIMD_KAFORPackInfo_23,
	SIMD_KAFORPackInfo_24, SIMD_KAFORPackInfo_25, SIMD_KAFORPackInfo_26, SIMD_KAFORPackInfo_27,
	SIMD_KAFORPackInfo_28, SIMD_KAFORPackInfo_29, SIMD_KAFORPackInfo_30, SIMD_KAFORPackInfo_31,
	SIMD_KAFORPackInfo_32, SIMD_KAFORPackInfo_33, SIMD_KAFORPackInfo_34, SIMD_KAFORPackInfo_35,
	SIMD_KAFORPackInfo_36, SIMD_KAFORPackInfo_37, SIMD_KAFORPackInfo_38, SIMD_KAFORPackInfo_39,
	SIMD_KAFORPackInfo_40, SIMD_KAFORPackInfo_41, SIMD_KAFORPackInfo_42, SIMD_KAFORPackInfo_43,
	SIMD_KAFORPackInfo_44, SIMD_KAFORPackInfo_45, SIMD_KAFORPackInfo_46, SIMD_KAFORPackInfo_47,
	SIMD_KAFORPackInfo_48, SIMD_KAFORPackInfo_49, SIMD_KAFORPackInfo_50, SIMD_KAFORPackInfo_51,
	SIMD_KAFORPackInfo_52, SIMD_KAFORPackInfo_53, SIMD_KAFORPackInfo_54, SIMD_KAFORPackInfo_55,
	SIMD_KAFORPackInfo_56, SIMD_KAFORPackInfo_57, SIMD_KAFORPackInfo_58, SIMD_KAFORPackInfo_59,
	SIMD_KAFORPackInfo_60, SIMD_KAFORPackInfo_61, SIMD_KAFORPackInfo_62, SIMD_KAFORPackInfo_63,
	SIMD_KAFORPackInfo_64, SIMD_KAFORPackInfo_65, SIMD_KAFORPackInfo_66, SIMD_KAFORPackInfo_67,
	SIMD_KAFORPackInfo_68, SIMD_KAFORPackInfo_69, SIMD_KAFORPackInfo_70, SIMD_KAFORPackInfo_71,
	SIMD_KAFORPackInfo_72, SIMD_KAFORPackInfo_73, SIMD_KAFORPackInfo_74, SIMD_KAFORPackInfo_75,
	SIMD_KAFORPackInfo_76, SIMD_KAFORPackInfo_77, SIMD_KAFORPackInfo_78, SIMD_KAFORPackInfo_79,
	SIMD_KAFORPackInfo_80, SIMD_KAFORPackInfo_81, SIMD_KAFORPackInfo_82, SIMD_KAFORPackInfo_83,
	SIMD_KAFORPackInfo_84, SIMD_KAFORPackInfo_85, SIMD_KAFORPackInfo_86, SIMD_KAFORPackInfo_87,
	SIMD_KAFORPackInfo_88, SIMD_KAFORPackInfo_89, SIMD_KAFORPackInfo_90, SIMD_KAFORPackInfo_91,
	SIMD_KAFORPackInfo_92, SIMD_KAFORPackInfo_93, SIMD_KAFORPackInfo_94, SIMD_KAFORPackInfo_95,
	SIMD_KAFORPackInfo_96, SIMD_KAFORPackInfo_97, SIMD_KAFORPackInfo_98, SIMD_KAFORPackInfo_99,
	SIMD_KAFORPackInfo_100, SIMD_KAFORPackInfo_101, SIMD_KAFORPackInfo_102, SIMD_KAFORPackInfo_103,
	SIMD_KAFORPackInfo_104, SIMD_KAFORPackInfo_105, SIMD_KAFORPackInfo_106, SIMD_KAFORPackInfo_107,
	SIMD_KAFORPackInfo_108, SIMD_KAFORPackInfo_109, SIMD_KAFORPackInfo_110, SIMD_KAFORPackInfo_111,
	SIMD_KAFORPackInfo_112, SIMD_KAFORPackInfo_113, SIMD_KAFORPackInfo_114, SIMD_KAFORPackInfo_115,
	SIMD_KAFORPackInfo_116, SIMD_KAFORPackInfo_117, SIMD_KAFORPackInfo_118, SIMD_KAFORPackInfo_119,
	SIMD_KAFORPackInfo_120, SIMD_KAFORPackInfo_121, SIMD_KAFORPackInfo_122, SIMD_KAFORPackInfo_123,
	SIMD_KAFORPackInfo_124, SIMD_KAFORPackInfo_125, SIMD_KAFORPackInfo_126, SIMD_KAFORPackInfo_127,
	SIMD_KAFORPackInfo_128, SIMD_KAFORPackInfo_129, SIMD_KAFORPackInfo_130, SIMD_KAFORPackInfo_131,
	SIMD_KAFORPackInfo_132, SIMD_KAFORPackInfo_133, SIMD_KAFORPackInfo_134, SIMD_KAFORPackInfo_135,
	SIMD_KAFORPackInfo_136, SIMD_KAFORPackInfo_137, SIMD_KAFORPackInfo_138, SIMD_KAFORPackInfo_139,
	SIMD_KAFORPackInfo_140, SIMD_KAFORPackInfo_141, SIMD_KAFORPackInfo_142, SIMD_KAFORPackInfo_143,
	SIMD_KAFORPackInfo_144, SIMD_KAFORPackInfo_145, SIMD_KAFORPackInfo_146, SIMD_KAFORPackInfo_147,
	SIMD_KAFORPackInfo_148, SIMD_KAFORPackInfo_149, SIMD_KAFORPackInfo_150, SIMD_KAFORPackInfo_151,
	SIMD_KAFORPackInfo_152, SIMD_KAFORPackInfo_153, SIMD_KAFORPackInfo_154, SIMD_KAFORPackInfo_155,
	SIMD_KAFORPackInfo_156, SIMD_KAFORPackInfo_157, SIMD_KAFORPackInfo_158, SIMD_KAFORPackInfo_159,
	SIMD_KAFORPackInfo_160, SIMD_KAFORPackInfo_161, SIMD_KAFORPackInfo_162, SIMD_KAFORPackInfo_163,
	SIMD_KAFORPackInfo_164, SIMD_KAFORPackInfo_165, SIMD_KAFORPackInfo_166, SIMD_KAFORPackInfo_167,
	SIMD_KAFORPackInfo_168, SIMD_KAFORPackInfo_169, SIMD_KAFORPackInfo_170, SIMD_KAFORPackInfo_171,
	SIMD_KAFORPackInfo_172, SIMD_KAFORPackInfo_173, SIMD_KAFORPackInfo_174, SIMD_KAFORPackInfo_175,
	SIMD_KAFORPackInfo_176, SIMD_KAFORPackInfo_177, SIMD_KAFORPackInfo_178, SIMD_KAFORPackInfo_179,
	SIMD_KAFORPackInfo_180, SIMD_KAFORPackInfo_181, SIMD_KAFORPackInfo_182, SIMD_KAFORPackInfo_183,
	SIMD_KAFORPackInfo_184, SIMD_KAFORPackInfo_185, SIMD_KAFORPackInfo_186, SIMD_KAFORPackInfo_187,
	SIMD_KAFORPackInfo_188, SIMD_KAFORPackInfo_189, SIMD_KAFORPackInfo_190, SIMD_KAFORPackInfo_191,
	SIMD_KAFORPackInfo_192, SIMD_KAFORPackInfo_193, SIMD_KAFORPackInfo_194, SIMD_KAFORPackInfo_195,
	SIMD_KAFORPackInfo_196, SIMD_KAFORPackInfo_197, SIMD_KAFORPackInfo_198, SIMD_KAFORPackInfo_199,
	SIMD_KAFORPackInfo_200, SIMD_KAFORPackInfo_201, SIMD_KAFORPackInfo_202, SIMD_KAFORPackInfo_203,
	SIMD_KAFORPackInfo_204, SIMD_KAFORPackInfo_205, SIMD_KAFORPackInfo_206, SIMD_KAFORPackInfo_207,
	SIMD_KAFORPackInfo_208, SIMD_KAFORPackInfo_209, SIMD_KAFORPackInfo_210, SIMD_KAFORPackInfo_211,
	SIMD_KAFORPackInfo_212, SIMD_KAFORPackInfo_213, SIMD_KAFORPackInfo_214, SIMD_KAFORPackInfo_215,
	SIMD_KAFORPackInfo_216, SIMD_KAFORPackInfo_217, SIMD_KAFORPackInfo_218, SIMD_KAFORPackInfo_219,
	SIMD_KAFORPackInfo_220, SIMD_KAFORPackInfo_221, SIMD_KAFORPackInfo_222, SIMD_KAFORPackInfo_223,
	SIMD_KAFORPackInfo_224, SIMD_KAFORPackInfo_225, SIMD_KAFORPackInfo_226, SIMD_KAFORPackInfo_227,
	SIMD_KAFORPackInfo_228, SIMD_KAFORPackInfo_229, SIMD_KAFORPackInfo_230, SIMD_KAFORPackInfo_231,
	SIMD_KAFORPackInfo_232, SIMD_KAFORPackInfo_233, SIMD_KAFORPackInfo_234, SIMD_KAFORPackInfo_235,
	SIMD_KAFORPackInfo_236, SIMD_KAFORPackInfo_237, SIMD_KAFORPackInfo_238, SIMD_KAFORPackInfo_239,
	SIMD_KAFORPackInfo_240, SIMD_KAFORPackInfo_241, SIMD_KAFORPackInfo_242, SIMD_KAFORPackInfo_243,
	SIMD_KAFORPackInfo_244, SIMD_KAFORPackInfo_245, SIMD_KAFORPackInfo_246, SIMD_KAFORPackInfo_247,
	SIMD_KAFORPackInfo_248, SIMD_KAFORPackInfo_249, SIMD_KAFORPackInfo_250, SIMD_KAFORPackInfo_251,
	SIMD_KAFORPackInfo_252, SIMD_KAFORPackInfo_253, SIMD_KAFORPackInfo_254, SIMD_KAFORPackInfo_255,
	SIMD_KAFORPackInfo_256, SIMD_KAFORPackInfo_257, SIMD_KAFORPackInfo_258, SIMD_KAFORPackInfo_259,
	SIMD_KAFORPackInfo_260, SIMD_KAFORPackInfo_261, SIMD_KAFORPackInfo_262, SIMD_KAFORPackInfo_263,
	SIMD_KAFORPackInfo_264, SIMD_KAFORPackInfo_265, SIMD_KAFORPackInfo_266, SIMD_KAFORPackInfo_267,
	SIMD_KAFORPackInfo_268, SIMD_KAFORPackInfo_269, SIMD_KAFORPackInfo_270, SIMD_KAFORPackInfo_271,
	SIMD_KAFORPackInfo_272, SIMD_KAFORPackInfo_273, SIMD_KAFORPackInfo_274, SIMD_KAFORPackInfo_275,
	SIMD_KAFORPackInfo_276, SIMD_KAFORPackInfo_277, SIMD_KAFORPackInfo_278, SIMD_KAFORPackInfo_279,
	SIMD_KAFORPackInfo_280, SIMD_KAFORPackInfo_281, SIMD_KAFORPackInfo_282, SIMD_KAFORPackInfo_283,
	SIMD_KAFORPackInfo_284, SIMD_KAFORPackInfo_285, SIMD_KAFORPackInfo_286, SIMD_KAFORPackInfo_287,
	SIMD_KAFORPackInfo_288, SIMD_KAFORPackInfo_289, SIMD_KAFORPackInfo_290, SIMD_KAFORPackInfo_291,
	SIMD_KAFORPackInfo_292, SIMD_KAFORPackInfo_293, SIMD_KAFORPackInfo_294, SIMD_KAFORPackInfo_295,
	SIMD_KAFORPackInfo_296, SIMD_KAFORPackInfo_297, SIMD_KAFORPackInfo_298, SIMD_KAFORPackInfo_299,
	SIMD_KAFORPackInfo_300, SIMD_KAFORPackInfo_301, SIMD_KAFORPackInfo_302, SIMD_KAFORPackInfo_303,
	SIMD_KAFORPackInfo_304, SIMD_KAFORPackInfo_305, SIMD_KAFORPackInfo_306, SIMD_KAFORPackInfo_307,
	SIMD_KAFORPackInfo_308, SIMD_KAFORPackInfo_309, SIMD_KAFORPackInfo_310, SIMD_KAFORPackInfo_311,
	SIMD_KAFORPackInfo_312, SIMD_KAFORPackInfo_313, SIMD_KAFORPackInfo_314, SIMD_KAFORPackInfo_315,
	SIMD_KAFORPackInfo_316, SIMD_KAFORPackInfo_317, SIMD_KAFORPackInfo_318, SIMD_KAFORPackInfo_319,
	SIMD_KAFORPackInfo_320, SIMD_KAFORPackInfo_321, SIMD_KAFORPackInfo_322, SIMD_KAFORPackInfo_323,
	SIMD_KAFORPackInfo_324, SIMD_KAFORPackInfo_325, SIMD_KAFORPackInfo_326, SIMD_KAFORPackInfo_327,
	SIMD_KAFORPackInfo_328, SIMD_KAFORPackInfo_329, SIMD_KAFORPackInfo_330, SIMD_KAFORPackInfo_331,
	SIMD_KAFORPackInfo_332, SIMD_KAFORPackInfo_333, SIMD_KAFORPackInfo_334, SIMD_KAFORPackInfo_335,
	SIMD_KAFORPackInfo_336, SIMD_KAFORPackInfo_337, SIMD_KAFORPackInfo_338, SIMD_KAFORPackInfo_339,
	SIMD_KAFORPackInfo_340, SIMD_KAFORPackInfo_341, SIMD_KAFORPackInfo_342, SIMD_KAFORPackInfo_343,
	SIMD_KAFORPackInfo_344, SIMD_KAFORPackInfo_345, SIMD_KAFORPackInfo_346, SIMD_KAFORPackInfo_347,
	SIMD_KAFORPackInfo_348, SIMD_KAFORPackInfo_349, SIMD_KAFORPackInfo_350, SIMD_KAFORPackInfo_351,
	SIMD_KAFORPackInfo_352, SIMD_KAFORPackInfo_353, SIMD_KAFORPackInfo_354, SIMD_KAFORPackInfo_355,
	SIMD_KAFORPackInfo_356, SIMD_KAFORPackInfo_357, SIMD_KAFORPackInfo_358, SIMD_KAFORPackInfo_359,
	SIMD_KAFORPackInfo_360, SIMD_KAFORPackInfo_361, SIMD_KAFORPackInfo_362, SIMD_KAFORPackInfo_363,
	SIMD_KAFORPackInfo_364, SIMD_KAFORPackInfo_365, SIMD_KAFORPackInfo_366, SIMD_KAFORPackInfo_367,
	SIMD_KAFORPackInfo_368, SIMD_KAFORPackInfo_369, SIMD_KAFORPackInfo_370, SIMD_KAFORPackInfo_371,
	SIMD_KAFORPackInfo_372, SIMD_KAFORPackInfo_373, SIMD_KAFORPackInfo_374, SIMD_KAFORPackInfo_375,
	SIMD_KAFORPackInfo_376, SIMD_KAFORPackInfo_377, SIMD_KAFORPackInfo_378, SIMD_KAFORPackInfo_379,
	SIMD_KAFORPackInfo_380, SIMD_KAFORPackInfo_381, SIMD_KAFORPackInfo_382, SIMD_KAFORPackInfo_383,
};

}
}

#endif /* SIMD_KAFOR_PACK_HPP_ */

/*

#include <iostream>
#include <sstream>
#include <string>
#include <stdint.h>

using namespace std;

string TRIPLE_TAB = "\t\t\t";
string QUOTE_END_LINE = "\\n\"\n";
int BEG_REG_IDX = 3;

void GenCode(int num, int base, ostringstream &oss, ostringstream &infoOss) {
	//string IDX_STR = "i";

	for (int i=1; i<=32; i++) {
		for (int k=0; k<4; k++) {	//ori byte offset
			oss << "template<typename T>" << endl;
			oss << "void SIMD_KAFOR_pack_" << num << "len_" << i << "bw_" << (k*8) << "offset(T * des, const uint32_t *src) {" << endl;
			int infoIdx = (base << 7) + ((i - 1) << 2) + k;
			infoOss << "static SIMD_KAFORPackInfo SIMD_KAFORPackInfo_" << infoIdx << " = { " << "SIMD_KAFOR_pack_"
					<< num << "len_" << i << "bw_" << (k*8) << "offset<uint32_t>, ";

			oss << "\t__asm__ volatile(\"prefetchnta %0\"::\"m\" (src[0]));\n";

			int offsetInWord = k << 3;
			int curWordIdx = 0;
			int j = 0;
			uint32_t mask  = (1LL << i) - 1;

			int asmBlockSrcQuadWordCount = 4;

			int asmBlockDstQuadWordCount = 0;
			int curBlockSrcQuadWordIdx = 0;
			int curBlockDstQuadWordIdx = 0;

			string asmBlockEndInfo = "";

			int TMP_REG_IDX;

			while (j < num) {
				if (j % asmBlockSrcQuadWordCount == 0) {
					// open an asm block
					asmBlockDstQuadWordCount = ((offsetInWord + i * 4 + 31) / 32);
					TMP_REG_IDX = BEG_REG_IDX + asmBlockSrcQuadWordCount;
					curBlockSrcQuadWordIdx = 0;
					curBlockDstQuadWordIdx = 0;
					oss << "\t__asm__(\n";

					// load all quadword acquired by asmBlock from mem into xmm
					for (int t=0; t<asmBlockSrcQuadWordCount; ++t) {
						oss << TRIPLE_TAB << "\"movdqu %" << (asmBlockDstQuadWordCount + t)
						<< ",%%xmm" << (BEG_REG_IDX+t) << QUOTE_END_LINE;
					}

					if (offsetInWord > 0) {	// load first dst quad word as needed
						oss << TRIPLE_TAB << "\"movdqu %" << (0)
						<< ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;

					}


					ostringstream tmp3;
					tmp3 << TRIPLE_TAB << ":";
					for (int t=0; t<asmBlockDstQuadWordCount; ++t) {
						tmp3 << "\"=m\"(des[" << (4 * (curWordIdx + t)) << "])";
						if (t < asmBlockDstQuadWordCount-1)
							tmp3 << ", ";
						else
							tmp3 << "\n";
					}

					tmp3 << TRIPLE_TAB << ":";
					for (int t=0; t<asmBlockSrcQuadWordCount; ++t) {
						tmp3 << "\"m\"(src[" << 4 * (j + t) << "])";
						if (t < asmBlockSrcQuadWordCount-1)
							tmp3 << ", ";
						else
							tmp3 << "\n";
					}
					tmp3 << TRIPLE_TAB << ":\"memory\");\n";
					asmBlockEndInfo = tmp3.str();
				}

				int newBitWidth = offsetInWord + i - 32;
				if (offsetInWord == 0)
					oss << TRIPLE_TAB << "\"pxor %%xmm" << (TMP_REG_IDX) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;


				if (newBitWidth >= 0) {
					ostringstream tmp1;
					tmp1 << TRIPLE_TAB << "\"movdqa %%xmm" << (BEG_REG_IDX + curBlockSrcQuadWordIdx) << ",%%xmm" << (TMP_REG_IDX + 1) << QUOTE_END_LINE;
					if (offsetInWord > 0)
						tmp1 << TRIPLE_TAB << "\"pslld $" << offsetInWord << ",%%xmm" << (TMP_REG_IDX + 1) << QUOTE_END_LINE;

					tmp1 << TRIPLE_TAB << "\"por %%xmm" << (TMP_REG_IDX + 1) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
					tmp1 << TRIPLE_TAB << "\"movdqu %%xmm" << (TMP_REG_IDX) << ",%" << curBlockDstQuadWordIdx << QUOTE_END_LINE;
					curWordIdx += (offsetInWord + i) / 32;
					curBlockDstQuadWordIdx += (offsetInWord + i) / 32;
					offsetInWord = (offsetInWord + i) % 32;
					if (newBitWidth > 0) {
						tmp1 << TRIPLE_TAB << "\"movdqa %%xmm" << (BEG_REG_IDX + curBlockSrcQuadWordIdx) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
						tmp1 << TRIPLE_TAB << "\"pslld $" << (32 - i) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
						tmp1 << TRIPLE_TAB << "\"psrld $" << (32 - newBitWidth) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
					}

					oss << tmp1.str();
				} else {
					ostringstream tmp1;
					tmp1 << TRIPLE_TAB << "\"movdqa %%xmm" << (BEG_REG_IDX + curBlockSrcQuadWordIdx) << ",%%xmm" << (TMP_REG_IDX + 1) << QUOTE_END_LINE;
					tmp1 << TRIPLE_TAB << "\"pslld $" << (32 - i) << ",%%xmm" << (TMP_REG_IDX + 1) << QUOTE_END_LINE;
					tmp1 << TRIPLE_TAB << "\"psrld $" << (32 - i - offsetInWord) << ",%%xmm" << (TMP_REG_IDX + 1) << QUOTE_END_LINE;
					tmp1 << TRIPLE_TAB << "\"por %%xmm" << (TMP_REG_IDX + 1) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
					oss << tmp1.str();

					curWordIdx += (offsetInWord + i) / 32;
					curBlockDstQuadWordIdx += (offsetInWord + i) / 32;
					offsetInWord = (offsetInWord + i) % 32;
				}

				curBlockSrcQuadWordIdx ++;
				j++;

				if (j == num || j % asmBlockSrcQuadWordCount == 0) {
					// write last dst xmm to mem as needed
					if (offsetInWord > 0)
						oss << TRIPLE_TAB << "\"movdqu %%xmm" << (TMP_REG_IDX) << ",%" << curBlockDstQuadWordIdx << QUOTE_END_LINE;
					oss << asmBlockEndInfo;
				}
			}
			oss << "}" << endl;
			oss << endl;
			infoOss << (k << 3) << ", "	//begOffset
				<< (offsetInWord) << ", "	//newOffset
				<< (curWordIdx << 2) << ", "	//wordskipped
				<< (num << 2) << ", "		//integer decoded
				<< "};" << endl;
		}
	}
}

string printInfoArr(int arrNum) {
	ostringstream oss;
	oss << "static SIMD_KAFORPackInfo SIMD_KAFORPackInfoArr[" << arrNum << "] = {" << endl;
	for (int i=0; i<arrNum; ++i) {
		if (i % 4 == 0)
			oss << "\t";
		oss << "SIMD_KAFORPackInfo_" << i << ", ";
		if (i % 4 == 3)
			oss << endl;
	}
	oss << "};" << endl;
	return oss.str();
}


int main() {
	ostringstream oss, infoOss;
	GenCode(8, 0, oss, infoOss);
	GenCode(16, 1, oss, infoOss);
	GenCode(32, 2, oss, infoOss);

	cout << oss.str();
	cout << endl;
	cout << infoOss.str();
	cout << endl;
	cout << printInfoArr(3 * 32 * 4);

	return 0;
}

 *
 *
 */
