/*
 * SIMD_KAFOR_unpack.hpp
 *
 *  Created on: 2013-11-18
 *      Author: zxd
 */

#ifndef SIMD_KAFOR_UNPACK_HPP_
#define SIMD_KAFOR_UNPACK_HPP_

namespace paradise {
namespace index {

struct SIMD_KAFORUnpackInfo {
	void (*m_subFunc)(uint32_t *des, const uint32_t *src);
	uint8_t m_offset;
	uint8_t m_newOffset;
	uint16_t m_wordSkipped;
	uint16_t m_intDecoded;
};

template<typename T>
void SIMD_KAFOR_unpack_8len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_13bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_13bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_13bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_13bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_14bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_14bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_14bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_14bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_15bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_15bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_15bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_15bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_17bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_17bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_17bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_17bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_18bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_18bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_18bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_18bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_19bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_19bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_19bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_19bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_21bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_21bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_21bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_21bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_22bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_22bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_22bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_22bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_23bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_23bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_23bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_23bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_24bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_24bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_24bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_24bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_25bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_25bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_25bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_25bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_26bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_26bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_26bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_26bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_27bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_27bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_27bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_27bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_28bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_28bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_28bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_28bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_29bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_29bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_29bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_29bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_30bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_30bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_30bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_30bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_31bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $5,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $6,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_31bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $26,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $27,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_31bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_31bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_8len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_13bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_13bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_13bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_13bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_14bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_14bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_14bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_14bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_15bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_15bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_15bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_15bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_17bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_17bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_17bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_17bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_18bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_18bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_18bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_18bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_19bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_19bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_19bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_19bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_21bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_21bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_21bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_21bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_22bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_22bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_22bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_22bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_23bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_23bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_23bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_23bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_24bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_24bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_24bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_24bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_25bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_25bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_25bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_25bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_26bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_26bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_26bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_26bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_27bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_27bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_27bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_27bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_28bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_28bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_28bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_28bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_29bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_29bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_29bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_29bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_30bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_30bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_30bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_30bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_31bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $5,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $6,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_31bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $26,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $27,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $5,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $6,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_31bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $26,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $27,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_31bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_16len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_13bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_13bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_13bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_13bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $19,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $19,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_14bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[48]), "m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_14bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_14bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_14bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $18,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $18,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_15bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_15bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_15bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_15bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $17,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $17,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_17bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_17bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_17bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_17bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $17,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $15,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $15,%%xmm6\n"
			"psrld $15,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_18bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_18bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_18bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_18bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $14,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_19bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_19bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_19bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_19bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $26,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $19,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $13,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $6,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $13,%%xmm6\n"
			"psrld $13,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_21bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_21bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_21bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_21bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $1,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $31,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $11,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $11,%%xmm6\n"
			"psrld $11,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_22bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_22bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_22bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_22bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $30,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $22,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $10,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $20,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $2,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"psrld $10,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_23bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_23bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_23bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_23bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $27,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $14,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $23,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $18,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $5,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"psrld $9,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $9,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_24bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_24bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_24bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_24bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_25bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_25bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_25bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_25bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $19,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $13,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $13,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $19,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_26bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_26bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_26bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_26bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $18,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $14,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $14,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $18,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $6,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_27bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[24]), "m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_27bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_27bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_27bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $21,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $11,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $11,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $21,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $25,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $7,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $15,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $17,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $10,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $22,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $22,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $10,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $17,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $15,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $7,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $25,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $5,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_28bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_28bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_28bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $16,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $16,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_28bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"psrld $4,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_29bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_29bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[56]), "m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112]), "m"(src[116])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_29bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112]), "m"(src[116])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_29bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $20,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $9,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $23,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $23,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $9,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $5,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $27,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"psrld $3,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $27,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $5,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[104]), "m"(src[108]), "m"(src[112]), "m"(src[116])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_30bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[72]), "m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[104]), "m"(src[108]), "m"(src[112]), "m"(src[116])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_30bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[104]), "m"(src[108]), "m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_30bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[104]), "m"(src[108]), "m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_30bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"psrld $2,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $8,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $24,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $6,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $26,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $28,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $4,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $26,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $6,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $2,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[108]), "m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_31bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $5,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $6,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $26,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $27,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[108]), "m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_31bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $26,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $27,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $5,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $6,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[44]), "m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[108]), "m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_31bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $26,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $27,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $5,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $6,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[76]), "m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[92]), "m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[108]), "m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_31bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $23,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $9,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $22,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $10,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $21,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $11,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $20,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $12,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $19,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $13,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $18,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $14,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $17,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $15,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $15,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $17,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $14,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $18,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $13,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $19,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $12,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $20,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $11,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $21,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $10,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $22,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $9,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $23,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $7,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $25,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $6,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $26,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $5,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $27,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $4,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $28,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $3,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $29,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $2,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $30,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $31,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $30,%%xmm7\n"
			"movdqa %%xmm5,%%xmm8\n"
			"pslld $2,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $29,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $3,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $1,%%xmm7\n"
			"psrld $1,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $28,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $4,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $27,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $5,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $26,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $6,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $25,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $7,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"pslld $1,%%xmm8\n"
			"psrld $1,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[108]), "m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
}

template<typename T>
void SIMD_KAFOR_unpack_32len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
}


static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_0 = { SIMD_KAFOR_unpack_8len_1bw_0offset<uint32_t>, 0, 8, 0, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_1 = { SIMD_KAFOR_unpack_8len_1bw_8offset<uint32_t>, 8, 16, 0, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_2 = { SIMD_KAFOR_unpack_8len_1bw_16offset<uint32_t>, 16, 24, 0, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_3 = { SIMD_KAFOR_unpack_8len_1bw_24offset<uint32_t>, 24, 0, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_4 = { SIMD_KAFOR_unpack_8len_2bw_0offset<uint32_t>, 0, 16, 0, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_5 = { SIMD_KAFOR_unpack_8len_2bw_8offset<uint32_t>, 8, 24, 0, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_6 = { SIMD_KAFOR_unpack_8len_2bw_16offset<uint32_t>, 16, 0, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_7 = { SIMD_KAFOR_unpack_8len_2bw_24offset<uint32_t>, 24, 8, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_8 = { SIMD_KAFOR_unpack_8len_3bw_0offset<uint32_t>, 0, 24, 0, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_9 = { SIMD_KAFOR_unpack_8len_3bw_8offset<uint32_t>, 8, 0, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_10 = { SIMD_KAFOR_unpack_8len_3bw_16offset<uint32_t>, 16, 8, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_11 = { SIMD_KAFOR_unpack_8len_3bw_24offset<uint32_t>, 24, 16, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_12 = { SIMD_KAFOR_unpack_8len_4bw_0offset<uint32_t>, 0, 0, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_13 = { SIMD_KAFOR_unpack_8len_4bw_8offset<uint32_t>, 8, 8, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_14 = { SIMD_KAFOR_unpack_8len_4bw_16offset<uint32_t>, 16, 16, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_15 = { SIMD_KAFOR_unpack_8len_4bw_24offset<uint32_t>, 24, 24, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_16 = { SIMD_KAFOR_unpack_8len_5bw_0offset<uint32_t>, 0, 8, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_17 = { SIMD_KAFOR_unpack_8len_5bw_8offset<uint32_t>, 8, 16, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_18 = { SIMD_KAFOR_unpack_8len_5bw_16offset<uint32_t>, 16, 24, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_19 = { SIMD_KAFOR_unpack_8len_5bw_24offset<uint32_t>, 24, 0, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_20 = { SIMD_KAFOR_unpack_8len_6bw_0offset<uint32_t>, 0, 16, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_21 = { SIMD_KAFOR_unpack_8len_6bw_8offset<uint32_t>, 8, 24, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_22 = { SIMD_KAFOR_unpack_8len_6bw_16offset<uint32_t>, 16, 0, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_23 = { SIMD_KAFOR_unpack_8len_6bw_24offset<uint32_t>, 24, 8, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_24 = { SIMD_KAFOR_unpack_8len_7bw_0offset<uint32_t>, 0, 24, 4, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_25 = { SIMD_KAFOR_unpack_8len_7bw_8offset<uint32_t>, 8, 0, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_26 = { SIMD_KAFOR_unpack_8len_7bw_16offset<uint32_t>, 16, 8, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_27 = { SIMD_KAFOR_unpack_8len_7bw_24offset<uint32_t>, 24, 16, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_28 = { SIMD_KAFOR_unpack_8len_8bw_0offset<uint32_t>, 0, 0, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_29 = { SIMD_KAFOR_unpack_8len_8bw_8offset<uint32_t>, 8, 8, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_30 = { SIMD_KAFOR_unpack_8len_8bw_16offset<uint32_t>, 16, 16, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_31 = { SIMD_KAFOR_unpack_8len_8bw_24offset<uint32_t>, 24, 24, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_32 = { SIMD_KAFOR_unpack_8len_9bw_0offset<uint32_t>, 0, 8, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_33 = { SIMD_KAFOR_unpack_8len_9bw_8offset<uint32_t>, 8, 16, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_34 = { SIMD_KAFOR_unpack_8len_9bw_16offset<uint32_t>, 16, 24, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_35 = { SIMD_KAFOR_unpack_8len_9bw_24offset<uint32_t>, 24, 0, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_36 = { SIMD_KAFOR_unpack_8len_10bw_0offset<uint32_t>, 0, 16, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_37 = { SIMD_KAFOR_unpack_8len_10bw_8offset<uint32_t>, 8, 24, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_38 = { SIMD_KAFOR_unpack_8len_10bw_16offset<uint32_t>, 16, 0, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_39 = { SIMD_KAFOR_unpack_8len_10bw_24offset<uint32_t>, 24, 8, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_40 = { SIMD_KAFOR_unpack_8len_11bw_0offset<uint32_t>, 0, 24, 8, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_41 = { SIMD_KAFOR_unpack_8len_11bw_8offset<uint32_t>, 8, 0, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_42 = { SIMD_KAFOR_unpack_8len_11bw_16offset<uint32_t>, 16, 8, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_43 = { SIMD_KAFOR_unpack_8len_11bw_24offset<uint32_t>, 24, 16, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_44 = { SIMD_KAFOR_unpack_8len_12bw_0offset<uint32_t>, 0, 0, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_45 = { SIMD_KAFOR_unpack_8len_12bw_8offset<uint32_t>, 8, 8, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_46 = { SIMD_KAFOR_unpack_8len_12bw_16offset<uint32_t>, 16, 16, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_47 = { SIMD_KAFOR_unpack_8len_12bw_24offset<uint32_t>, 24, 24, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_48 = { SIMD_KAFOR_unpack_8len_13bw_0offset<uint32_t>, 0, 8, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_49 = { SIMD_KAFOR_unpack_8len_13bw_8offset<uint32_t>, 8, 16, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_50 = { SIMD_KAFOR_unpack_8len_13bw_16offset<uint32_t>, 16, 24, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_51 = { SIMD_KAFOR_unpack_8len_13bw_24offset<uint32_t>, 24, 0, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_52 = { SIMD_KAFOR_unpack_8len_14bw_0offset<uint32_t>, 0, 16, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_53 = { SIMD_KAFOR_unpack_8len_14bw_8offset<uint32_t>, 8, 24, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_54 = { SIMD_KAFOR_unpack_8len_14bw_16offset<uint32_t>, 16, 0, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_55 = { SIMD_KAFOR_unpack_8len_14bw_24offset<uint32_t>, 24, 8, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_56 = { SIMD_KAFOR_unpack_8len_15bw_0offset<uint32_t>, 0, 24, 12, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_57 = { SIMD_KAFOR_unpack_8len_15bw_8offset<uint32_t>, 8, 0, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_58 = { SIMD_KAFOR_unpack_8len_15bw_16offset<uint32_t>, 16, 8, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_59 = { SIMD_KAFOR_unpack_8len_15bw_24offset<uint32_t>, 24, 16, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_60 = { SIMD_KAFOR_unpack_8len_16bw_0offset<uint32_t>, 0, 0, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_61 = { SIMD_KAFOR_unpack_8len_16bw_8offset<uint32_t>, 8, 8, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_62 = { SIMD_KAFOR_unpack_8len_16bw_16offset<uint32_t>, 16, 16, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_63 = { SIMD_KAFOR_unpack_8len_16bw_24offset<uint32_t>, 24, 24, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_64 = { SIMD_KAFOR_unpack_8len_17bw_0offset<uint32_t>, 0, 8, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_65 = { SIMD_KAFOR_unpack_8len_17bw_8offset<uint32_t>, 8, 16, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_66 = { SIMD_KAFOR_unpack_8len_17bw_16offset<uint32_t>, 16, 24, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_67 = { SIMD_KAFOR_unpack_8len_17bw_24offset<uint32_t>, 24, 0, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_68 = { SIMD_KAFOR_unpack_8len_18bw_0offset<uint32_t>, 0, 16, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_69 = { SIMD_KAFOR_unpack_8len_18bw_8offset<uint32_t>, 8, 24, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_70 = { SIMD_KAFOR_unpack_8len_18bw_16offset<uint32_t>, 16, 0, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_71 = { SIMD_KAFOR_unpack_8len_18bw_24offset<uint32_t>, 24, 8, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_72 = { SIMD_KAFOR_unpack_8len_19bw_0offset<uint32_t>, 0, 24, 16, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_73 = { SIMD_KAFOR_unpack_8len_19bw_8offset<uint32_t>, 8, 0, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_74 = { SIMD_KAFOR_unpack_8len_19bw_16offset<uint32_t>, 16, 8, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_75 = { SIMD_KAFOR_unpack_8len_19bw_24offset<uint32_t>, 24, 16, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_76 = { SIMD_KAFOR_unpack_8len_20bw_0offset<uint32_t>, 0, 0, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_77 = { SIMD_KAFOR_unpack_8len_20bw_8offset<uint32_t>, 8, 8, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_78 = { SIMD_KAFOR_unpack_8len_20bw_16offset<uint32_t>, 16, 16, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_79 = { SIMD_KAFOR_unpack_8len_20bw_24offset<uint32_t>, 24, 24, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_80 = { SIMD_KAFOR_unpack_8len_21bw_0offset<uint32_t>, 0, 8, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_81 = { SIMD_KAFOR_unpack_8len_21bw_8offset<uint32_t>, 8, 16, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_82 = { SIMD_KAFOR_unpack_8len_21bw_16offset<uint32_t>, 16, 24, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_83 = { SIMD_KAFOR_unpack_8len_21bw_24offset<uint32_t>, 24, 0, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_84 = { SIMD_KAFOR_unpack_8len_22bw_0offset<uint32_t>, 0, 16, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_85 = { SIMD_KAFOR_unpack_8len_22bw_8offset<uint32_t>, 8, 24, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_86 = { SIMD_KAFOR_unpack_8len_22bw_16offset<uint32_t>, 16, 0, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_87 = { SIMD_KAFOR_unpack_8len_22bw_24offset<uint32_t>, 24, 8, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_88 = { SIMD_KAFOR_unpack_8len_23bw_0offset<uint32_t>, 0, 24, 20, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_89 = { SIMD_KAFOR_unpack_8len_23bw_8offset<uint32_t>, 8, 0, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_90 = { SIMD_KAFOR_unpack_8len_23bw_16offset<uint32_t>, 16, 8, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_91 = { SIMD_KAFOR_unpack_8len_23bw_24offset<uint32_t>, 24, 16, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_92 = { SIMD_KAFOR_unpack_8len_24bw_0offset<uint32_t>, 0, 0, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_93 = { SIMD_KAFOR_unpack_8len_24bw_8offset<uint32_t>, 8, 8, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_94 = { SIMD_KAFOR_unpack_8len_24bw_16offset<uint32_t>, 16, 16, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_95 = { SIMD_KAFOR_unpack_8len_24bw_24offset<uint32_t>, 24, 24, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_96 = { SIMD_KAFOR_unpack_8len_25bw_0offset<uint32_t>, 0, 8, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_97 = { SIMD_KAFOR_unpack_8len_25bw_8offset<uint32_t>, 8, 16, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_98 = { SIMD_KAFOR_unpack_8len_25bw_16offset<uint32_t>, 16, 24, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_99 = { SIMD_KAFOR_unpack_8len_25bw_24offset<uint32_t>, 24, 0, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_100 = { SIMD_KAFOR_unpack_8len_26bw_0offset<uint32_t>, 0, 16, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_101 = { SIMD_KAFOR_unpack_8len_26bw_8offset<uint32_t>, 8, 24, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_102 = { SIMD_KAFOR_unpack_8len_26bw_16offset<uint32_t>, 16, 0, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_103 = { SIMD_KAFOR_unpack_8len_26bw_24offset<uint32_t>, 24, 8, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_104 = { SIMD_KAFOR_unpack_8len_27bw_0offset<uint32_t>, 0, 24, 24, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_105 = { SIMD_KAFOR_unpack_8len_27bw_8offset<uint32_t>, 8, 0, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_106 = { SIMD_KAFOR_unpack_8len_27bw_16offset<uint32_t>, 16, 8, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_107 = { SIMD_KAFOR_unpack_8len_27bw_24offset<uint32_t>, 24, 16, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_108 = { SIMD_KAFOR_unpack_8len_28bw_0offset<uint32_t>, 0, 0, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_109 = { SIMD_KAFOR_unpack_8len_28bw_8offset<uint32_t>, 8, 8, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_110 = { SIMD_KAFOR_unpack_8len_28bw_16offset<uint32_t>, 16, 16, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_111 = { SIMD_KAFOR_unpack_8len_28bw_24offset<uint32_t>, 24, 24, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_112 = { SIMD_KAFOR_unpack_8len_29bw_0offset<uint32_t>, 0, 8, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_113 = { SIMD_KAFOR_unpack_8len_29bw_8offset<uint32_t>, 8, 16, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_114 = { SIMD_KAFOR_unpack_8len_29bw_16offset<uint32_t>, 16, 24, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_115 = { SIMD_KAFOR_unpack_8len_29bw_24offset<uint32_t>, 24, 0, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_116 = { SIMD_KAFOR_unpack_8len_30bw_0offset<uint32_t>, 0, 16, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_117 = { SIMD_KAFOR_unpack_8len_30bw_8offset<uint32_t>, 8, 24, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_118 = { SIMD_KAFOR_unpack_8len_30bw_16offset<uint32_t>, 16, 0, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_119 = { SIMD_KAFOR_unpack_8len_30bw_24offset<uint32_t>, 24, 8, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_120 = { SIMD_KAFOR_unpack_8len_31bw_0offset<uint32_t>, 0, 24, 28, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_121 = { SIMD_KAFOR_unpack_8len_31bw_8offset<uint32_t>, 8, 0, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_122 = { SIMD_KAFOR_unpack_8len_31bw_16offset<uint32_t>, 16, 8, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_123 = { SIMD_KAFOR_unpack_8len_31bw_24offset<uint32_t>, 24, 16, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_124 = { SIMD_KAFOR_unpack_8len_32bw_0offset<uint32_t>, 0, 0, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_125 = { SIMD_KAFOR_unpack_8len_32bw_8offset<uint32_t>, 8, 8, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_126 = { SIMD_KAFOR_unpack_8len_32bw_16offset<uint32_t>, 16, 16, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_127 = { SIMD_KAFOR_unpack_8len_32bw_24offset<uint32_t>, 24, 24, 32, 32, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_128 = { SIMD_KAFOR_unpack_16len_1bw_0offset<uint32_t>, 0, 16, 0, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_129 = { SIMD_KAFOR_unpack_16len_1bw_8offset<uint32_t>, 8, 24, 0, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_130 = { SIMD_KAFOR_unpack_16len_1bw_16offset<uint32_t>, 16, 0, 4, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_131 = { SIMD_KAFOR_unpack_16len_1bw_24offset<uint32_t>, 24, 8, 4, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_132 = { SIMD_KAFOR_unpack_16len_2bw_0offset<uint32_t>, 0, 0, 4, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_133 = { SIMD_KAFOR_unpack_16len_2bw_8offset<uint32_t>, 8, 8, 4, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_134 = { SIMD_KAFOR_unpack_16len_2bw_16offset<uint32_t>, 16, 16, 4, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_135 = { SIMD_KAFOR_unpack_16len_2bw_24offset<uint32_t>, 24, 24, 4, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_136 = { SIMD_KAFOR_unpack_16len_3bw_0offset<uint32_t>, 0, 16, 4, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_137 = { SIMD_KAFOR_unpack_16len_3bw_8offset<uint32_t>, 8, 24, 4, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_138 = { SIMD_KAFOR_unpack_16len_3bw_16offset<uint32_t>, 16, 0, 8, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_139 = { SIMD_KAFOR_unpack_16len_3bw_24offset<uint32_t>, 24, 8, 8, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_140 = { SIMD_KAFOR_unpack_16len_4bw_0offset<uint32_t>, 0, 0, 8, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_141 = { SIMD_KAFOR_unpack_16len_4bw_8offset<uint32_t>, 8, 8, 8, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_142 = { SIMD_KAFOR_unpack_16len_4bw_16offset<uint32_t>, 16, 16, 8, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_143 = { SIMD_KAFOR_unpack_16len_4bw_24offset<uint32_t>, 24, 24, 8, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_144 = { SIMD_KAFOR_unpack_16len_5bw_0offset<uint32_t>, 0, 16, 8, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_145 = { SIMD_KAFOR_unpack_16len_5bw_8offset<uint32_t>, 8, 24, 8, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_146 = { SIMD_KAFOR_unpack_16len_5bw_16offset<uint32_t>, 16, 0, 12, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_147 = { SIMD_KAFOR_unpack_16len_5bw_24offset<uint32_t>, 24, 8, 12, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_148 = { SIMD_KAFOR_unpack_16len_6bw_0offset<uint32_t>, 0, 0, 12, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_149 = { SIMD_KAFOR_unpack_16len_6bw_8offset<uint32_t>, 8, 8, 12, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_150 = { SIMD_KAFOR_unpack_16len_6bw_16offset<uint32_t>, 16, 16, 12, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_151 = { SIMD_KAFOR_unpack_16len_6bw_24offset<uint32_t>, 24, 24, 12, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_152 = { SIMD_KAFOR_unpack_16len_7bw_0offset<uint32_t>, 0, 16, 12, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_153 = { SIMD_KAFOR_unpack_16len_7bw_8offset<uint32_t>, 8, 24, 12, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_154 = { SIMD_KAFOR_unpack_16len_7bw_16offset<uint32_t>, 16, 0, 16, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_155 = { SIMD_KAFOR_unpack_16len_7bw_24offset<uint32_t>, 24, 8, 16, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_156 = { SIMD_KAFOR_unpack_16len_8bw_0offset<uint32_t>, 0, 0, 16, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_157 = { SIMD_KAFOR_unpack_16len_8bw_8offset<uint32_t>, 8, 8, 16, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_158 = { SIMD_KAFOR_unpack_16len_8bw_16offset<uint32_t>, 16, 16, 16, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_159 = { SIMD_KAFOR_unpack_16len_8bw_24offset<uint32_t>, 24, 24, 16, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_160 = { SIMD_KAFOR_unpack_16len_9bw_0offset<uint32_t>, 0, 16, 16, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_161 = { SIMD_KAFOR_unpack_16len_9bw_8offset<uint32_t>, 8, 24, 16, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_162 = { SIMD_KAFOR_unpack_16len_9bw_16offset<uint32_t>, 16, 0, 20, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_163 = { SIMD_KAFOR_unpack_16len_9bw_24offset<uint32_t>, 24, 8, 20, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_164 = { SIMD_KAFOR_unpack_16len_10bw_0offset<uint32_t>, 0, 0, 20, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_165 = { SIMD_KAFOR_unpack_16len_10bw_8offset<uint32_t>, 8, 8, 20, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_166 = { SIMD_KAFOR_unpack_16len_10bw_16offset<uint32_t>, 16, 16, 20, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_167 = { SIMD_KAFOR_unpack_16len_10bw_24offset<uint32_t>, 24, 24, 20, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_168 = { SIMD_KAFOR_unpack_16len_11bw_0offset<uint32_t>, 0, 16, 20, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_169 = { SIMD_KAFOR_unpack_16len_11bw_8offset<uint32_t>, 8, 24, 20, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_170 = { SIMD_KAFOR_unpack_16len_11bw_16offset<uint32_t>, 16, 0, 24, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_171 = { SIMD_KAFOR_unpack_16len_11bw_24offset<uint32_t>, 24, 8, 24, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_172 = { SIMD_KAFOR_unpack_16len_12bw_0offset<uint32_t>, 0, 0, 24, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_173 = { SIMD_KAFOR_unpack_16len_12bw_8offset<uint32_t>, 8, 8, 24, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_174 = { SIMD_KAFOR_unpack_16len_12bw_16offset<uint32_t>, 16, 16, 24, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_175 = { SIMD_KAFOR_unpack_16len_12bw_24offset<uint32_t>, 24, 24, 24, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_176 = { SIMD_KAFOR_unpack_16len_13bw_0offset<uint32_t>, 0, 16, 24, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_177 = { SIMD_KAFOR_unpack_16len_13bw_8offset<uint32_t>, 8, 24, 24, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_178 = { SIMD_KAFOR_unpack_16len_13bw_16offset<uint32_t>, 16, 0, 28, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_179 = { SIMD_KAFOR_unpack_16len_13bw_24offset<uint32_t>, 24, 8, 28, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_180 = { SIMD_KAFOR_unpack_16len_14bw_0offset<uint32_t>, 0, 0, 28, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_181 = { SIMD_KAFOR_unpack_16len_14bw_8offset<uint32_t>, 8, 8, 28, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_182 = { SIMD_KAFOR_unpack_16len_14bw_16offset<uint32_t>, 16, 16, 28, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_183 = { SIMD_KAFOR_unpack_16len_14bw_24offset<uint32_t>, 24, 24, 28, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_184 = { SIMD_KAFOR_unpack_16len_15bw_0offset<uint32_t>, 0, 16, 28, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_185 = { SIMD_KAFOR_unpack_16len_15bw_8offset<uint32_t>, 8, 24, 28, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_186 = { SIMD_KAFOR_unpack_16len_15bw_16offset<uint32_t>, 16, 0, 32, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_187 = { SIMD_KAFOR_unpack_16len_15bw_24offset<uint32_t>, 24, 8, 32, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_188 = { SIMD_KAFOR_unpack_16len_16bw_0offset<uint32_t>, 0, 0, 32, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_189 = { SIMD_KAFOR_unpack_16len_16bw_8offset<uint32_t>, 8, 8, 32, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_190 = { SIMD_KAFOR_unpack_16len_16bw_16offset<uint32_t>, 16, 16, 32, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_191 = { SIMD_KAFOR_unpack_16len_16bw_24offset<uint32_t>, 24, 24, 32, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_192 = { SIMD_KAFOR_unpack_16len_17bw_0offset<uint32_t>, 0, 16, 32, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_193 = { SIMD_KAFOR_unpack_16len_17bw_8offset<uint32_t>, 8, 24, 32, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_194 = { SIMD_KAFOR_unpack_16len_17bw_16offset<uint32_t>, 16, 0, 36, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_195 = { SIMD_KAFOR_unpack_16len_17bw_24offset<uint32_t>, 24, 8, 36, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_196 = { SIMD_KAFOR_unpack_16len_18bw_0offset<uint32_t>, 0, 0, 36, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_197 = { SIMD_KAFOR_unpack_16len_18bw_8offset<uint32_t>, 8, 8, 36, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_198 = { SIMD_KAFOR_unpack_16len_18bw_16offset<uint32_t>, 16, 16, 36, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_199 = { SIMD_KAFOR_unpack_16len_18bw_24offset<uint32_t>, 24, 24, 36, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_200 = { SIMD_KAFOR_unpack_16len_19bw_0offset<uint32_t>, 0, 16, 36, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_201 = { SIMD_KAFOR_unpack_16len_19bw_8offset<uint32_t>, 8, 24, 36, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_202 = { SIMD_KAFOR_unpack_16len_19bw_16offset<uint32_t>, 16, 0, 40, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_203 = { SIMD_KAFOR_unpack_16len_19bw_24offset<uint32_t>, 24, 8, 40, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_204 = { SIMD_KAFOR_unpack_16len_20bw_0offset<uint32_t>, 0, 0, 40, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_205 = { SIMD_KAFOR_unpack_16len_20bw_8offset<uint32_t>, 8, 8, 40, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_206 = { SIMD_KAFOR_unpack_16len_20bw_16offset<uint32_t>, 16, 16, 40, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_207 = { SIMD_KAFOR_unpack_16len_20bw_24offset<uint32_t>, 24, 24, 40, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_208 = { SIMD_KAFOR_unpack_16len_21bw_0offset<uint32_t>, 0, 16, 40, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_209 = { SIMD_KAFOR_unpack_16len_21bw_8offset<uint32_t>, 8, 24, 40, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_210 = { SIMD_KAFOR_unpack_16len_21bw_16offset<uint32_t>, 16, 0, 44, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_211 = { SIMD_KAFOR_unpack_16len_21bw_24offset<uint32_t>, 24, 8, 44, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_212 = { SIMD_KAFOR_unpack_16len_22bw_0offset<uint32_t>, 0, 0, 44, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_213 = { SIMD_KAFOR_unpack_16len_22bw_8offset<uint32_t>, 8, 8, 44, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_214 = { SIMD_KAFOR_unpack_16len_22bw_16offset<uint32_t>, 16, 16, 44, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_215 = { SIMD_KAFOR_unpack_16len_22bw_24offset<uint32_t>, 24, 24, 44, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_216 = { SIMD_KAFOR_unpack_16len_23bw_0offset<uint32_t>, 0, 16, 44, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_217 = { SIMD_KAFOR_unpack_16len_23bw_8offset<uint32_t>, 8, 24, 44, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_218 = { SIMD_KAFOR_unpack_16len_23bw_16offset<uint32_t>, 16, 0, 48, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_219 = { SIMD_KAFOR_unpack_16len_23bw_24offset<uint32_t>, 24, 8, 48, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_220 = { SIMD_KAFOR_unpack_16len_24bw_0offset<uint32_t>, 0, 0, 48, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_221 = { SIMD_KAFOR_unpack_16len_24bw_8offset<uint32_t>, 8, 8, 48, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_222 = { SIMD_KAFOR_unpack_16len_24bw_16offset<uint32_t>, 16, 16, 48, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_223 = { SIMD_KAFOR_unpack_16len_24bw_24offset<uint32_t>, 24, 24, 48, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_224 = { SIMD_KAFOR_unpack_16len_25bw_0offset<uint32_t>, 0, 16, 48, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_225 = { SIMD_KAFOR_unpack_16len_25bw_8offset<uint32_t>, 8, 24, 48, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_226 = { SIMD_KAFOR_unpack_16len_25bw_16offset<uint32_t>, 16, 0, 52, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_227 = { SIMD_KAFOR_unpack_16len_25bw_24offset<uint32_t>, 24, 8, 52, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_228 = { SIMD_KAFOR_unpack_16len_26bw_0offset<uint32_t>, 0, 0, 52, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_229 = { SIMD_KAFOR_unpack_16len_26bw_8offset<uint32_t>, 8, 8, 52, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_230 = { SIMD_KAFOR_unpack_16len_26bw_16offset<uint32_t>, 16, 16, 52, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_231 = { SIMD_KAFOR_unpack_16len_26bw_24offset<uint32_t>, 24, 24, 52, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_232 = { SIMD_KAFOR_unpack_16len_27bw_0offset<uint32_t>, 0, 16, 52, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_233 = { SIMD_KAFOR_unpack_16len_27bw_8offset<uint32_t>, 8, 24, 52, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_234 = { SIMD_KAFOR_unpack_16len_27bw_16offset<uint32_t>, 16, 0, 56, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_235 = { SIMD_KAFOR_unpack_16len_27bw_24offset<uint32_t>, 24, 8, 56, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_236 = { SIMD_KAFOR_unpack_16len_28bw_0offset<uint32_t>, 0, 0, 56, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_237 = { SIMD_KAFOR_unpack_16len_28bw_8offset<uint32_t>, 8, 8, 56, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_238 = { SIMD_KAFOR_unpack_16len_28bw_16offset<uint32_t>, 16, 16, 56, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_239 = { SIMD_KAFOR_unpack_16len_28bw_24offset<uint32_t>, 24, 24, 56, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_240 = { SIMD_KAFOR_unpack_16len_29bw_0offset<uint32_t>, 0, 16, 56, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_241 = { SIMD_KAFOR_unpack_16len_29bw_8offset<uint32_t>, 8, 24, 56, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_242 = { SIMD_KAFOR_unpack_16len_29bw_16offset<uint32_t>, 16, 0, 60, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_243 = { SIMD_KAFOR_unpack_16len_29bw_24offset<uint32_t>, 24, 8, 60, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_244 = { SIMD_KAFOR_unpack_16len_30bw_0offset<uint32_t>, 0, 0, 60, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_245 = { SIMD_KAFOR_unpack_16len_30bw_8offset<uint32_t>, 8, 8, 60, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_246 = { SIMD_KAFOR_unpack_16len_30bw_16offset<uint32_t>, 16, 16, 60, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_247 = { SIMD_KAFOR_unpack_16len_30bw_24offset<uint32_t>, 24, 24, 60, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_248 = { SIMD_KAFOR_unpack_16len_31bw_0offset<uint32_t>, 0, 16, 60, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_249 = { SIMD_KAFOR_unpack_16len_31bw_8offset<uint32_t>, 8, 24, 60, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_250 = { SIMD_KAFOR_unpack_16len_31bw_16offset<uint32_t>, 16, 0, 64, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_251 = { SIMD_KAFOR_unpack_16len_31bw_24offset<uint32_t>, 24, 8, 64, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_252 = { SIMD_KAFOR_unpack_16len_32bw_0offset<uint32_t>, 0, 0, 64, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_253 = { SIMD_KAFOR_unpack_16len_32bw_8offset<uint32_t>, 8, 8, 64, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_254 = { SIMD_KAFOR_unpack_16len_32bw_16offset<uint32_t>, 16, 16, 64, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_255 = { SIMD_KAFOR_unpack_16len_32bw_24offset<uint32_t>, 24, 24, 64, 64, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_256 = { SIMD_KAFOR_unpack_32len_1bw_0offset<uint32_t>, 0, 0, 4, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_257 = { SIMD_KAFOR_unpack_32len_1bw_8offset<uint32_t>, 8, 8, 4, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_258 = { SIMD_KAFOR_unpack_32len_1bw_16offset<uint32_t>, 16, 16, 4, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_259 = { SIMD_KAFOR_unpack_32len_1bw_24offset<uint32_t>, 24, 24, 4, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_260 = { SIMD_KAFOR_unpack_32len_2bw_0offset<uint32_t>, 0, 0, 8, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_261 = { SIMD_KAFOR_unpack_32len_2bw_8offset<uint32_t>, 8, 8, 8, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_262 = { SIMD_KAFOR_unpack_32len_2bw_16offset<uint32_t>, 16, 16, 8, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_263 = { SIMD_KAFOR_unpack_32len_2bw_24offset<uint32_t>, 24, 24, 8, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_264 = { SIMD_KAFOR_unpack_32len_3bw_0offset<uint32_t>, 0, 0, 12, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_265 = { SIMD_KAFOR_unpack_32len_3bw_8offset<uint32_t>, 8, 8, 12, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_266 = { SIMD_KAFOR_unpack_32len_3bw_16offset<uint32_t>, 16, 16, 12, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_267 = { SIMD_KAFOR_unpack_32len_3bw_24offset<uint32_t>, 24, 24, 12, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_268 = { SIMD_KAFOR_unpack_32len_4bw_0offset<uint32_t>, 0, 0, 16, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_269 = { SIMD_KAFOR_unpack_32len_4bw_8offset<uint32_t>, 8, 8, 16, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_270 = { SIMD_KAFOR_unpack_32len_4bw_16offset<uint32_t>, 16, 16, 16, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_271 = { SIMD_KAFOR_unpack_32len_4bw_24offset<uint32_t>, 24, 24, 16, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_272 = { SIMD_KAFOR_unpack_32len_5bw_0offset<uint32_t>, 0, 0, 20, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_273 = { SIMD_KAFOR_unpack_32len_5bw_8offset<uint32_t>, 8, 8, 20, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_274 = { SIMD_KAFOR_unpack_32len_5bw_16offset<uint32_t>, 16, 16, 20, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_275 = { SIMD_KAFOR_unpack_32len_5bw_24offset<uint32_t>, 24, 24, 20, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_276 = { SIMD_KAFOR_unpack_32len_6bw_0offset<uint32_t>, 0, 0, 24, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_277 = { SIMD_KAFOR_unpack_32len_6bw_8offset<uint32_t>, 8, 8, 24, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_278 = { SIMD_KAFOR_unpack_32len_6bw_16offset<uint32_t>, 16, 16, 24, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_279 = { SIMD_KAFOR_unpack_32len_6bw_24offset<uint32_t>, 24, 24, 24, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_280 = { SIMD_KAFOR_unpack_32len_7bw_0offset<uint32_t>, 0, 0, 28, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_281 = { SIMD_KAFOR_unpack_32len_7bw_8offset<uint32_t>, 8, 8, 28, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_282 = { SIMD_KAFOR_unpack_32len_7bw_16offset<uint32_t>, 16, 16, 28, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_283 = { SIMD_KAFOR_unpack_32len_7bw_24offset<uint32_t>, 24, 24, 28, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_284 = { SIMD_KAFOR_unpack_32len_8bw_0offset<uint32_t>, 0, 0, 32, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_285 = { SIMD_KAFOR_unpack_32len_8bw_8offset<uint32_t>, 8, 8, 32, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_286 = { SIMD_KAFOR_unpack_32len_8bw_16offset<uint32_t>, 16, 16, 32, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_287 = { SIMD_KAFOR_unpack_32len_8bw_24offset<uint32_t>, 24, 24, 32, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_288 = { SIMD_KAFOR_unpack_32len_9bw_0offset<uint32_t>, 0, 0, 36, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_289 = { SIMD_KAFOR_unpack_32len_9bw_8offset<uint32_t>, 8, 8, 36, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_290 = { SIMD_KAFOR_unpack_32len_9bw_16offset<uint32_t>, 16, 16, 36, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_291 = { SIMD_KAFOR_unpack_32len_9bw_24offset<uint32_t>, 24, 24, 36, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_292 = { SIMD_KAFOR_unpack_32len_10bw_0offset<uint32_t>, 0, 0, 40, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_293 = { SIMD_KAFOR_unpack_32len_10bw_8offset<uint32_t>, 8, 8, 40, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_294 = { SIMD_KAFOR_unpack_32len_10bw_16offset<uint32_t>, 16, 16, 40, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_295 = { SIMD_KAFOR_unpack_32len_10bw_24offset<uint32_t>, 24, 24, 40, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_296 = { SIMD_KAFOR_unpack_32len_11bw_0offset<uint32_t>, 0, 0, 44, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_297 = { SIMD_KAFOR_unpack_32len_11bw_8offset<uint32_t>, 8, 8, 44, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_298 = { SIMD_KAFOR_unpack_32len_11bw_16offset<uint32_t>, 16, 16, 44, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_299 = { SIMD_KAFOR_unpack_32len_11bw_24offset<uint32_t>, 24, 24, 44, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_300 = { SIMD_KAFOR_unpack_32len_12bw_0offset<uint32_t>, 0, 0, 48, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_301 = { SIMD_KAFOR_unpack_32len_12bw_8offset<uint32_t>, 8, 8, 48, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_302 = { SIMD_KAFOR_unpack_32len_12bw_16offset<uint32_t>, 16, 16, 48, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_303 = { SIMD_KAFOR_unpack_32len_12bw_24offset<uint32_t>, 24, 24, 48, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_304 = { SIMD_KAFOR_unpack_32len_13bw_0offset<uint32_t>, 0, 0, 52, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_305 = { SIMD_KAFOR_unpack_32len_13bw_8offset<uint32_t>, 8, 8, 52, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_306 = { SIMD_KAFOR_unpack_32len_13bw_16offset<uint32_t>, 16, 16, 52, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_307 = { SIMD_KAFOR_unpack_32len_13bw_24offset<uint32_t>, 24, 24, 52, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_308 = { SIMD_KAFOR_unpack_32len_14bw_0offset<uint32_t>, 0, 0, 56, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_309 = { SIMD_KAFOR_unpack_32len_14bw_8offset<uint32_t>, 8, 8, 56, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_310 = { SIMD_KAFOR_unpack_32len_14bw_16offset<uint32_t>, 16, 16, 56, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_311 = { SIMD_KAFOR_unpack_32len_14bw_24offset<uint32_t>, 24, 24, 56, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_312 = { SIMD_KAFOR_unpack_32len_15bw_0offset<uint32_t>, 0, 0, 60, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_313 = { SIMD_KAFOR_unpack_32len_15bw_8offset<uint32_t>, 8, 8, 60, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_314 = { SIMD_KAFOR_unpack_32len_15bw_16offset<uint32_t>, 16, 16, 60, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_315 = { SIMD_KAFOR_unpack_32len_15bw_24offset<uint32_t>, 24, 24, 60, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_316 = { SIMD_KAFOR_unpack_32len_16bw_0offset<uint32_t>, 0, 0, 64, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_317 = { SIMD_KAFOR_unpack_32len_16bw_8offset<uint32_t>, 8, 8, 64, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_318 = { SIMD_KAFOR_unpack_32len_16bw_16offset<uint32_t>, 16, 16, 64, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_319 = { SIMD_KAFOR_unpack_32len_16bw_24offset<uint32_t>, 24, 24, 64, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_320 = { SIMD_KAFOR_unpack_32len_17bw_0offset<uint32_t>, 0, 0, 68, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_321 = { SIMD_KAFOR_unpack_32len_17bw_8offset<uint32_t>, 8, 8, 68, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_322 = { SIMD_KAFOR_unpack_32len_17bw_16offset<uint32_t>, 16, 16, 68, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_323 = { SIMD_KAFOR_unpack_32len_17bw_24offset<uint32_t>, 24, 24, 68, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_324 = { SIMD_KAFOR_unpack_32len_18bw_0offset<uint32_t>, 0, 0, 72, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_325 = { SIMD_KAFOR_unpack_32len_18bw_8offset<uint32_t>, 8, 8, 72, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_326 = { SIMD_KAFOR_unpack_32len_18bw_16offset<uint32_t>, 16, 16, 72, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_327 = { SIMD_KAFOR_unpack_32len_18bw_24offset<uint32_t>, 24, 24, 72, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_328 = { SIMD_KAFOR_unpack_32len_19bw_0offset<uint32_t>, 0, 0, 76, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_329 = { SIMD_KAFOR_unpack_32len_19bw_8offset<uint32_t>, 8, 8, 76, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_330 = { SIMD_KAFOR_unpack_32len_19bw_16offset<uint32_t>, 16, 16, 76, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_331 = { SIMD_KAFOR_unpack_32len_19bw_24offset<uint32_t>, 24, 24, 76, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_332 = { SIMD_KAFOR_unpack_32len_20bw_0offset<uint32_t>, 0, 0, 80, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_333 = { SIMD_KAFOR_unpack_32len_20bw_8offset<uint32_t>, 8, 8, 80, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_334 = { SIMD_KAFOR_unpack_32len_20bw_16offset<uint32_t>, 16, 16, 80, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_335 = { SIMD_KAFOR_unpack_32len_20bw_24offset<uint32_t>, 24, 24, 80, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_336 = { SIMD_KAFOR_unpack_32len_21bw_0offset<uint32_t>, 0, 0, 84, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_337 = { SIMD_KAFOR_unpack_32len_21bw_8offset<uint32_t>, 8, 8, 84, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_338 = { SIMD_KAFOR_unpack_32len_21bw_16offset<uint32_t>, 16, 16, 84, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_339 = { SIMD_KAFOR_unpack_32len_21bw_24offset<uint32_t>, 24, 24, 84, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_340 = { SIMD_KAFOR_unpack_32len_22bw_0offset<uint32_t>, 0, 0, 88, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_341 = { SIMD_KAFOR_unpack_32len_22bw_8offset<uint32_t>, 8, 8, 88, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_342 = { SIMD_KAFOR_unpack_32len_22bw_16offset<uint32_t>, 16, 16, 88, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_343 = { SIMD_KAFOR_unpack_32len_22bw_24offset<uint32_t>, 24, 24, 88, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_344 = { SIMD_KAFOR_unpack_32len_23bw_0offset<uint32_t>, 0, 0, 92, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_345 = { SIMD_KAFOR_unpack_32len_23bw_8offset<uint32_t>, 8, 8, 92, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_346 = { SIMD_KAFOR_unpack_32len_23bw_16offset<uint32_t>, 16, 16, 92, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_347 = { SIMD_KAFOR_unpack_32len_23bw_24offset<uint32_t>, 24, 24, 92, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_348 = { SIMD_KAFOR_unpack_32len_24bw_0offset<uint32_t>, 0, 0, 96, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_349 = { SIMD_KAFOR_unpack_32len_24bw_8offset<uint32_t>, 8, 8, 96, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_350 = { SIMD_KAFOR_unpack_32len_24bw_16offset<uint32_t>, 16, 16, 96, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_351 = { SIMD_KAFOR_unpack_32len_24bw_24offset<uint32_t>, 24, 24, 96, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_352 = { SIMD_KAFOR_unpack_32len_25bw_0offset<uint32_t>, 0, 0, 100, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_353 = { SIMD_KAFOR_unpack_32len_25bw_8offset<uint32_t>, 8, 8, 100, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_354 = { SIMD_KAFOR_unpack_32len_25bw_16offset<uint32_t>, 16, 16, 100, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_355 = { SIMD_KAFOR_unpack_32len_25bw_24offset<uint32_t>, 24, 24, 100, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_356 = { SIMD_KAFOR_unpack_32len_26bw_0offset<uint32_t>, 0, 0, 104, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_357 = { SIMD_KAFOR_unpack_32len_26bw_8offset<uint32_t>, 8, 8, 104, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_358 = { SIMD_KAFOR_unpack_32len_26bw_16offset<uint32_t>, 16, 16, 104, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_359 = { SIMD_KAFOR_unpack_32len_26bw_24offset<uint32_t>, 24, 24, 104, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_360 = { SIMD_KAFOR_unpack_32len_27bw_0offset<uint32_t>, 0, 0, 108, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_361 = { SIMD_KAFOR_unpack_32len_27bw_8offset<uint32_t>, 8, 8, 108, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_362 = { SIMD_KAFOR_unpack_32len_27bw_16offset<uint32_t>, 16, 16, 108, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_363 = { SIMD_KAFOR_unpack_32len_27bw_24offset<uint32_t>, 24, 24, 108, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_364 = { SIMD_KAFOR_unpack_32len_28bw_0offset<uint32_t>, 0, 0, 112, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_365 = { SIMD_KAFOR_unpack_32len_28bw_8offset<uint32_t>, 8, 8, 112, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_366 = { SIMD_KAFOR_unpack_32len_28bw_16offset<uint32_t>, 16, 16, 112, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_367 = { SIMD_KAFOR_unpack_32len_28bw_24offset<uint32_t>, 24, 24, 112, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_368 = { SIMD_KAFOR_unpack_32len_29bw_0offset<uint32_t>, 0, 0, 116, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_369 = { SIMD_KAFOR_unpack_32len_29bw_8offset<uint32_t>, 8, 8, 116, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_370 = { SIMD_KAFOR_unpack_32len_29bw_16offset<uint32_t>, 16, 16, 116, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_371 = { SIMD_KAFOR_unpack_32len_29bw_24offset<uint32_t>, 24, 24, 116, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_372 = { SIMD_KAFOR_unpack_32len_30bw_0offset<uint32_t>, 0, 0, 120, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_373 = { SIMD_KAFOR_unpack_32len_30bw_8offset<uint32_t>, 8, 8, 120, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_374 = { SIMD_KAFOR_unpack_32len_30bw_16offset<uint32_t>, 16, 16, 120, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_375 = { SIMD_KAFOR_unpack_32len_30bw_24offset<uint32_t>, 24, 24, 120, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_376 = { SIMD_KAFOR_unpack_32len_31bw_0offset<uint32_t>, 0, 0, 124, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_377 = { SIMD_KAFOR_unpack_32len_31bw_8offset<uint32_t>, 8, 8, 124, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_378 = { SIMD_KAFOR_unpack_32len_31bw_16offset<uint32_t>, 16, 16, 124, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_379 = { SIMD_KAFOR_unpack_32len_31bw_24offset<uint32_t>, 24, 24, 124, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_380 = { SIMD_KAFOR_unpack_32len_32bw_0offset<uint32_t>, 0, 0, 128, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_381 = { SIMD_KAFOR_unpack_32len_32bw_8offset<uint32_t>, 8, 8, 128, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_382 = { SIMD_KAFOR_unpack_32len_32bw_16offset<uint32_t>, 16, 16, 128, 128, };
static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_383 = { SIMD_KAFOR_unpack_32len_32bw_24offset<uint32_t>, 24, 24, 128, 128, };

static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfoArr[384] = {
	SIMD_KAFORUnpackInfo_0, SIMD_KAFORUnpackInfo_1, SIMD_KAFORUnpackInfo_2, SIMD_KAFORUnpackInfo_3,
	SIMD_KAFORUnpackInfo_4, SIMD_KAFORUnpackInfo_5, SIMD_KAFORUnpackInfo_6, SIMD_KAFORUnpackInfo_7,
	SIMD_KAFORUnpackInfo_8, SIMD_KAFORUnpackInfo_9, SIMD_KAFORUnpackInfo_10, SIMD_KAFORUnpackInfo_11,
	SIMD_KAFORUnpackInfo_12, SIMD_KAFORUnpackInfo_13, SIMD_KAFORUnpackInfo_14, SIMD_KAFORUnpackInfo_15,
	SIMD_KAFORUnpackInfo_16, SIMD_KAFORUnpackInfo_17, SIMD_KAFORUnpackInfo_18, SIMD_KAFORUnpackInfo_19,
	SIMD_KAFORUnpackInfo_20, SIMD_KAFORUnpackInfo_21, SIMD_KAFORUnpackInfo_22, SIMD_KAFORUnpackInfo_23,
	SIMD_KAFORUnpackInfo_24, SIMD_KAFORUnpackInfo_25, SIMD_KAFORUnpackInfo_26, SIMD_KAFORUnpackInfo_27,
	SIMD_KAFORUnpackInfo_28, SIMD_KAFORUnpackInfo_29, SIMD_KAFORUnpackInfo_30, SIMD_KAFORUnpackInfo_31,
	SIMD_KAFORUnpackInfo_32, SIMD_KAFORUnpackInfo_33, SIMD_KAFORUnpackInfo_34, SIMD_KAFORUnpackInfo_35,
	SIMD_KAFORUnpackInfo_36, SIMD_KAFORUnpackInfo_37, SIMD_KAFORUnpackInfo_38, SIMD_KAFORUnpackInfo_39,
	SIMD_KAFORUnpackInfo_40, SIMD_KAFORUnpackInfo_41, SIMD_KAFORUnpackInfo_42, SIMD_KAFORUnpackInfo_43,
	SIMD_KAFORUnpackInfo_44, SIMD_KAFORUnpackInfo_45, SIMD_KAFORUnpackInfo_46, SIMD_KAFORUnpackInfo_47,
	SIMD_KAFORUnpackInfo_48, SIMD_KAFORUnpackInfo_49, SIMD_KAFORUnpackInfo_50, SIMD_KAFORUnpackInfo_51,
	SIMD_KAFORUnpackInfo_52, SIMD_KAFORUnpackInfo_53, SIMD_KAFORUnpackInfo_54, SIMD_KAFORUnpackInfo_55,
	SIMD_KAFORUnpackInfo_56, SIMD_KAFORUnpackInfo_57, SIMD_KAFORUnpackInfo_58, SIMD_KAFORUnpackInfo_59,
	SIMD_KAFORUnpackInfo_60, SIMD_KAFORUnpackInfo_61, SIMD_KAFORUnpackInfo_62, SIMD_KAFORUnpackInfo_63,
	SIMD_KAFORUnpackInfo_64, SIMD_KAFORUnpackInfo_65, SIMD_KAFORUnpackInfo_66, SIMD_KAFORUnpackInfo_67,
	SIMD_KAFORUnpackInfo_68, SIMD_KAFORUnpackInfo_69, SIMD_KAFORUnpackInfo_70, SIMD_KAFORUnpackInfo_71,
	SIMD_KAFORUnpackInfo_72, SIMD_KAFORUnpackInfo_73, SIMD_KAFORUnpackInfo_74, SIMD_KAFORUnpackInfo_75,
	SIMD_KAFORUnpackInfo_76, SIMD_KAFORUnpackInfo_77, SIMD_KAFORUnpackInfo_78, SIMD_KAFORUnpackInfo_79,
	SIMD_KAFORUnpackInfo_80, SIMD_KAFORUnpackInfo_81, SIMD_KAFORUnpackInfo_82, SIMD_KAFORUnpackInfo_83,
	SIMD_KAFORUnpackInfo_84, SIMD_KAFORUnpackInfo_85, SIMD_KAFORUnpackInfo_86, SIMD_KAFORUnpackInfo_87,
	SIMD_KAFORUnpackInfo_88, SIMD_KAFORUnpackInfo_89, SIMD_KAFORUnpackInfo_90, SIMD_KAFORUnpackInfo_91,
	SIMD_KAFORUnpackInfo_92, SIMD_KAFORUnpackInfo_93, SIMD_KAFORUnpackInfo_94, SIMD_KAFORUnpackInfo_95,
	SIMD_KAFORUnpackInfo_96, SIMD_KAFORUnpackInfo_97, SIMD_KAFORUnpackInfo_98, SIMD_KAFORUnpackInfo_99,
	SIMD_KAFORUnpackInfo_100, SIMD_KAFORUnpackInfo_101, SIMD_KAFORUnpackInfo_102, SIMD_KAFORUnpackInfo_103,
	SIMD_KAFORUnpackInfo_104, SIMD_KAFORUnpackInfo_105, SIMD_KAFORUnpackInfo_106, SIMD_KAFORUnpackInfo_107,
	SIMD_KAFORUnpackInfo_108, SIMD_KAFORUnpackInfo_109, SIMD_KAFORUnpackInfo_110, SIMD_KAFORUnpackInfo_111,
	SIMD_KAFORUnpackInfo_112, SIMD_KAFORUnpackInfo_113, SIMD_KAFORUnpackInfo_114, SIMD_KAFORUnpackInfo_115,
	SIMD_KAFORUnpackInfo_116, SIMD_KAFORUnpackInfo_117, SIMD_KAFORUnpackInfo_118, SIMD_KAFORUnpackInfo_119,
	SIMD_KAFORUnpackInfo_120, SIMD_KAFORUnpackInfo_121, SIMD_KAFORUnpackInfo_122, SIMD_KAFORUnpackInfo_123,
	SIMD_KAFORUnpackInfo_124, SIMD_KAFORUnpackInfo_125, SIMD_KAFORUnpackInfo_126, SIMD_KAFORUnpackInfo_127,
	SIMD_KAFORUnpackInfo_128, SIMD_KAFORUnpackInfo_129, SIMD_KAFORUnpackInfo_130, SIMD_KAFORUnpackInfo_131,
	SIMD_KAFORUnpackInfo_132, SIMD_KAFORUnpackInfo_133, SIMD_KAFORUnpackInfo_134, SIMD_KAFORUnpackInfo_135,
	SIMD_KAFORUnpackInfo_136, SIMD_KAFORUnpackInfo_137, SIMD_KAFORUnpackInfo_138, SIMD_KAFORUnpackInfo_139,
	SIMD_KAFORUnpackInfo_140, SIMD_KAFORUnpackInfo_141, SIMD_KAFORUnpackInfo_142, SIMD_KAFORUnpackInfo_143,
	SIMD_KAFORUnpackInfo_144, SIMD_KAFORUnpackInfo_145, SIMD_KAFORUnpackInfo_146, SIMD_KAFORUnpackInfo_147,
	SIMD_KAFORUnpackInfo_148, SIMD_KAFORUnpackInfo_149, SIMD_KAFORUnpackInfo_150, SIMD_KAFORUnpackInfo_151,
	SIMD_KAFORUnpackInfo_152, SIMD_KAFORUnpackInfo_153, SIMD_KAFORUnpackInfo_154, SIMD_KAFORUnpackInfo_155,
	SIMD_KAFORUnpackInfo_156, SIMD_KAFORUnpackInfo_157, SIMD_KAFORUnpackInfo_158, SIMD_KAFORUnpackInfo_159,
	SIMD_KAFORUnpackInfo_160, SIMD_KAFORUnpackInfo_161, SIMD_KAFORUnpackInfo_162, SIMD_KAFORUnpackInfo_163,
	SIMD_KAFORUnpackInfo_164, SIMD_KAFORUnpackInfo_165, SIMD_KAFORUnpackInfo_166, SIMD_KAFORUnpackInfo_167,
	SIMD_KAFORUnpackInfo_168, SIMD_KAFORUnpackInfo_169, SIMD_KAFORUnpackInfo_170, SIMD_KAFORUnpackInfo_171,
	SIMD_KAFORUnpackInfo_172, SIMD_KAFORUnpackInfo_173, SIMD_KAFORUnpackInfo_174, SIMD_KAFORUnpackInfo_175,
	SIMD_KAFORUnpackInfo_176, SIMD_KAFORUnpackInfo_177, SIMD_KAFORUnpackInfo_178, SIMD_KAFORUnpackInfo_179,
	SIMD_KAFORUnpackInfo_180, SIMD_KAFORUnpackInfo_181, SIMD_KAFORUnpackInfo_182, SIMD_KAFORUnpackInfo_183,
	SIMD_KAFORUnpackInfo_184, SIMD_KAFORUnpackInfo_185, SIMD_KAFORUnpackInfo_186, SIMD_KAFORUnpackInfo_187,
	SIMD_KAFORUnpackInfo_188, SIMD_KAFORUnpackInfo_189, SIMD_KAFORUnpackInfo_190, SIMD_KAFORUnpackInfo_191,
	SIMD_KAFORUnpackInfo_192, SIMD_KAFORUnpackInfo_193, SIMD_KAFORUnpackInfo_194, SIMD_KAFORUnpackInfo_195,
	SIMD_KAFORUnpackInfo_196, SIMD_KAFORUnpackInfo_197, SIMD_KAFORUnpackInfo_198, SIMD_KAFORUnpackInfo_199,
	SIMD_KAFORUnpackInfo_200, SIMD_KAFORUnpackInfo_201, SIMD_KAFORUnpackInfo_202, SIMD_KAFORUnpackInfo_203,
	SIMD_KAFORUnpackInfo_204, SIMD_KAFORUnpackInfo_205, SIMD_KAFORUnpackInfo_206, SIMD_KAFORUnpackInfo_207,
	SIMD_KAFORUnpackInfo_208, SIMD_KAFORUnpackInfo_209, SIMD_KAFORUnpackInfo_210, SIMD_KAFORUnpackInfo_211,
	SIMD_KAFORUnpackInfo_212, SIMD_KAFORUnpackInfo_213, SIMD_KAFORUnpackInfo_214, SIMD_KAFORUnpackInfo_215,
	SIMD_KAFORUnpackInfo_216, SIMD_KAFORUnpackInfo_217, SIMD_KAFORUnpackInfo_218, SIMD_KAFORUnpackInfo_219,
	SIMD_KAFORUnpackInfo_220, SIMD_KAFORUnpackInfo_221, SIMD_KAFORUnpackInfo_222, SIMD_KAFORUnpackInfo_223,
	SIMD_KAFORUnpackInfo_224, SIMD_KAFORUnpackInfo_225, SIMD_KAFORUnpackInfo_226, SIMD_KAFORUnpackInfo_227,
	SIMD_KAFORUnpackInfo_228, SIMD_KAFORUnpackInfo_229, SIMD_KAFORUnpackInfo_230, SIMD_KAFORUnpackInfo_231,
	SIMD_KAFORUnpackInfo_232, SIMD_KAFORUnpackInfo_233, SIMD_KAFORUnpackInfo_234, SIMD_KAFORUnpackInfo_235,
	SIMD_KAFORUnpackInfo_236, SIMD_KAFORUnpackInfo_237, SIMD_KAFORUnpackInfo_238, SIMD_KAFORUnpackInfo_239,
	SIMD_KAFORUnpackInfo_240, SIMD_KAFORUnpackInfo_241, SIMD_KAFORUnpackInfo_242, SIMD_KAFORUnpackInfo_243,
	SIMD_KAFORUnpackInfo_244, SIMD_KAFORUnpackInfo_245, SIMD_KAFORUnpackInfo_246, SIMD_KAFORUnpackInfo_247,
	SIMD_KAFORUnpackInfo_248, SIMD_KAFORUnpackInfo_249, SIMD_KAFORUnpackInfo_250, SIMD_KAFORUnpackInfo_251,
	SIMD_KAFORUnpackInfo_252, SIMD_KAFORUnpackInfo_253, SIMD_KAFORUnpackInfo_254, SIMD_KAFORUnpackInfo_255,
	SIMD_KAFORUnpackInfo_256, SIMD_KAFORUnpackInfo_257, SIMD_KAFORUnpackInfo_258, SIMD_KAFORUnpackInfo_259,
	SIMD_KAFORUnpackInfo_260, SIMD_KAFORUnpackInfo_261, SIMD_KAFORUnpackInfo_262, SIMD_KAFORUnpackInfo_263,
	SIMD_KAFORUnpackInfo_264, SIMD_KAFORUnpackInfo_265, SIMD_KAFORUnpackInfo_266, SIMD_KAFORUnpackInfo_267,
	SIMD_KAFORUnpackInfo_268, SIMD_KAFORUnpackInfo_269, SIMD_KAFORUnpackInfo_270, SIMD_KAFORUnpackInfo_271,
	SIMD_KAFORUnpackInfo_272, SIMD_KAFORUnpackInfo_273, SIMD_KAFORUnpackInfo_274, SIMD_KAFORUnpackInfo_275,
	SIMD_KAFORUnpackInfo_276, SIMD_KAFORUnpackInfo_277, SIMD_KAFORUnpackInfo_278, SIMD_KAFORUnpackInfo_279,
	SIMD_KAFORUnpackInfo_280, SIMD_KAFORUnpackInfo_281, SIMD_KAFORUnpackInfo_282, SIMD_KAFORUnpackInfo_283,
	SIMD_KAFORUnpackInfo_284, SIMD_KAFORUnpackInfo_285, SIMD_KAFORUnpackInfo_286, SIMD_KAFORUnpackInfo_287,
	SIMD_KAFORUnpackInfo_288, SIMD_KAFORUnpackInfo_289, SIMD_KAFORUnpackInfo_290, SIMD_KAFORUnpackInfo_291,
	SIMD_KAFORUnpackInfo_292, SIMD_KAFORUnpackInfo_293, SIMD_KAFORUnpackInfo_294, SIMD_KAFORUnpackInfo_295,
	SIMD_KAFORUnpackInfo_296, SIMD_KAFORUnpackInfo_297, SIMD_KAFORUnpackInfo_298, SIMD_KAFORUnpackInfo_299,
	SIMD_KAFORUnpackInfo_300, SIMD_KAFORUnpackInfo_301, SIMD_KAFORUnpackInfo_302, SIMD_KAFORUnpackInfo_303,
	SIMD_KAFORUnpackInfo_304, SIMD_KAFORUnpackInfo_305, SIMD_KAFORUnpackInfo_306, SIMD_KAFORUnpackInfo_307,
	SIMD_KAFORUnpackInfo_308, SIMD_KAFORUnpackInfo_309, SIMD_KAFORUnpackInfo_310, SIMD_KAFORUnpackInfo_311,
	SIMD_KAFORUnpackInfo_312, SIMD_KAFORUnpackInfo_313, SIMD_KAFORUnpackInfo_314, SIMD_KAFORUnpackInfo_315,
	SIMD_KAFORUnpackInfo_316, SIMD_KAFORUnpackInfo_317, SIMD_KAFORUnpackInfo_318, SIMD_KAFORUnpackInfo_319,
	SIMD_KAFORUnpackInfo_320, SIMD_KAFORUnpackInfo_321, SIMD_KAFORUnpackInfo_322, SIMD_KAFORUnpackInfo_323,
	SIMD_KAFORUnpackInfo_324, SIMD_KAFORUnpackInfo_325, SIMD_KAFORUnpackInfo_326, SIMD_KAFORUnpackInfo_327,
	SIMD_KAFORUnpackInfo_328, SIMD_KAFORUnpackInfo_329, SIMD_KAFORUnpackInfo_330, SIMD_KAFORUnpackInfo_331,
	SIMD_KAFORUnpackInfo_332, SIMD_KAFORUnpackInfo_333, SIMD_KAFORUnpackInfo_334, SIMD_KAFORUnpackInfo_335,
	SIMD_KAFORUnpackInfo_336, SIMD_KAFORUnpackInfo_337, SIMD_KAFORUnpackInfo_338, SIMD_KAFORUnpackInfo_339,
	SIMD_KAFORUnpackInfo_340, SIMD_KAFORUnpackInfo_341, SIMD_KAFORUnpackInfo_342, SIMD_KAFORUnpackInfo_343,
	SIMD_KAFORUnpackInfo_344, SIMD_KAFORUnpackInfo_345, SIMD_KAFORUnpackInfo_346, SIMD_KAFORUnpackInfo_347,
	SIMD_KAFORUnpackInfo_348, SIMD_KAFORUnpackInfo_349, SIMD_KAFORUnpackInfo_350, SIMD_KAFORUnpackInfo_351,
	SIMD_KAFORUnpackInfo_352, SIMD_KAFORUnpackInfo_353, SIMD_KAFORUnpackInfo_354, SIMD_KAFORUnpackInfo_355,
	SIMD_KAFORUnpackInfo_356, SIMD_KAFORUnpackInfo_357, SIMD_KAFORUnpackInfo_358, SIMD_KAFORUnpackInfo_359,
	SIMD_KAFORUnpackInfo_360, SIMD_KAFORUnpackInfo_361, SIMD_KAFORUnpackInfo_362, SIMD_KAFORUnpackInfo_363,
	SIMD_KAFORUnpackInfo_364, SIMD_KAFORUnpackInfo_365, SIMD_KAFORUnpackInfo_366, SIMD_KAFORUnpackInfo_367,
	SIMD_KAFORUnpackInfo_368, SIMD_KAFORUnpackInfo_369, SIMD_KAFORUnpackInfo_370, SIMD_KAFORUnpackInfo_371,
	SIMD_KAFORUnpackInfo_372, SIMD_KAFORUnpackInfo_373, SIMD_KAFORUnpackInfo_374, SIMD_KAFORUnpackInfo_375,
	SIMD_KAFORUnpackInfo_376, SIMD_KAFORUnpackInfo_377, SIMD_KAFORUnpackInfo_378, SIMD_KAFORUnpackInfo_379,
	SIMD_KAFORUnpackInfo_380, SIMD_KAFORUnpackInfo_381, SIMD_KAFORUnpackInfo_382, SIMD_KAFORUnpackInfo_383,
};

}
}

#endif /* SIMD_KAFOR_UNPACK_HPP_ */

/*

#include <iostream>
#include <sstream>
#include <string>
#include <stdint.h>

using namespace std;

string TRIPLE_TAB = "\t\t\t";
string QUOTE_END_LINE = "\\n\"\n";
int BEG_REG_IDX = 3;

void GenCode(int num, int base, ostringstream &oss, ostringstream &infoOss) {
	//string IDX_STR = "i";

	for (int i=1; i<=32; i++) {
		for (int k=0; k<4; k++) {	//ori byte offset
			oss << "template<typename T>" << endl;
			oss << "void SIMD_KAFOR_unpack_" << num << "len_" << i << "bw_" << (k*8) << "offset(T * des, const uint32_t *src) {" << endl;
			int infoIdx = (base << 7) + ((i - 1) << 2) + k;
			infoOss << "static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfo_" << infoIdx << " = { " << "SIMD_KAFOR_unpack_"
					<< num << "len_" << i << "bw_" << (k*8) << "offset<uint32_t>, ";

			oss << "\t__asm__ volatile(\"prefetchnta %0\"::\"m\" (src[0]));\n";

			int offsetInWord = k << 3;
			int curWordIdx = 0;
			int j = 0;
			uint32_t mask  = (1LL << i) - 1;

			int asmBlockDstQuadWordCount = 4;

			int asmBlockIdx = 0;
			int asmBlockSrcQuadWordCount = 0;
			int curBlockSrcQuadWordIdx = 0;
			int curBlockDstQuadWordIdx = 0;

			string asmBlockEndInfo = "";

			int TMP_REG_IDX;

			while (j < num) {
				if (j % asmBlockDstQuadWordCount == 0) {
					// open an asm block
					asmBlockSrcQuadWordCount = ((offsetInWord + i * 4 + 31) / 32);
					TMP_REG_IDX = BEG_REG_IDX + asmBlockSrcQuadWordCount;
					curBlockSrcQuadWordIdx = 0;
					curBlockDstQuadWordIdx = 0;
					oss << "\t__asm__(\n";

					// load all quadword acquired by asmBlock from mem into xmm
					for (int t=0; t<asmBlockSrcQuadWordCount; ++t) {
						oss << TRIPLE_TAB << "\"movdqu %" << (asmBlockDstQuadWordCount + t)
						<< ",%%xmm" << (BEG_REG_IDX+t) << QUOTE_END_LINE;
					}
					ostringstream tmp3;
					tmp3 << TRIPLE_TAB << ":";
					for (int t=0; t<asmBlockDstQuadWordCount; ++t) {
						tmp3 << "\"=m\"(des[" << (4 * (j + t)) << "])";
						if (t < asmBlockDstQuadWordCount-1)
							tmp3 << ", ";
						else
							tmp3 << "\n";
					}

					tmp3 << TRIPLE_TAB << ":";
					for (int t=0; t<asmBlockSrcQuadWordCount; ++t) {
						tmp3 << "\"m\"(src[" << 4 * (curWordIdx + t) << "])";
						if (t < asmBlockSrcQuadWordCount-1)
							tmp3 << ", ";
						else
							tmp3 << "\n";
					}
					tmp3 << TRIPLE_TAB << ":\"memory\");\n";
					asmBlockEndInfo = tmp3.str();
				}

				ostringstream tmp1;
				tmp1 << TRIPLE_TAB << "\"movdqa %%xmm" << (BEG_REG_IDX + curBlockSrcQuadWordIdx) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
				if (offsetInWord > 0) {
					tmp1 << TRIPLE_TAB << "\"psrld $" << offsetInWord << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
				}

				oss << tmp1.str();

				if (offsetInWord + i > 32) {
					ostringstream tmp2;
					tmp2 << TRIPLE_TAB << "\"movdqa %%xmm" << (BEG_REG_IDX + curBlockSrcQuadWordIdx + 1) << ",%%xmm" << (TMP_REG_IDX + 1) << QUOTE_END_LINE;
					tmp2 << TRIPLE_TAB << "\"pslld $" << (32 - offsetInWord) << ",%%xmm" << (TMP_REG_IDX + 1) << QUOTE_END_LINE;
					tmp2 << TRIPLE_TAB << "\"por %%xmm" << (TMP_REG_IDX + 1) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
                        		oss << tmp2.str();
				}

				if (i < 32) {
					oss << TRIPLE_TAB << "\"pslld $" << (32 - i) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
					oss << TRIPLE_TAB << "\"psrld $" << (32 - i) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
				}
				oss << TRIPLE_TAB << "\"movdqu %%xmm" << (TMP_REG_IDX) << ",%" << curBlockDstQuadWordIdx << QUOTE_END_LINE;

				curBlockDstQuadWordIdx ++;
				curWordIdx += (offsetInWord + i) / 32;
				curBlockSrcQuadWordIdx += (offsetInWord + i) / 32;
				offsetInWord = (offsetInWord + i) % 32;
				j++;

				if (j == num || j % asmBlockDstQuadWordCount == 0) {
					oss << asmBlockEndInfo;
				}
			}
			oss << "}" << endl;
			oss << endl;
			infoOss << (k << 3) << ", "	//begOffset
				<< (offsetInWord) << ", "	//newOffset
				<< (curWordIdx << 2) << ", "	//wordskipped
				<< (num << 2) << ", "		//integer decoded
				<< "};" << endl;
		}
	}
}

string printInfoArr(int arrNum) {
	ostringstream oss;
	oss << "static SIMD_KAFORUnpackInfo SIMD_KAFORUnpackInfoArr[" << arrNum << "] = {" << endl;
	for (int i=0; i<arrNum; ++i) {
		if (i % 4 == 0)
			oss << "\t";
		oss << "SIMD_KAFORUnpackInfo_" << i << ", ";
		if (i % 4 == 3)
			oss << endl;
	}
	oss << "};" << endl;
	return oss.str();
}


int main() {
	ostringstream oss, infoOss;
	GenCode(8, 0, oss, infoOss);
	GenCode(16, 1, oss, infoOss);
	GenCode(32, 2, oss, infoOss);

	cout << oss.str();
	cout << endl;
	cout << infoOss.str();
	cout << endl;
	cout << printInfoArr(3 * 32 * 4);

	return 0;
}
 */
