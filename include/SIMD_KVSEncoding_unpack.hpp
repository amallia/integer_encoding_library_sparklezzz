/*
 * SIMD_KVSEncoding_unpack.hpp
 *
 *  Created on: 2013-11-18
 *      Author: zxd
 */

#ifndef SIMD_KVSEncoding_UNPACK_HPP_
#define SIMD_KVSEncoding_UNPACK_HPP_

namespace paradise {
namespace index {

struct SIMD_KVSEUnpackInfo {
	void (*m_subFunc)(uint32_t *des, const uint32_t *src);
	uint8_t m_offset;
	uint8_t m_newOffset;
	uint16_t m_wordSkipped;
	uint16_t m_intDecoded;
};

template<typename T>
void SIMD_KVSE_unpack_1len_0bw_0offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
}

template<typename T>
void SIMD_KVSE_unpack_1len_0bw_8offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
}

template<typename T>
void SIMD_KVSE_unpack_1len_0bw_16offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
}

template<typename T>
void SIMD_KVSE_unpack_1len_0bw_24offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
}

template<typename T>
void SIMD_KVSE_unpack_1len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_1len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_0bw_0offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
}

template<typename T>
void SIMD_KVSE_unpack_2len_0bw_8offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
}

template<typename T>
void SIMD_KVSE_unpack_2len_0bw_16offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
}

template<typename T>
void SIMD_KVSE_unpack_2len_0bw_24offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
}

template<typename T>
void SIMD_KVSE_unpack_2len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_2len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_0bw_0offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
}

template<typename T>
void SIMD_KVSE_unpack_4len_0bw_8offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
}

template<typename T>
void SIMD_KVSE_unpack_4len_0bw_16offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
}

template<typename T>
void SIMD_KVSE_unpack_4len_0bw_24offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
}

template<typename T>
void SIMD_KVSE_unpack_4len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_4len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_0bw_0offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
}

template<typename T>
void SIMD_KVSE_unpack_8len_0bw_8offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
}

template<typename T>
void SIMD_KVSE_unpack_8len_0bw_16offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
}

template<typename T>
void SIMD_KVSE_unpack_8len_0bw_24offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
}

template<typename T>
void SIMD_KVSE_unpack_8len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_8len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_0bw_0offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
}

template<typename T>
void SIMD_KVSE_unpack_12len_0bw_8offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
}

template<typename T>
void SIMD_KVSE_unpack_12len_0bw_16offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
}

template<typename T>
void SIMD_KVSE_unpack_12len_0bw_24offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
}

template<typename T>
void SIMD_KVSE_unpack_12len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0]), "m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_12len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_0bw_0offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
}

template<typename T>
void SIMD_KVSE_unpack_16len_0bw_8offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
}

template<typename T>
void SIMD_KVSE_unpack_16len_0bw_16offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
}

template<typename T>
void SIMD_KVSE_unpack_16len_0bw_24offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
}

template<typename T>
void SIMD_KVSE_unpack_16len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_16len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_0bw_0offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
	ZMEMCPY128(des + 64);
	ZMEMCPY128(des + 68);
	ZMEMCPY128(des + 72);
	ZMEMCPY128(des + 76);
	ZMEMCPY128(des + 80);
	ZMEMCPY128(des + 84);
	ZMEMCPY128(des + 88);
	ZMEMCPY128(des + 92);
	ZMEMCPY128(des + 96);
	ZMEMCPY128(des + 100);
	ZMEMCPY128(des + 104);
	ZMEMCPY128(des + 108);
	ZMEMCPY128(des + 112);
	ZMEMCPY128(des + 116);
	ZMEMCPY128(des + 120);
	ZMEMCPY128(des + 124);
}

template<typename T>
void SIMD_KVSE_unpack_32len_0bw_8offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
	ZMEMCPY128(des + 64);
	ZMEMCPY128(des + 68);
	ZMEMCPY128(des + 72);
	ZMEMCPY128(des + 76);
	ZMEMCPY128(des + 80);
	ZMEMCPY128(des + 84);
	ZMEMCPY128(des + 88);
	ZMEMCPY128(des + 92);
	ZMEMCPY128(des + 96);
	ZMEMCPY128(des + 100);
	ZMEMCPY128(des + 104);
	ZMEMCPY128(des + 108);
	ZMEMCPY128(des + 112);
	ZMEMCPY128(des + 116);
	ZMEMCPY128(des + 120);
	ZMEMCPY128(des + 124);
}

template<typename T>
void SIMD_KVSE_unpack_32len_0bw_16offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
	ZMEMCPY128(des + 64);
	ZMEMCPY128(des + 68);
	ZMEMCPY128(des + 72);
	ZMEMCPY128(des + 76);
	ZMEMCPY128(des + 80);
	ZMEMCPY128(des + 84);
	ZMEMCPY128(des + 88);
	ZMEMCPY128(des + 92);
	ZMEMCPY128(des + 96);
	ZMEMCPY128(des + 100);
	ZMEMCPY128(des + 104);
	ZMEMCPY128(des + 108);
	ZMEMCPY128(des + 112);
	ZMEMCPY128(des + 116);
	ZMEMCPY128(des + 120);
	ZMEMCPY128(des + 124);
}

template<typename T>
void SIMD_KVSE_unpack_32len_0bw_24offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
	ZMEMCPY128(des + 64);
	ZMEMCPY128(des + 68);
	ZMEMCPY128(des + 72);
	ZMEMCPY128(des + 76);
	ZMEMCPY128(des + 80);
	ZMEMCPY128(des + 84);
	ZMEMCPY128(des + 88);
	ZMEMCPY128(des + 92);
	ZMEMCPY128(des + 96);
	ZMEMCPY128(des + 100);
	ZMEMCPY128(des + 104);
	ZMEMCPY128(des + 108);
	ZMEMCPY128(des + 112);
	ZMEMCPY128(des + 116);
	ZMEMCPY128(des + 120);
	ZMEMCPY128(des + 124);
}

template<typename T>
void SIMD_KVSE_unpack_32len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[0])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8]), "m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12]), "m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16]), "m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24]), "m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_32len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_0bw_0offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
	ZMEMCPY128(des + 64);
	ZMEMCPY128(des + 68);
	ZMEMCPY128(des + 72);
	ZMEMCPY128(des + 76);
	ZMEMCPY128(des + 80);
	ZMEMCPY128(des + 84);
	ZMEMCPY128(des + 88);
	ZMEMCPY128(des + 92);
	ZMEMCPY128(des + 96);
	ZMEMCPY128(des + 100);
	ZMEMCPY128(des + 104);
	ZMEMCPY128(des + 108);
	ZMEMCPY128(des + 112);
	ZMEMCPY128(des + 116);
	ZMEMCPY128(des + 120);
	ZMEMCPY128(des + 124);
	ZMEMCPY128(des + 128);
	ZMEMCPY128(des + 132);
	ZMEMCPY128(des + 136);
	ZMEMCPY128(des + 140);
	ZMEMCPY128(des + 144);
	ZMEMCPY128(des + 148);
	ZMEMCPY128(des + 152);
	ZMEMCPY128(des + 156);
	ZMEMCPY128(des + 160);
	ZMEMCPY128(des + 164);
	ZMEMCPY128(des + 168);
	ZMEMCPY128(des + 172);
	ZMEMCPY128(des + 176);
	ZMEMCPY128(des + 180);
	ZMEMCPY128(des + 184);
	ZMEMCPY128(des + 188);
	ZMEMCPY128(des + 192);
	ZMEMCPY128(des + 196);
	ZMEMCPY128(des + 200);
	ZMEMCPY128(des + 204);
	ZMEMCPY128(des + 208);
	ZMEMCPY128(des + 212);
	ZMEMCPY128(des + 216);
	ZMEMCPY128(des + 220);
	ZMEMCPY128(des + 224);
	ZMEMCPY128(des + 228);
	ZMEMCPY128(des + 232);
	ZMEMCPY128(des + 236);
	ZMEMCPY128(des + 240);
	ZMEMCPY128(des + 244);
	ZMEMCPY128(des + 248);
	ZMEMCPY128(des + 252);
}

template<typename T>
void SIMD_KVSE_unpack_64len_0bw_8offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
	ZMEMCPY128(des + 64);
	ZMEMCPY128(des + 68);
	ZMEMCPY128(des + 72);
	ZMEMCPY128(des + 76);
	ZMEMCPY128(des + 80);
	ZMEMCPY128(des + 84);
	ZMEMCPY128(des + 88);
	ZMEMCPY128(des + 92);
	ZMEMCPY128(des + 96);
	ZMEMCPY128(des + 100);
	ZMEMCPY128(des + 104);
	ZMEMCPY128(des + 108);
	ZMEMCPY128(des + 112);
	ZMEMCPY128(des + 116);
	ZMEMCPY128(des + 120);
	ZMEMCPY128(des + 124);
	ZMEMCPY128(des + 128);
	ZMEMCPY128(des + 132);
	ZMEMCPY128(des + 136);
	ZMEMCPY128(des + 140);
	ZMEMCPY128(des + 144);
	ZMEMCPY128(des + 148);
	ZMEMCPY128(des + 152);
	ZMEMCPY128(des + 156);
	ZMEMCPY128(des + 160);
	ZMEMCPY128(des + 164);
	ZMEMCPY128(des + 168);
	ZMEMCPY128(des + 172);
	ZMEMCPY128(des + 176);
	ZMEMCPY128(des + 180);
	ZMEMCPY128(des + 184);
	ZMEMCPY128(des + 188);
	ZMEMCPY128(des + 192);
	ZMEMCPY128(des + 196);
	ZMEMCPY128(des + 200);
	ZMEMCPY128(des + 204);
	ZMEMCPY128(des + 208);
	ZMEMCPY128(des + 212);
	ZMEMCPY128(des + 216);
	ZMEMCPY128(des + 220);
	ZMEMCPY128(des + 224);
	ZMEMCPY128(des + 228);
	ZMEMCPY128(des + 232);
	ZMEMCPY128(des + 236);
	ZMEMCPY128(des + 240);
	ZMEMCPY128(des + 244);
	ZMEMCPY128(des + 248);
	ZMEMCPY128(des + 252);
}

template<typename T>
void SIMD_KVSE_unpack_64len_0bw_16offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
	ZMEMCPY128(des + 64);
	ZMEMCPY128(des + 68);
	ZMEMCPY128(des + 72);
	ZMEMCPY128(des + 76);
	ZMEMCPY128(des + 80);
	ZMEMCPY128(des + 84);
	ZMEMCPY128(des + 88);
	ZMEMCPY128(des + 92);
	ZMEMCPY128(des + 96);
	ZMEMCPY128(des + 100);
	ZMEMCPY128(des + 104);
	ZMEMCPY128(des + 108);
	ZMEMCPY128(des + 112);
	ZMEMCPY128(des + 116);
	ZMEMCPY128(des + 120);
	ZMEMCPY128(des + 124);
	ZMEMCPY128(des + 128);
	ZMEMCPY128(des + 132);
	ZMEMCPY128(des + 136);
	ZMEMCPY128(des + 140);
	ZMEMCPY128(des + 144);
	ZMEMCPY128(des + 148);
	ZMEMCPY128(des + 152);
	ZMEMCPY128(des + 156);
	ZMEMCPY128(des + 160);
	ZMEMCPY128(des + 164);
	ZMEMCPY128(des + 168);
	ZMEMCPY128(des + 172);
	ZMEMCPY128(des + 176);
	ZMEMCPY128(des + 180);
	ZMEMCPY128(des + 184);
	ZMEMCPY128(des + 188);
	ZMEMCPY128(des + 192);
	ZMEMCPY128(des + 196);
	ZMEMCPY128(des + 200);
	ZMEMCPY128(des + 204);
	ZMEMCPY128(des + 208);
	ZMEMCPY128(des + 212);
	ZMEMCPY128(des + 216);
	ZMEMCPY128(des + 220);
	ZMEMCPY128(des + 224);
	ZMEMCPY128(des + 228);
	ZMEMCPY128(des + 232);
	ZMEMCPY128(des + 236);
	ZMEMCPY128(des + 240);
	ZMEMCPY128(des + 244);
	ZMEMCPY128(des + 248);
	ZMEMCPY128(des + 252);
}

template<typename T>
void SIMD_KVSE_unpack_64len_0bw_24offset(T * des, const uint32_t *src) {
	ZMEMCPY128(des);
	ZMEMCPY128(des + 4);
	ZMEMCPY128(des + 8);
	ZMEMCPY128(des + 12);
	ZMEMCPY128(des + 16);
	ZMEMCPY128(des + 20);
	ZMEMCPY128(des + 24);
	ZMEMCPY128(des + 28);
	ZMEMCPY128(des + 32);
	ZMEMCPY128(des + 36);
	ZMEMCPY128(des + 40);
	ZMEMCPY128(des + 44);
	ZMEMCPY128(des + 48);
	ZMEMCPY128(des + 52);
	ZMEMCPY128(des + 56);
	ZMEMCPY128(des + 60);
	ZMEMCPY128(des + 64);
	ZMEMCPY128(des + 68);
	ZMEMCPY128(des + 72);
	ZMEMCPY128(des + 76);
	ZMEMCPY128(des + 80);
	ZMEMCPY128(des + 84);
	ZMEMCPY128(des + 88);
	ZMEMCPY128(des + 92);
	ZMEMCPY128(des + 96);
	ZMEMCPY128(des + 100);
	ZMEMCPY128(des + 104);
	ZMEMCPY128(des + 108);
	ZMEMCPY128(des + 112);
	ZMEMCPY128(des + 116);
	ZMEMCPY128(des + 120);
	ZMEMCPY128(des + 124);
	ZMEMCPY128(des + 128);
	ZMEMCPY128(des + 132);
	ZMEMCPY128(des + 136);
	ZMEMCPY128(des + 140);
	ZMEMCPY128(des + 144);
	ZMEMCPY128(des + 148);
	ZMEMCPY128(des + 152);
	ZMEMCPY128(des + 156);
	ZMEMCPY128(des + 160);
	ZMEMCPY128(des + 164);
	ZMEMCPY128(des + 168);
	ZMEMCPY128(des + 172);
	ZMEMCPY128(des + 176);
	ZMEMCPY128(des + 180);
	ZMEMCPY128(des + 184);
	ZMEMCPY128(des + 188);
	ZMEMCPY128(des + 192);
	ZMEMCPY128(des + 196);
	ZMEMCPY128(des + 200);
	ZMEMCPY128(des + 204);
	ZMEMCPY128(des + 208);
	ZMEMCPY128(des + 212);
	ZMEMCPY128(des + 216);
	ZMEMCPY128(des + 220);
	ZMEMCPY128(des + 224);
	ZMEMCPY128(des + 228);
	ZMEMCPY128(des + 232);
	ZMEMCPY128(des + 236);
	ZMEMCPY128(des + 240);
	ZMEMCPY128(des + 244);
	ZMEMCPY128(des + 248);
	ZMEMCPY128(des + 252);
}

template<typename T>
void SIMD_KVSE_unpack_64len_1bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[4])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_1bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_1bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_1bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $1,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $31,%%xmm4\n"
			"psrld $31,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[8])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_2bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[12])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_2bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_2bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_2bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $2,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $30,%%xmm4\n"
			"psrld $30,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[16])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_3bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[20])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_3bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[20]), "m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_3bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_3bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $29,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $3,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $29,%%xmm4\n"
			"psrld $29,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[24])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_4bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[28])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_4bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[28]), "m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_4bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_4bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $28,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $28,%%xmm4\n"
			"psrld $28,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[32])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_5bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[36])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_5bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_5bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[36]), "m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_5bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $17,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $22,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $5,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $10,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $15,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $13,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $23,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $27,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $9,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $19,%%xmm4\n"
			"pslld $27,%%xmm4\n"
			"psrld $27,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[40])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_6bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[44])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_6bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_6bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[44]), "m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_6bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $26,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $20,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $6,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $12,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $26,%%xmm4\n"
			"psrld $26,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[48])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_7bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[52])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_7bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_7bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_7bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $4,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $11,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $18,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $7,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $14,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $21,%%xmm4\n"
			"pslld $25,%%xmm4\n"
			"psrld $25,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $25,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[52]), "m"(src[56])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_8bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqa %%xmm3,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%0\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $8,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%1\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $16,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%2\n"
			"movdqa %%xmm3,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"pslld $24,%%xmm4\n"
			"psrld $24,%%xmm4\n"
			"movdqu %%xmm4,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[60])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_8bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_8bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_8bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $24,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[60]), "m"(src[64])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_9bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[64]), "m"(src[68])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_9bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[68]), "m"(src[72])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_9bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[68]), "m"(src[72])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_9bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $3,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $7,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $25,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $7,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $29,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $3,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $23,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[68]), "m"(src[72])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_10bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[72]), "m"(src[76])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_10bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_10bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_10bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $18,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $14,%%xmm5\n"
			"pslld $22,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[76]), "m"(src[80])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_11bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[80]), "m"(src[84])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_11bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_11bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[84]), "m"(src[88])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_11bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $3,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $14,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $25,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $7,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $15,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $26,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $6,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $5,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $27,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $5,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $17,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $18,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $29,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $3,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $21,%%xmm6\n"
			"psrld $21,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $19,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $30,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $2,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $9,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $31,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $1,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $10,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $11,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $22,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $10,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $1,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $23,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $9,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $2,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $13,%%xmm5\n"
			"pslld $21,%%xmm5\n"
			"psrld $21,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[84]), "m"(src[88])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_12bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[88]), "m"(src[92])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_12bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[76]), "m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_12bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $28,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $4,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $24,%%xmm5\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $8,%%xmm6\n"
			"por %%xmm6,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[92]), "m"(src[96])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_12bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $20,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $8,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $12,%%xmm5\n"
			"pslld $20,%%xmm5\n"
			"psrld $20,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[92]), "m"(src[96])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_16bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[80]), "m"(src[84])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[96]), "m"(src[100])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[112]), "m"(src[116])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqa %%xmm3,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%0\n"
			"movdqa %%xmm3,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%1\n"
			"movdqa %%xmm4,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%2\n"
			"movdqa %%xmm4,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"pslld $16,%%xmm5\n"
			"psrld $16,%%xmm5\n"
			"movdqu %%xmm5,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[120]), "m"(src[124])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_16bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_16bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_16bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[16]), "m"(src[20]), "m"(src[24])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[96]), "m"(src[100]), "m"(src[104])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $16,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_20bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[108]), "m"(src[112]), "m"(src[116])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[128]), "m"(src[132]), "m"(src[136])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[140]), "m"(src[144]), "m"(src[148])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[148]), "m"(src[152]), "m"(src[156])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_20bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[8]), "m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[28]), "m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[88]), "m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[108]), "m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[128]), "m"(src[132]), "m"(src[136]), "m"(src[140])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[140]), "m"(src[144]), "m"(src[148])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[148]), "m"(src[152]), "m"(src[156]), "m"(src[160])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_20bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[80]), "m"(src[84]), "m"(src[88])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[132]), "m"(src[136]), "m"(src[140])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $24,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $8,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[140]), "m"(src[144]), "m"(src[148])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $20,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[152]), "m"(src[156]), "m"(src[160])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_20bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[12]), "m"(src[16]), "m"(src[20])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[32]), "m"(src[36]), "m"(src[40])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[40]), "m"(src[44]), "m"(src[48]), "m"(src[52])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[60]), "m"(src[64]), "m"(src[68]), "m"(src[72])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[92]), "m"(src[96]), "m"(src[100])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[112]), "m"(src[116]), "m"(src[120])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[120]), "m"(src[124]), "m"(src[128]), "m"(src[132])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[132]), "m"(src[136]), "m"(src[140])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"psrld $24,%%xmm7\n"
			"movdqa %%xmm4,%%xmm8\n"
			"pslld $8,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm5,%%xmm7\n"
			"psrld $20,%%xmm7\n"
			"movdqa %%xmm6,%%xmm8\n"
			"pslld $12,%%xmm8\n"
			"por %%xmm8,%%xmm7\n"
			"pslld $12,%%xmm7\n"
			"psrld $12,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[140]), "m"(src[144]), "m"(src[148]), "m"(src[152])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $8,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%0\n"
			"movdqa %%xmm3,%%xmm6\n"
			"psrld $28,%%xmm6\n"
			"movdqa %%xmm4,%%xmm7\n"
			"pslld $4,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%1\n"
			"movdqa %%xmm4,%%xmm6\n"
			"psrld $16,%%xmm6\n"
			"movdqa %%xmm5,%%xmm7\n"
			"pslld $16,%%xmm7\n"
			"por %%xmm7,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%2\n"
			"movdqa %%xmm5,%%xmm6\n"
			"psrld $4,%%xmm6\n"
			"pslld $12,%%xmm6\n"
			"psrld $12,%%xmm6\n"
			"movdqu %%xmm6,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[152]), "m"(src[156]), "m"(src[160])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_32bw_0offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[128]), "m"(src[132]), "m"(src[136]), "m"(src[140])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[144]), "m"(src[148]), "m"(src[152]), "m"(src[156])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[160]), "m"(src[164]), "m"(src[168]), "m"(src[172])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[176]), "m"(src[180]), "m"(src[184]), "m"(src[188])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[192]), "m"(src[196]), "m"(src[200]), "m"(src[204])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[208]), "m"(src[212]), "m"(src[216]), "m"(src[220])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[224]), "m"(src[228]), "m"(src[232]), "m"(src[236])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqa %%xmm3,%%xmm7\n"
			"movdqu %%xmm7,%0\n"
			"movdqa %%xmm4,%%xmm7\n"
			"movdqu %%xmm7,%1\n"
			"movdqa %%xmm5,%%xmm7\n"
			"movdqu %%xmm7,%2\n"
			"movdqa %%xmm6,%%xmm7\n"
			"movdqu %%xmm7,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[240]), "m"(src[244]), "m"(src[248]), "m"(src[252])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_32bw_8offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[128]), "m"(src[132]), "m"(src[136]), "m"(src[140]), "m"(src[144])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[144]), "m"(src[148]), "m"(src[152]), "m"(src[156]), "m"(src[160])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[160]), "m"(src[164]), "m"(src[168]), "m"(src[172]), "m"(src[176])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[176]), "m"(src[180]), "m"(src[184]), "m"(src[188]), "m"(src[192])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[192]), "m"(src[196]), "m"(src[200]), "m"(src[204]), "m"(src[208])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[208]), "m"(src[212]), "m"(src[216]), "m"(src[220]), "m"(src[224])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[224]), "m"(src[228]), "m"(src[232]), "m"(src[236]), "m"(src[240])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $8,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $24,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[240]), "m"(src[244]), "m"(src[248]), "m"(src[252]), "m"(src[256])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_32bw_16offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[128]), "m"(src[132]), "m"(src[136]), "m"(src[140]), "m"(src[144])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[144]), "m"(src[148]), "m"(src[152]), "m"(src[156]), "m"(src[160])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[160]), "m"(src[164]), "m"(src[168]), "m"(src[172]), "m"(src[176])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[176]), "m"(src[180]), "m"(src[184]), "m"(src[188]), "m"(src[192])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[192]), "m"(src[196]), "m"(src[200]), "m"(src[204]), "m"(src[208])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[208]), "m"(src[212]), "m"(src[216]), "m"(src[220]), "m"(src[224])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[224]), "m"(src[228]), "m"(src[232]), "m"(src[236]), "m"(src[240])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $16,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $16,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[240]), "m"(src[244]), "m"(src[248]), "m"(src[252]), "m"(src[256])
			:"memory");
}

template<typename T>
void SIMD_KVSE_unpack_64len_32bw_24offset(T * des, const uint32_t *src) {
	__asm__ volatile("prefetchnta %0"::"m" (src[0]));
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[0]), "=m"(des[4]), "=m"(des[8]), "=m"(des[12])
			:"m"(src[0]), "m"(src[4]), "m"(src[8]), "m"(src[12]), "m"(src[16])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[16]), "=m"(des[20]), "=m"(des[24]), "=m"(des[28])
			:"m"(src[16]), "m"(src[20]), "m"(src[24]), "m"(src[28]), "m"(src[32])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[32]), "=m"(des[36]), "=m"(des[40]), "=m"(des[44])
			:"m"(src[32]), "m"(src[36]), "m"(src[40]), "m"(src[44]), "m"(src[48])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[48]), "=m"(des[52]), "=m"(des[56]), "=m"(des[60])
			:"m"(src[48]), "m"(src[52]), "m"(src[56]), "m"(src[60]), "m"(src[64])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[64]), "=m"(des[68]), "=m"(des[72]), "=m"(des[76])
			:"m"(src[64]), "m"(src[68]), "m"(src[72]), "m"(src[76]), "m"(src[80])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[80]), "=m"(des[84]), "=m"(des[88]), "=m"(des[92])
			:"m"(src[80]), "m"(src[84]), "m"(src[88]), "m"(src[92]), "m"(src[96])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[96]), "=m"(des[100]), "=m"(des[104]), "=m"(des[108])
			:"m"(src[96]), "m"(src[100]), "m"(src[104]), "m"(src[108]), "m"(src[112])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[112]), "=m"(des[116]), "=m"(des[120]), "=m"(des[124])
			:"m"(src[112]), "m"(src[116]), "m"(src[120]), "m"(src[124]), "m"(src[128])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[128]), "=m"(des[132]), "=m"(des[136]), "=m"(des[140])
			:"m"(src[128]), "m"(src[132]), "m"(src[136]), "m"(src[140]), "m"(src[144])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[144]), "=m"(des[148]), "=m"(des[152]), "=m"(des[156])
			:"m"(src[144]), "m"(src[148]), "m"(src[152]), "m"(src[156]), "m"(src[160])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[160]), "=m"(des[164]), "=m"(des[168]), "=m"(des[172])
			:"m"(src[160]), "m"(src[164]), "m"(src[168]), "m"(src[172]), "m"(src[176])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[176]), "=m"(des[180]), "=m"(des[184]), "=m"(des[188])
			:"m"(src[176]), "m"(src[180]), "m"(src[184]), "m"(src[188]), "m"(src[192])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[192]), "=m"(des[196]), "=m"(des[200]), "=m"(des[204])
			:"m"(src[192]), "m"(src[196]), "m"(src[200]), "m"(src[204]), "m"(src[208])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[208]), "=m"(des[212]), "=m"(des[216]), "=m"(des[220])
			:"m"(src[208]), "m"(src[212]), "m"(src[216]), "m"(src[220]), "m"(src[224])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[224]), "=m"(des[228]), "=m"(des[232]), "=m"(des[236])
			:"m"(src[224]), "m"(src[228]), "m"(src[232]), "m"(src[236]), "m"(src[240])
			:"memory");
	__asm__(
			"movdqu %4,%%xmm3\n"
			"movdqu %5,%%xmm4\n"
			"movdqu %6,%%xmm5\n"
			"movdqu %7,%%xmm6\n"
			"movdqu %8,%%xmm7\n"
			"movdqa %%xmm3,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm4,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%0\n"
			"movdqa %%xmm4,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm5,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%1\n"
			"movdqa %%xmm5,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm6,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%2\n"
			"movdqa %%xmm6,%%xmm8\n"
			"psrld $24,%%xmm8\n"
			"movdqa %%xmm7,%%xmm9\n"
			"pslld $8,%%xmm9\n"
			"por %%xmm9,%%xmm8\n"
			"movdqu %%xmm8,%3\n"
			:"=m"(des[240]), "=m"(des[244]), "=m"(des[248]), "=m"(des[252])
			:"m"(src[240]), "m"(src[244]), "m"(src[248]), "m"(src[252]), "m"(src[256])
			:"memory");
}


static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_0 = { SIMD_KVSE_unpack_1len_0bw_0offset<uint32_t>, 0, 0, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_1 = { SIMD_KVSE_unpack_1len_0bw_8offset<uint32_t>, 8, 8, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_2 = { SIMD_KVSE_unpack_1len_0bw_16offset<uint32_t>, 16, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_3 = { SIMD_KVSE_unpack_1len_0bw_24offset<uint32_t>, 24, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_4 = { SIMD_KVSE_unpack_1len_1bw_0offset<uint32_t>, 0, 8, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_5 = { SIMD_KVSE_unpack_1len_1bw_8offset<uint32_t>, 8, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_6 = { SIMD_KVSE_unpack_1len_1bw_16offset<uint32_t>, 16, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_7 = { SIMD_KVSE_unpack_1len_1bw_24offset<uint32_t>, 24, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_8 = { SIMD_KVSE_unpack_1len_2bw_0offset<uint32_t>, 0, 8, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_9 = { SIMD_KVSE_unpack_1len_2bw_8offset<uint32_t>, 8, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_10 = { SIMD_KVSE_unpack_1len_2bw_16offset<uint32_t>, 16, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_11 = { SIMD_KVSE_unpack_1len_2bw_24offset<uint32_t>, 24, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_12 = { SIMD_KVSE_unpack_1len_3bw_0offset<uint32_t>, 0, 8, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_13 = { SIMD_KVSE_unpack_1len_3bw_8offset<uint32_t>, 8, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_14 = { SIMD_KVSE_unpack_1len_3bw_16offset<uint32_t>, 16, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_15 = { SIMD_KVSE_unpack_1len_3bw_24offset<uint32_t>, 24, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_16 = { SIMD_KVSE_unpack_1len_4bw_0offset<uint32_t>, 0, 8, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_17 = { SIMD_KVSE_unpack_1len_4bw_8offset<uint32_t>, 8, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_18 = { SIMD_KVSE_unpack_1len_4bw_16offset<uint32_t>, 16, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_19 = { SIMD_KVSE_unpack_1len_4bw_24offset<uint32_t>, 24, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_20 = { SIMD_KVSE_unpack_1len_5bw_0offset<uint32_t>, 0, 8, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_21 = { SIMD_KVSE_unpack_1len_5bw_8offset<uint32_t>, 8, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_22 = { SIMD_KVSE_unpack_1len_5bw_16offset<uint32_t>, 16, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_23 = { SIMD_KVSE_unpack_1len_5bw_24offset<uint32_t>, 24, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_24 = { SIMD_KVSE_unpack_1len_6bw_0offset<uint32_t>, 0, 8, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_25 = { SIMD_KVSE_unpack_1len_6bw_8offset<uint32_t>, 8, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_26 = { SIMD_KVSE_unpack_1len_6bw_16offset<uint32_t>, 16, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_27 = { SIMD_KVSE_unpack_1len_6bw_24offset<uint32_t>, 24, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_28 = { SIMD_KVSE_unpack_1len_7bw_0offset<uint32_t>, 0, 8, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_29 = { SIMD_KVSE_unpack_1len_7bw_8offset<uint32_t>, 8, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_30 = { SIMD_KVSE_unpack_1len_7bw_16offset<uint32_t>, 16, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_31 = { SIMD_KVSE_unpack_1len_7bw_24offset<uint32_t>, 24, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_32 = { SIMD_KVSE_unpack_1len_8bw_0offset<uint32_t>, 0, 8, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_33 = { SIMD_KVSE_unpack_1len_8bw_8offset<uint32_t>, 8, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_34 = { SIMD_KVSE_unpack_1len_8bw_16offset<uint32_t>, 16, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_35 = { SIMD_KVSE_unpack_1len_8bw_24offset<uint32_t>, 24, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_36 = { SIMD_KVSE_unpack_1len_9bw_0offset<uint32_t>, 0, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_37 = { SIMD_KVSE_unpack_1len_9bw_8offset<uint32_t>, 8, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_38 = { SIMD_KVSE_unpack_1len_9bw_16offset<uint32_t>, 16, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_39 = { SIMD_KVSE_unpack_1len_9bw_24offset<uint32_t>, 24, 8, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_40 = { SIMD_KVSE_unpack_1len_10bw_0offset<uint32_t>, 0, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_41 = { SIMD_KVSE_unpack_1len_10bw_8offset<uint32_t>, 8, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_42 = { SIMD_KVSE_unpack_1len_10bw_16offset<uint32_t>, 16, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_43 = { SIMD_KVSE_unpack_1len_10bw_24offset<uint32_t>, 24, 8, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_44 = { SIMD_KVSE_unpack_1len_11bw_0offset<uint32_t>, 0, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_45 = { SIMD_KVSE_unpack_1len_11bw_8offset<uint32_t>, 8, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_46 = { SIMD_KVSE_unpack_1len_11bw_16offset<uint32_t>, 16, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_47 = { SIMD_KVSE_unpack_1len_11bw_24offset<uint32_t>, 24, 8, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_48 = { SIMD_KVSE_unpack_1len_12bw_0offset<uint32_t>, 0, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_49 = { SIMD_KVSE_unpack_1len_12bw_8offset<uint32_t>, 8, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_50 = { SIMD_KVSE_unpack_1len_12bw_16offset<uint32_t>, 16, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_51 = { SIMD_KVSE_unpack_1len_12bw_24offset<uint32_t>, 24, 8, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_52 = { SIMD_KVSE_unpack_1len_16bw_0offset<uint32_t>, 0, 16, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_53 = { SIMD_KVSE_unpack_1len_16bw_8offset<uint32_t>, 8, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_54 = { SIMD_KVSE_unpack_1len_16bw_16offset<uint32_t>, 16, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_55 = { SIMD_KVSE_unpack_1len_16bw_24offset<uint32_t>, 24, 8, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_56 = { SIMD_KVSE_unpack_1len_20bw_0offset<uint32_t>, 0, 24, 0, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_57 = { SIMD_KVSE_unpack_1len_20bw_8offset<uint32_t>, 8, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_58 = { SIMD_KVSE_unpack_1len_20bw_16offset<uint32_t>, 16, 8, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_59 = { SIMD_KVSE_unpack_1len_20bw_24offset<uint32_t>, 24, 16, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_60 = { SIMD_KVSE_unpack_1len_32bw_0offset<uint32_t>, 0, 0, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_61 = { SIMD_KVSE_unpack_1len_32bw_8offset<uint32_t>, 8, 8, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_62 = { SIMD_KVSE_unpack_1len_32bw_16offset<uint32_t>, 16, 16, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_63 = { SIMD_KVSE_unpack_1len_32bw_24offset<uint32_t>, 24, 24, 4, 4, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_64 = { SIMD_KVSE_unpack_2len_0bw_0offset<uint32_t>, 0, 0, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_65 = { SIMD_KVSE_unpack_2len_0bw_8offset<uint32_t>, 8, 8, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_66 = { SIMD_KVSE_unpack_2len_0bw_16offset<uint32_t>, 16, 16, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_67 = { SIMD_KVSE_unpack_2len_0bw_24offset<uint32_t>, 24, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_68 = { SIMD_KVSE_unpack_2len_1bw_0offset<uint32_t>, 0, 8, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_69 = { SIMD_KVSE_unpack_2len_1bw_8offset<uint32_t>, 8, 16, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_70 = { SIMD_KVSE_unpack_2len_1bw_16offset<uint32_t>, 16, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_71 = { SIMD_KVSE_unpack_2len_1bw_24offset<uint32_t>, 24, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_72 = { SIMD_KVSE_unpack_2len_2bw_0offset<uint32_t>, 0, 8, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_73 = { SIMD_KVSE_unpack_2len_2bw_8offset<uint32_t>, 8, 16, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_74 = { SIMD_KVSE_unpack_2len_2bw_16offset<uint32_t>, 16, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_75 = { SIMD_KVSE_unpack_2len_2bw_24offset<uint32_t>, 24, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_76 = { SIMD_KVSE_unpack_2len_3bw_0offset<uint32_t>, 0, 8, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_77 = { SIMD_KVSE_unpack_2len_3bw_8offset<uint32_t>, 8, 16, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_78 = { SIMD_KVSE_unpack_2len_3bw_16offset<uint32_t>, 16, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_79 = { SIMD_KVSE_unpack_2len_3bw_24offset<uint32_t>, 24, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_80 = { SIMD_KVSE_unpack_2len_4bw_0offset<uint32_t>, 0, 8, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_81 = { SIMD_KVSE_unpack_2len_4bw_8offset<uint32_t>, 8, 16, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_82 = { SIMD_KVSE_unpack_2len_4bw_16offset<uint32_t>, 16, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_83 = { SIMD_KVSE_unpack_2len_4bw_24offset<uint32_t>, 24, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_84 = { SIMD_KVSE_unpack_2len_5bw_0offset<uint32_t>, 0, 16, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_85 = { SIMD_KVSE_unpack_2len_5bw_8offset<uint32_t>, 8, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_86 = { SIMD_KVSE_unpack_2len_5bw_16offset<uint32_t>, 16, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_87 = { SIMD_KVSE_unpack_2len_5bw_24offset<uint32_t>, 24, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_88 = { SIMD_KVSE_unpack_2len_6bw_0offset<uint32_t>, 0, 16, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_89 = { SIMD_KVSE_unpack_2len_6bw_8offset<uint32_t>, 8, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_90 = { SIMD_KVSE_unpack_2len_6bw_16offset<uint32_t>, 16, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_91 = { SIMD_KVSE_unpack_2len_6bw_24offset<uint32_t>, 24, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_92 = { SIMD_KVSE_unpack_2len_7bw_0offset<uint32_t>, 0, 16, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_93 = { SIMD_KVSE_unpack_2len_7bw_8offset<uint32_t>, 8, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_94 = { SIMD_KVSE_unpack_2len_7bw_16offset<uint32_t>, 16, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_95 = { SIMD_KVSE_unpack_2len_7bw_24offset<uint32_t>, 24, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_96 = { SIMD_KVSE_unpack_2len_8bw_0offset<uint32_t>, 0, 16, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_97 = { SIMD_KVSE_unpack_2len_8bw_8offset<uint32_t>, 8, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_98 = { SIMD_KVSE_unpack_2len_8bw_16offset<uint32_t>, 16, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_99 = { SIMD_KVSE_unpack_2len_8bw_24offset<uint32_t>, 24, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_100 = { SIMD_KVSE_unpack_2len_9bw_0offset<uint32_t>, 0, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_101 = { SIMD_KVSE_unpack_2len_9bw_8offset<uint32_t>, 8, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_102 = { SIMD_KVSE_unpack_2len_9bw_16offset<uint32_t>, 16, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_103 = { SIMD_KVSE_unpack_2len_9bw_24offset<uint32_t>, 24, 16, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_104 = { SIMD_KVSE_unpack_2len_10bw_0offset<uint32_t>, 0, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_105 = { SIMD_KVSE_unpack_2len_10bw_8offset<uint32_t>, 8, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_106 = { SIMD_KVSE_unpack_2len_10bw_16offset<uint32_t>, 16, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_107 = { SIMD_KVSE_unpack_2len_10bw_24offset<uint32_t>, 24, 16, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_108 = { SIMD_KVSE_unpack_2len_11bw_0offset<uint32_t>, 0, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_109 = { SIMD_KVSE_unpack_2len_11bw_8offset<uint32_t>, 8, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_110 = { SIMD_KVSE_unpack_2len_11bw_16offset<uint32_t>, 16, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_111 = { SIMD_KVSE_unpack_2len_11bw_24offset<uint32_t>, 24, 16, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_112 = { SIMD_KVSE_unpack_2len_12bw_0offset<uint32_t>, 0, 24, 0, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_113 = { SIMD_KVSE_unpack_2len_12bw_8offset<uint32_t>, 8, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_114 = { SIMD_KVSE_unpack_2len_12bw_16offset<uint32_t>, 16, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_115 = { SIMD_KVSE_unpack_2len_12bw_24offset<uint32_t>, 24, 16, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_116 = { SIMD_KVSE_unpack_2len_16bw_0offset<uint32_t>, 0, 0, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_117 = { SIMD_KVSE_unpack_2len_16bw_8offset<uint32_t>, 8, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_118 = { SIMD_KVSE_unpack_2len_16bw_16offset<uint32_t>, 16, 16, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_119 = { SIMD_KVSE_unpack_2len_16bw_24offset<uint32_t>, 24, 24, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_120 = { SIMD_KVSE_unpack_2len_20bw_0offset<uint32_t>, 0, 8, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_121 = { SIMD_KVSE_unpack_2len_20bw_8offset<uint32_t>, 8, 16, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_122 = { SIMD_KVSE_unpack_2len_20bw_16offset<uint32_t>, 16, 24, 4, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_123 = { SIMD_KVSE_unpack_2len_20bw_24offset<uint32_t>, 24, 0, 8, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_124 = { SIMD_KVSE_unpack_2len_32bw_0offset<uint32_t>, 0, 0, 8, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_125 = { SIMD_KVSE_unpack_2len_32bw_8offset<uint32_t>, 8, 8, 8, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_126 = { SIMD_KVSE_unpack_2len_32bw_16offset<uint32_t>, 16, 16, 8, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_127 = { SIMD_KVSE_unpack_2len_32bw_24offset<uint32_t>, 24, 24, 8, 8, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_128 = { SIMD_KVSE_unpack_4len_0bw_0offset<uint32_t>, 0, 0, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_129 = { SIMD_KVSE_unpack_4len_0bw_8offset<uint32_t>, 8, 8, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_130 = { SIMD_KVSE_unpack_4len_0bw_16offset<uint32_t>, 16, 16, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_131 = { SIMD_KVSE_unpack_4len_0bw_24offset<uint32_t>, 24, 24, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_132 = { SIMD_KVSE_unpack_4len_1bw_0offset<uint32_t>, 0, 8, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_133 = { SIMD_KVSE_unpack_4len_1bw_8offset<uint32_t>, 8, 16, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_134 = { SIMD_KVSE_unpack_4len_1bw_16offset<uint32_t>, 16, 24, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_135 = { SIMD_KVSE_unpack_4len_1bw_24offset<uint32_t>, 24, 0, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_136 = { SIMD_KVSE_unpack_4len_2bw_0offset<uint32_t>, 0, 8, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_137 = { SIMD_KVSE_unpack_4len_2bw_8offset<uint32_t>, 8, 16, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_138 = { SIMD_KVSE_unpack_4len_2bw_16offset<uint32_t>, 16, 24, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_139 = { SIMD_KVSE_unpack_4len_2bw_24offset<uint32_t>, 24, 0, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_140 = { SIMD_KVSE_unpack_4len_3bw_0offset<uint32_t>, 0, 16, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_141 = { SIMD_KVSE_unpack_4len_3bw_8offset<uint32_t>, 8, 24, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_142 = { SIMD_KVSE_unpack_4len_3bw_16offset<uint32_t>, 16, 0, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_143 = { SIMD_KVSE_unpack_4len_3bw_24offset<uint32_t>, 24, 8, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_144 = { SIMD_KVSE_unpack_4len_4bw_0offset<uint32_t>, 0, 16, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_145 = { SIMD_KVSE_unpack_4len_4bw_8offset<uint32_t>, 8, 24, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_146 = { SIMD_KVSE_unpack_4len_4bw_16offset<uint32_t>, 16, 0, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_147 = { SIMD_KVSE_unpack_4len_4bw_24offset<uint32_t>, 24, 8, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_148 = { SIMD_KVSE_unpack_4len_5bw_0offset<uint32_t>, 0, 24, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_149 = { SIMD_KVSE_unpack_4len_5bw_8offset<uint32_t>, 8, 0, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_150 = { SIMD_KVSE_unpack_4len_5bw_16offset<uint32_t>, 16, 8, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_151 = { SIMD_KVSE_unpack_4len_5bw_24offset<uint32_t>, 24, 16, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_152 = { SIMD_KVSE_unpack_4len_6bw_0offset<uint32_t>, 0, 24, 0, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_153 = { SIMD_KVSE_unpack_4len_6bw_8offset<uint32_t>, 8, 0, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_154 = { SIMD_KVSE_unpack_4len_6bw_16offset<uint32_t>, 16, 8, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_155 = { SIMD_KVSE_unpack_4len_6bw_24offset<uint32_t>, 24, 16, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_156 = { SIMD_KVSE_unpack_4len_7bw_0offset<uint32_t>, 0, 0, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_157 = { SIMD_KVSE_unpack_4len_7bw_8offset<uint32_t>, 8, 8, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_158 = { SIMD_KVSE_unpack_4len_7bw_16offset<uint32_t>, 16, 16, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_159 = { SIMD_KVSE_unpack_4len_7bw_24offset<uint32_t>, 24, 24, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_160 = { SIMD_KVSE_unpack_4len_8bw_0offset<uint32_t>, 0, 0, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_161 = { SIMD_KVSE_unpack_4len_8bw_8offset<uint32_t>, 8, 8, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_162 = { SIMD_KVSE_unpack_4len_8bw_16offset<uint32_t>, 16, 16, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_163 = { SIMD_KVSE_unpack_4len_8bw_24offset<uint32_t>, 24, 24, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_164 = { SIMD_KVSE_unpack_4len_9bw_0offset<uint32_t>, 0, 8, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_165 = { SIMD_KVSE_unpack_4len_9bw_8offset<uint32_t>, 8, 16, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_166 = { SIMD_KVSE_unpack_4len_9bw_16offset<uint32_t>, 16, 24, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_167 = { SIMD_KVSE_unpack_4len_9bw_24offset<uint32_t>, 24, 0, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_168 = { SIMD_KVSE_unpack_4len_10bw_0offset<uint32_t>, 0, 8, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_169 = { SIMD_KVSE_unpack_4len_10bw_8offset<uint32_t>, 8, 16, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_170 = { SIMD_KVSE_unpack_4len_10bw_16offset<uint32_t>, 16, 24, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_171 = { SIMD_KVSE_unpack_4len_10bw_24offset<uint32_t>, 24, 0, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_172 = { SIMD_KVSE_unpack_4len_11bw_0offset<uint32_t>, 0, 16, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_173 = { SIMD_KVSE_unpack_4len_11bw_8offset<uint32_t>, 8, 24, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_174 = { SIMD_KVSE_unpack_4len_11bw_16offset<uint32_t>, 16, 0, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_175 = { SIMD_KVSE_unpack_4len_11bw_24offset<uint32_t>, 24, 8, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_176 = { SIMD_KVSE_unpack_4len_12bw_0offset<uint32_t>, 0, 16, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_177 = { SIMD_KVSE_unpack_4len_12bw_8offset<uint32_t>, 8, 24, 4, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_178 = { SIMD_KVSE_unpack_4len_12bw_16offset<uint32_t>, 16, 0, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_179 = { SIMD_KVSE_unpack_4len_12bw_24offset<uint32_t>, 24, 8, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_180 = { SIMD_KVSE_unpack_4len_16bw_0offset<uint32_t>, 0, 0, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_181 = { SIMD_KVSE_unpack_4len_16bw_8offset<uint32_t>, 8, 8, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_182 = { SIMD_KVSE_unpack_4len_16bw_16offset<uint32_t>, 16, 16, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_183 = { SIMD_KVSE_unpack_4len_16bw_24offset<uint32_t>, 24, 24, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_184 = { SIMD_KVSE_unpack_4len_20bw_0offset<uint32_t>, 0, 16, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_185 = { SIMD_KVSE_unpack_4len_20bw_8offset<uint32_t>, 8, 24, 8, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_186 = { SIMD_KVSE_unpack_4len_20bw_16offset<uint32_t>, 16, 0, 12, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_187 = { SIMD_KVSE_unpack_4len_20bw_24offset<uint32_t>, 24, 8, 12, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_188 = { SIMD_KVSE_unpack_4len_32bw_0offset<uint32_t>, 0, 0, 16, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_189 = { SIMD_KVSE_unpack_4len_32bw_8offset<uint32_t>, 8, 8, 16, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_190 = { SIMD_KVSE_unpack_4len_32bw_16offset<uint32_t>, 16, 16, 16, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_191 = { SIMD_KVSE_unpack_4len_32bw_24offset<uint32_t>, 24, 24, 16, 16, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_192 = { SIMD_KVSE_unpack_8len_0bw_0offset<uint32_t>, 0, 0, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_193 = { SIMD_KVSE_unpack_8len_0bw_8offset<uint32_t>, 8, 8, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_194 = { SIMD_KVSE_unpack_8len_0bw_16offset<uint32_t>, 16, 16, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_195 = { SIMD_KVSE_unpack_8len_0bw_24offset<uint32_t>, 24, 24, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_196 = { SIMD_KVSE_unpack_8len_1bw_0offset<uint32_t>, 0, 8, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_197 = { SIMD_KVSE_unpack_8len_1bw_8offset<uint32_t>, 8, 16, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_198 = { SIMD_KVSE_unpack_8len_1bw_16offset<uint32_t>, 16, 24, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_199 = { SIMD_KVSE_unpack_8len_1bw_24offset<uint32_t>, 24, 0, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_200 = { SIMD_KVSE_unpack_8len_2bw_0offset<uint32_t>, 0, 16, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_201 = { SIMD_KVSE_unpack_8len_2bw_8offset<uint32_t>, 8, 24, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_202 = { SIMD_KVSE_unpack_8len_2bw_16offset<uint32_t>, 16, 0, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_203 = { SIMD_KVSE_unpack_8len_2bw_24offset<uint32_t>, 24, 8, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_204 = { SIMD_KVSE_unpack_8len_3bw_0offset<uint32_t>, 0, 24, 0, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_205 = { SIMD_KVSE_unpack_8len_3bw_8offset<uint32_t>, 8, 0, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_206 = { SIMD_KVSE_unpack_8len_3bw_16offset<uint32_t>, 16, 8, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_207 = { SIMD_KVSE_unpack_8len_3bw_24offset<uint32_t>, 24, 16, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_208 = { SIMD_KVSE_unpack_8len_4bw_0offset<uint32_t>, 0, 0, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_209 = { SIMD_KVSE_unpack_8len_4bw_8offset<uint32_t>, 8, 8, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_210 = { SIMD_KVSE_unpack_8len_4bw_16offset<uint32_t>, 16, 16, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_211 = { SIMD_KVSE_unpack_8len_4bw_24offset<uint32_t>, 24, 24, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_212 = { SIMD_KVSE_unpack_8len_5bw_0offset<uint32_t>, 0, 8, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_213 = { SIMD_KVSE_unpack_8len_5bw_8offset<uint32_t>, 8, 16, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_214 = { SIMD_KVSE_unpack_8len_5bw_16offset<uint32_t>, 16, 24, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_215 = { SIMD_KVSE_unpack_8len_5bw_24offset<uint32_t>, 24, 0, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_216 = { SIMD_KVSE_unpack_8len_6bw_0offset<uint32_t>, 0, 16, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_217 = { SIMD_KVSE_unpack_8len_6bw_8offset<uint32_t>, 8, 24, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_218 = { SIMD_KVSE_unpack_8len_6bw_16offset<uint32_t>, 16, 0, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_219 = { SIMD_KVSE_unpack_8len_6bw_24offset<uint32_t>, 24, 8, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_220 = { SIMD_KVSE_unpack_8len_7bw_0offset<uint32_t>, 0, 24, 4, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_221 = { SIMD_KVSE_unpack_8len_7bw_8offset<uint32_t>, 8, 0, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_222 = { SIMD_KVSE_unpack_8len_7bw_16offset<uint32_t>, 16, 8, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_223 = { SIMD_KVSE_unpack_8len_7bw_24offset<uint32_t>, 24, 16, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_224 = { SIMD_KVSE_unpack_8len_8bw_0offset<uint32_t>, 0, 0, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_225 = { SIMD_KVSE_unpack_8len_8bw_8offset<uint32_t>, 8, 8, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_226 = { SIMD_KVSE_unpack_8len_8bw_16offset<uint32_t>, 16, 16, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_227 = { SIMD_KVSE_unpack_8len_8bw_24offset<uint32_t>, 24, 24, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_228 = { SIMD_KVSE_unpack_8len_9bw_0offset<uint32_t>, 0, 8, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_229 = { SIMD_KVSE_unpack_8len_9bw_8offset<uint32_t>, 8, 16, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_230 = { SIMD_KVSE_unpack_8len_9bw_16offset<uint32_t>, 16, 24, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_231 = { SIMD_KVSE_unpack_8len_9bw_24offset<uint32_t>, 24, 0, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_232 = { SIMD_KVSE_unpack_8len_10bw_0offset<uint32_t>, 0, 16, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_233 = { SIMD_KVSE_unpack_8len_10bw_8offset<uint32_t>, 8, 24, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_234 = { SIMD_KVSE_unpack_8len_10bw_16offset<uint32_t>, 16, 0, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_235 = { SIMD_KVSE_unpack_8len_10bw_24offset<uint32_t>, 24, 8, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_236 = { SIMD_KVSE_unpack_8len_11bw_0offset<uint32_t>, 0, 24, 8, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_237 = { SIMD_KVSE_unpack_8len_11bw_8offset<uint32_t>, 8, 0, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_238 = { SIMD_KVSE_unpack_8len_11bw_16offset<uint32_t>, 16, 8, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_239 = { SIMD_KVSE_unpack_8len_11bw_24offset<uint32_t>, 24, 16, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_240 = { SIMD_KVSE_unpack_8len_12bw_0offset<uint32_t>, 0, 0, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_241 = { SIMD_KVSE_unpack_8len_12bw_8offset<uint32_t>, 8, 8, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_242 = { SIMD_KVSE_unpack_8len_12bw_16offset<uint32_t>, 16, 16, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_243 = { SIMD_KVSE_unpack_8len_12bw_24offset<uint32_t>, 24, 24, 12, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_244 = { SIMD_KVSE_unpack_8len_16bw_0offset<uint32_t>, 0, 0, 16, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_245 = { SIMD_KVSE_unpack_8len_16bw_8offset<uint32_t>, 8, 8, 16, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_246 = { SIMD_KVSE_unpack_8len_16bw_16offset<uint32_t>, 16, 16, 16, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_247 = { SIMD_KVSE_unpack_8len_16bw_24offset<uint32_t>, 24, 24, 16, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_248 = { SIMD_KVSE_unpack_8len_20bw_0offset<uint32_t>, 0, 0, 20, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_249 = { SIMD_KVSE_unpack_8len_20bw_8offset<uint32_t>, 8, 8, 20, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_250 = { SIMD_KVSE_unpack_8len_20bw_16offset<uint32_t>, 16, 16, 20, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_251 = { SIMD_KVSE_unpack_8len_20bw_24offset<uint32_t>, 24, 24, 20, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_252 = { SIMD_KVSE_unpack_8len_32bw_0offset<uint32_t>, 0, 0, 32, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_253 = { SIMD_KVSE_unpack_8len_32bw_8offset<uint32_t>, 8, 8, 32, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_254 = { SIMD_KVSE_unpack_8len_32bw_16offset<uint32_t>, 16, 16, 32, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_255 = { SIMD_KVSE_unpack_8len_32bw_24offset<uint32_t>, 24, 24, 32, 32, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_256 = { SIMD_KVSE_unpack_12len_0bw_0offset<uint32_t>, 0, 0, 0, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_257 = { SIMD_KVSE_unpack_12len_0bw_8offset<uint32_t>, 8, 8, 0, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_258 = { SIMD_KVSE_unpack_12len_0bw_16offset<uint32_t>, 16, 16, 0, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_259 = { SIMD_KVSE_unpack_12len_0bw_24offset<uint32_t>, 24, 24, 0, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_260 = { SIMD_KVSE_unpack_12len_1bw_0offset<uint32_t>, 0, 16, 0, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_261 = { SIMD_KVSE_unpack_12len_1bw_8offset<uint32_t>, 8, 24, 0, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_262 = { SIMD_KVSE_unpack_12len_1bw_16offset<uint32_t>, 16, 0, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_263 = { SIMD_KVSE_unpack_12len_1bw_24offset<uint32_t>, 24, 8, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_264 = { SIMD_KVSE_unpack_12len_2bw_0offset<uint32_t>, 0, 24, 0, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_265 = { SIMD_KVSE_unpack_12len_2bw_8offset<uint32_t>, 8, 0, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_266 = { SIMD_KVSE_unpack_12len_2bw_16offset<uint32_t>, 16, 8, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_267 = { SIMD_KVSE_unpack_12len_2bw_24offset<uint32_t>, 24, 16, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_268 = { SIMD_KVSE_unpack_12len_3bw_0offset<uint32_t>, 0, 8, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_269 = { SIMD_KVSE_unpack_12len_3bw_8offset<uint32_t>, 8, 16, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_270 = { SIMD_KVSE_unpack_12len_3bw_16offset<uint32_t>, 16, 24, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_271 = { SIMD_KVSE_unpack_12len_3bw_24offset<uint32_t>, 24, 0, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_272 = { SIMD_KVSE_unpack_12len_4bw_0offset<uint32_t>, 0, 16, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_273 = { SIMD_KVSE_unpack_12len_4bw_8offset<uint32_t>, 8, 24, 4, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_274 = { SIMD_KVSE_unpack_12len_4bw_16offset<uint32_t>, 16, 0, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_275 = { SIMD_KVSE_unpack_12len_4bw_24offset<uint32_t>, 24, 8, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_276 = { SIMD_KVSE_unpack_12len_5bw_0offset<uint32_t>, 0, 0, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_277 = { SIMD_KVSE_unpack_12len_5bw_8offset<uint32_t>, 8, 8, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_278 = { SIMD_KVSE_unpack_12len_5bw_16offset<uint32_t>, 16, 16, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_279 = { SIMD_KVSE_unpack_12len_5bw_24offset<uint32_t>, 24, 24, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_280 = { SIMD_KVSE_unpack_12len_6bw_0offset<uint32_t>, 0, 8, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_281 = { SIMD_KVSE_unpack_12len_6bw_8offset<uint32_t>, 8, 16, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_282 = { SIMD_KVSE_unpack_12len_6bw_16offset<uint32_t>, 16, 24, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_283 = { SIMD_KVSE_unpack_12len_6bw_24offset<uint32_t>, 24, 0, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_284 = { SIMD_KVSE_unpack_12len_7bw_0offset<uint32_t>, 0, 24, 8, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_285 = { SIMD_KVSE_unpack_12len_7bw_8offset<uint32_t>, 8, 0, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_286 = { SIMD_KVSE_unpack_12len_7bw_16offset<uint32_t>, 16, 8, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_287 = { SIMD_KVSE_unpack_12len_7bw_24offset<uint32_t>, 24, 16, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_288 = { SIMD_KVSE_unpack_12len_8bw_0offset<uint32_t>, 0, 0, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_289 = { SIMD_KVSE_unpack_12len_8bw_8offset<uint32_t>, 8, 8, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_290 = { SIMD_KVSE_unpack_12len_8bw_16offset<uint32_t>, 16, 16, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_291 = { SIMD_KVSE_unpack_12len_8bw_24offset<uint32_t>, 24, 24, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_292 = { SIMD_KVSE_unpack_12len_9bw_0offset<uint32_t>, 0, 16, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_293 = { SIMD_KVSE_unpack_12len_9bw_8offset<uint32_t>, 8, 24, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_294 = { SIMD_KVSE_unpack_12len_9bw_16offset<uint32_t>, 16, 0, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_295 = { SIMD_KVSE_unpack_12len_9bw_24offset<uint32_t>, 24, 8, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_296 = { SIMD_KVSE_unpack_12len_10bw_0offset<uint32_t>, 0, 24, 12, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_297 = { SIMD_KVSE_unpack_12len_10bw_8offset<uint32_t>, 8, 0, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_298 = { SIMD_KVSE_unpack_12len_10bw_16offset<uint32_t>, 16, 8, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_299 = { SIMD_KVSE_unpack_12len_10bw_24offset<uint32_t>, 24, 16, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_300 = { SIMD_KVSE_unpack_12len_11bw_0offset<uint32_t>, 0, 8, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_301 = { SIMD_KVSE_unpack_12len_11bw_8offset<uint32_t>, 8, 16, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_302 = { SIMD_KVSE_unpack_12len_11bw_16offset<uint32_t>, 16, 24, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_303 = { SIMD_KVSE_unpack_12len_11bw_24offset<uint32_t>, 24, 0, 20, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_304 = { SIMD_KVSE_unpack_12len_12bw_0offset<uint32_t>, 0, 16, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_305 = { SIMD_KVSE_unpack_12len_12bw_8offset<uint32_t>, 8, 24, 16, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_306 = { SIMD_KVSE_unpack_12len_12bw_16offset<uint32_t>, 16, 0, 20, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_307 = { SIMD_KVSE_unpack_12len_12bw_24offset<uint32_t>, 24, 8, 20, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_308 = { SIMD_KVSE_unpack_12len_16bw_0offset<uint32_t>, 0, 0, 24, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_309 = { SIMD_KVSE_unpack_12len_16bw_8offset<uint32_t>, 8, 8, 24, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_310 = { SIMD_KVSE_unpack_12len_16bw_16offset<uint32_t>, 16, 16, 24, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_311 = { SIMD_KVSE_unpack_12len_16bw_24offset<uint32_t>, 24, 24, 24, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_312 = { SIMD_KVSE_unpack_12len_20bw_0offset<uint32_t>, 0, 16, 28, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_313 = { SIMD_KVSE_unpack_12len_20bw_8offset<uint32_t>, 8, 24, 28, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_314 = { SIMD_KVSE_unpack_12len_20bw_16offset<uint32_t>, 16, 0, 32, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_315 = { SIMD_KVSE_unpack_12len_20bw_24offset<uint32_t>, 24, 8, 32, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_316 = { SIMD_KVSE_unpack_12len_32bw_0offset<uint32_t>, 0, 0, 48, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_317 = { SIMD_KVSE_unpack_12len_32bw_8offset<uint32_t>, 8, 8, 48, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_318 = { SIMD_KVSE_unpack_12len_32bw_16offset<uint32_t>, 16, 16, 48, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_319 = { SIMD_KVSE_unpack_12len_32bw_24offset<uint32_t>, 24, 24, 48, 48, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_320 = { SIMD_KVSE_unpack_16len_0bw_0offset<uint32_t>, 0, 0, 0, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_321 = { SIMD_KVSE_unpack_16len_0bw_8offset<uint32_t>, 8, 8, 0, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_322 = { SIMD_KVSE_unpack_16len_0bw_16offset<uint32_t>, 16, 16, 0, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_323 = { SIMD_KVSE_unpack_16len_0bw_24offset<uint32_t>, 24, 24, 0, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_324 = { SIMD_KVSE_unpack_16len_1bw_0offset<uint32_t>, 0, 16, 0, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_325 = { SIMD_KVSE_unpack_16len_1bw_8offset<uint32_t>, 8, 24, 0, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_326 = { SIMD_KVSE_unpack_16len_1bw_16offset<uint32_t>, 16, 0, 4, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_327 = { SIMD_KVSE_unpack_16len_1bw_24offset<uint32_t>, 24, 8, 4, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_328 = { SIMD_KVSE_unpack_16len_2bw_0offset<uint32_t>, 0, 0, 4, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_329 = { SIMD_KVSE_unpack_16len_2bw_8offset<uint32_t>, 8, 8, 4, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_330 = { SIMD_KVSE_unpack_16len_2bw_16offset<uint32_t>, 16, 16, 4, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_331 = { SIMD_KVSE_unpack_16len_2bw_24offset<uint32_t>, 24, 24, 4, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_332 = { SIMD_KVSE_unpack_16len_3bw_0offset<uint32_t>, 0, 16, 4, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_333 = { SIMD_KVSE_unpack_16len_3bw_8offset<uint32_t>, 8, 24, 4, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_334 = { SIMD_KVSE_unpack_16len_3bw_16offset<uint32_t>, 16, 0, 8, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_335 = { SIMD_KVSE_unpack_16len_3bw_24offset<uint32_t>, 24, 8, 8, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_336 = { SIMD_KVSE_unpack_16len_4bw_0offset<uint32_t>, 0, 0, 8, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_337 = { SIMD_KVSE_unpack_16len_4bw_8offset<uint32_t>, 8, 8, 8, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_338 = { SIMD_KVSE_unpack_16len_4bw_16offset<uint32_t>, 16, 16, 8, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_339 = { SIMD_KVSE_unpack_16len_4bw_24offset<uint32_t>, 24, 24, 8, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_340 = { SIMD_KVSE_unpack_16len_5bw_0offset<uint32_t>, 0, 16, 8, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_341 = { SIMD_KVSE_unpack_16len_5bw_8offset<uint32_t>, 8, 24, 8, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_342 = { SIMD_KVSE_unpack_16len_5bw_16offset<uint32_t>, 16, 0, 12, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_343 = { SIMD_KVSE_unpack_16len_5bw_24offset<uint32_t>, 24, 8, 12, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_344 = { SIMD_KVSE_unpack_16len_6bw_0offset<uint32_t>, 0, 0, 12, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_345 = { SIMD_KVSE_unpack_16len_6bw_8offset<uint32_t>, 8, 8, 12, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_346 = { SIMD_KVSE_unpack_16len_6bw_16offset<uint32_t>, 16, 16, 12, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_347 = { SIMD_KVSE_unpack_16len_6bw_24offset<uint32_t>, 24, 24, 12, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_348 = { SIMD_KVSE_unpack_16len_7bw_0offset<uint32_t>, 0, 16, 12, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_349 = { SIMD_KVSE_unpack_16len_7bw_8offset<uint32_t>, 8, 24, 12, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_350 = { SIMD_KVSE_unpack_16len_7bw_16offset<uint32_t>, 16, 0, 16, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_351 = { SIMD_KVSE_unpack_16len_7bw_24offset<uint32_t>, 24, 8, 16, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_352 = { SIMD_KVSE_unpack_16len_8bw_0offset<uint32_t>, 0, 0, 16, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_353 = { SIMD_KVSE_unpack_16len_8bw_8offset<uint32_t>, 8, 8, 16, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_354 = { SIMD_KVSE_unpack_16len_8bw_16offset<uint32_t>, 16, 16, 16, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_355 = { SIMD_KVSE_unpack_16len_8bw_24offset<uint32_t>, 24, 24, 16, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_356 = { SIMD_KVSE_unpack_16len_9bw_0offset<uint32_t>, 0, 16, 16, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_357 = { SIMD_KVSE_unpack_16len_9bw_8offset<uint32_t>, 8, 24, 16, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_358 = { SIMD_KVSE_unpack_16len_9bw_16offset<uint32_t>, 16, 0, 20, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_359 = { SIMD_KVSE_unpack_16len_9bw_24offset<uint32_t>, 24, 8, 20, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_360 = { SIMD_KVSE_unpack_16len_10bw_0offset<uint32_t>, 0, 0, 20, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_361 = { SIMD_KVSE_unpack_16len_10bw_8offset<uint32_t>, 8, 8, 20, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_362 = { SIMD_KVSE_unpack_16len_10bw_16offset<uint32_t>, 16, 16, 20, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_363 = { SIMD_KVSE_unpack_16len_10bw_24offset<uint32_t>, 24, 24, 20, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_364 = { SIMD_KVSE_unpack_16len_11bw_0offset<uint32_t>, 0, 16, 20, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_365 = { SIMD_KVSE_unpack_16len_11bw_8offset<uint32_t>, 8, 24, 20, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_366 = { SIMD_KVSE_unpack_16len_11bw_16offset<uint32_t>, 16, 0, 24, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_367 = { SIMD_KVSE_unpack_16len_11bw_24offset<uint32_t>, 24, 8, 24, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_368 = { SIMD_KVSE_unpack_16len_12bw_0offset<uint32_t>, 0, 0, 24, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_369 = { SIMD_KVSE_unpack_16len_12bw_8offset<uint32_t>, 8, 8, 24, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_370 = { SIMD_KVSE_unpack_16len_12bw_16offset<uint32_t>, 16, 16, 24, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_371 = { SIMD_KVSE_unpack_16len_12bw_24offset<uint32_t>, 24, 24, 24, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_372 = { SIMD_KVSE_unpack_16len_16bw_0offset<uint32_t>, 0, 0, 32, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_373 = { SIMD_KVSE_unpack_16len_16bw_8offset<uint32_t>, 8, 8, 32, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_374 = { SIMD_KVSE_unpack_16len_16bw_16offset<uint32_t>, 16, 16, 32, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_375 = { SIMD_KVSE_unpack_16len_16bw_24offset<uint32_t>, 24, 24, 32, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_376 = { SIMD_KVSE_unpack_16len_20bw_0offset<uint32_t>, 0, 0, 40, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_377 = { SIMD_KVSE_unpack_16len_20bw_8offset<uint32_t>, 8, 8, 40, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_378 = { SIMD_KVSE_unpack_16len_20bw_16offset<uint32_t>, 16, 16, 40, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_379 = { SIMD_KVSE_unpack_16len_20bw_24offset<uint32_t>, 24, 24, 40, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_380 = { SIMD_KVSE_unpack_16len_32bw_0offset<uint32_t>, 0, 0, 64, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_381 = { SIMD_KVSE_unpack_16len_32bw_8offset<uint32_t>, 8, 8, 64, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_382 = { SIMD_KVSE_unpack_16len_32bw_16offset<uint32_t>, 16, 16, 64, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_383 = { SIMD_KVSE_unpack_16len_32bw_24offset<uint32_t>, 24, 24, 64, 64, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_384 = { SIMD_KVSE_unpack_32len_0bw_0offset<uint32_t>, 0, 0, 0, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_385 = { SIMD_KVSE_unpack_32len_0bw_8offset<uint32_t>, 8, 8, 0, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_386 = { SIMD_KVSE_unpack_32len_0bw_16offset<uint32_t>, 16, 16, 0, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_387 = { SIMD_KVSE_unpack_32len_0bw_24offset<uint32_t>, 24, 24, 0, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_388 = { SIMD_KVSE_unpack_32len_1bw_0offset<uint32_t>, 0, 0, 4, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_389 = { SIMD_KVSE_unpack_32len_1bw_8offset<uint32_t>, 8, 8, 4, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_390 = { SIMD_KVSE_unpack_32len_1bw_16offset<uint32_t>, 16, 16, 4, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_391 = { SIMD_KVSE_unpack_32len_1bw_24offset<uint32_t>, 24, 24, 4, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_392 = { SIMD_KVSE_unpack_32len_2bw_0offset<uint32_t>, 0, 0, 8, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_393 = { SIMD_KVSE_unpack_32len_2bw_8offset<uint32_t>, 8, 8, 8, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_394 = { SIMD_KVSE_unpack_32len_2bw_16offset<uint32_t>, 16, 16, 8, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_395 = { SIMD_KVSE_unpack_32len_2bw_24offset<uint32_t>, 24, 24, 8, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_396 = { SIMD_KVSE_unpack_32len_3bw_0offset<uint32_t>, 0, 0, 12, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_397 = { SIMD_KVSE_unpack_32len_3bw_8offset<uint32_t>, 8, 8, 12, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_398 = { SIMD_KVSE_unpack_32len_3bw_16offset<uint32_t>, 16, 16, 12, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_399 = { SIMD_KVSE_unpack_32len_3bw_24offset<uint32_t>, 24, 24, 12, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_400 = { SIMD_KVSE_unpack_32len_4bw_0offset<uint32_t>, 0, 0, 16, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_401 = { SIMD_KVSE_unpack_32len_4bw_8offset<uint32_t>, 8, 8, 16, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_402 = { SIMD_KVSE_unpack_32len_4bw_16offset<uint32_t>, 16, 16, 16, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_403 = { SIMD_KVSE_unpack_32len_4bw_24offset<uint32_t>, 24, 24, 16, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_404 = { SIMD_KVSE_unpack_32len_5bw_0offset<uint32_t>, 0, 0, 20, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_405 = { SIMD_KVSE_unpack_32len_5bw_8offset<uint32_t>, 8, 8, 20, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_406 = { SIMD_KVSE_unpack_32len_5bw_16offset<uint32_t>, 16, 16, 20, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_407 = { SIMD_KVSE_unpack_32len_5bw_24offset<uint32_t>, 24, 24, 20, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_408 = { SIMD_KVSE_unpack_32len_6bw_0offset<uint32_t>, 0, 0, 24, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_409 = { SIMD_KVSE_unpack_32len_6bw_8offset<uint32_t>, 8, 8, 24, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_410 = { SIMD_KVSE_unpack_32len_6bw_16offset<uint32_t>, 16, 16, 24, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_411 = { SIMD_KVSE_unpack_32len_6bw_24offset<uint32_t>, 24, 24, 24, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_412 = { SIMD_KVSE_unpack_32len_7bw_0offset<uint32_t>, 0, 0, 28, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_413 = { SIMD_KVSE_unpack_32len_7bw_8offset<uint32_t>, 8, 8, 28, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_414 = { SIMD_KVSE_unpack_32len_7bw_16offset<uint32_t>, 16, 16, 28, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_415 = { SIMD_KVSE_unpack_32len_7bw_24offset<uint32_t>, 24, 24, 28, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_416 = { SIMD_KVSE_unpack_32len_8bw_0offset<uint32_t>, 0, 0, 32, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_417 = { SIMD_KVSE_unpack_32len_8bw_8offset<uint32_t>, 8, 8, 32, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_418 = { SIMD_KVSE_unpack_32len_8bw_16offset<uint32_t>, 16, 16, 32, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_419 = { SIMD_KVSE_unpack_32len_8bw_24offset<uint32_t>, 24, 24, 32, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_420 = { SIMD_KVSE_unpack_32len_9bw_0offset<uint32_t>, 0, 0, 36, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_421 = { SIMD_KVSE_unpack_32len_9bw_8offset<uint32_t>, 8, 8, 36, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_422 = { SIMD_KVSE_unpack_32len_9bw_16offset<uint32_t>, 16, 16, 36, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_423 = { SIMD_KVSE_unpack_32len_9bw_24offset<uint32_t>, 24, 24, 36, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_424 = { SIMD_KVSE_unpack_32len_10bw_0offset<uint32_t>, 0, 0, 40, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_425 = { SIMD_KVSE_unpack_32len_10bw_8offset<uint32_t>, 8, 8, 40, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_426 = { SIMD_KVSE_unpack_32len_10bw_16offset<uint32_t>, 16, 16, 40, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_427 = { SIMD_KVSE_unpack_32len_10bw_24offset<uint32_t>, 24, 24, 40, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_428 = { SIMD_KVSE_unpack_32len_11bw_0offset<uint32_t>, 0, 0, 44, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_429 = { SIMD_KVSE_unpack_32len_11bw_8offset<uint32_t>, 8, 8, 44, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_430 = { SIMD_KVSE_unpack_32len_11bw_16offset<uint32_t>, 16, 16, 44, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_431 = { SIMD_KVSE_unpack_32len_11bw_24offset<uint32_t>, 24, 24, 44, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_432 = { SIMD_KVSE_unpack_32len_12bw_0offset<uint32_t>, 0, 0, 48, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_433 = { SIMD_KVSE_unpack_32len_12bw_8offset<uint32_t>, 8, 8, 48, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_434 = { SIMD_KVSE_unpack_32len_12bw_16offset<uint32_t>, 16, 16, 48, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_435 = { SIMD_KVSE_unpack_32len_12bw_24offset<uint32_t>, 24, 24, 48, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_436 = { SIMD_KVSE_unpack_32len_16bw_0offset<uint32_t>, 0, 0, 64, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_437 = { SIMD_KVSE_unpack_32len_16bw_8offset<uint32_t>, 8, 8, 64, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_438 = { SIMD_KVSE_unpack_32len_16bw_16offset<uint32_t>, 16, 16, 64, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_439 = { SIMD_KVSE_unpack_32len_16bw_24offset<uint32_t>, 24, 24, 64, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_440 = { SIMD_KVSE_unpack_32len_20bw_0offset<uint32_t>, 0, 0, 80, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_441 = { SIMD_KVSE_unpack_32len_20bw_8offset<uint32_t>, 8, 8, 80, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_442 = { SIMD_KVSE_unpack_32len_20bw_16offset<uint32_t>, 16, 16, 80, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_443 = { SIMD_KVSE_unpack_32len_20bw_24offset<uint32_t>, 24, 24, 80, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_444 = { SIMD_KVSE_unpack_32len_32bw_0offset<uint32_t>, 0, 0, 128, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_445 = { SIMD_KVSE_unpack_32len_32bw_8offset<uint32_t>, 8, 8, 128, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_446 = { SIMD_KVSE_unpack_32len_32bw_16offset<uint32_t>, 16, 16, 128, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_447 = { SIMD_KVSE_unpack_32len_32bw_24offset<uint32_t>, 24, 24, 128, 128, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_448 = { SIMD_KVSE_unpack_64len_0bw_0offset<uint32_t>, 0, 0, 0, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_449 = { SIMD_KVSE_unpack_64len_0bw_8offset<uint32_t>, 8, 8, 0, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_450 = { SIMD_KVSE_unpack_64len_0bw_16offset<uint32_t>, 16, 16, 0, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_451 = { SIMD_KVSE_unpack_64len_0bw_24offset<uint32_t>, 24, 24, 0, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_452 = { SIMD_KVSE_unpack_64len_1bw_0offset<uint32_t>, 0, 0, 8, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_453 = { SIMD_KVSE_unpack_64len_1bw_8offset<uint32_t>, 8, 8, 8, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_454 = { SIMD_KVSE_unpack_64len_1bw_16offset<uint32_t>, 16, 16, 8, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_455 = { SIMD_KVSE_unpack_64len_1bw_24offset<uint32_t>, 24, 24, 8, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_456 = { SIMD_KVSE_unpack_64len_2bw_0offset<uint32_t>, 0, 0, 16, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_457 = { SIMD_KVSE_unpack_64len_2bw_8offset<uint32_t>, 8, 8, 16, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_458 = { SIMD_KVSE_unpack_64len_2bw_16offset<uint32_t>, 16, 16, 16, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_459 = { SIMD_KVSE_unpack_64len_2bw_24offset<uint32_t>, 24, 24, 16, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_460 = { SIMD_KVSE_unpack_64len_3bw_0offset<uint32_t>, 0, 0, 24, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_461 = { SIMD_KVSE_unpack_64len_3bw_8offset<uint32_t>, 8, 8, 24, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_462 = { SIMD_KVSE_unpack_64len_3bw_16offset<uint32_t>, 16, 16, 24, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_463 = { SIMD_KVSE_unpack_64len_3bw_24offset<uint32_t>, 24, 24, 24, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_464 = { SIMD_KVSE_unpack_64len_4bw_0offset<uint32_t>, 0, 0, 32, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_465 = { SIMD_KVSE_unpack_64len_4bw_8offset<uint32_t>, 8, 8, 32, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_466 = { SIMD_KVSE_unpack_64len_4bw_16offset<uint32_t>, 16, 16, 32, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_467 = { SIMD_KVSE_unpack_64len_4bw_24offset<uint32_t>, 24, 24, 32, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_468 = { SIMD_KVSE_unpack_64len_5bw_0offset<uint32_t>, 0, 0, 40, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_469 = { SIMD_KVSE_unpack_64len_5bw_8offset<uint32_t>, 8, 8, 40, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_470 = { SIMD_KVSE_unpack_64len_5bw_16offset<uint32_t>, 16, 16, 40, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_471 = { SIMD_KVSE_unpack_64len_5bw_24offset<uint32_t>, 24, 24, 40, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_472 = { SIMD_KVSE_unpack_64len_6bw_0offset<uint32_t>, 0, 0, 48, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_473 = { SIMD_KVSE_unpack_64len_6bw_8offset<uint32_t>, 8, 8, 48, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_474 = { SIMD_KVSE_unpack_64len_6bw_16offset<uint32_t>, 16, 16, 48, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_475 = { SIMD_KVSE_unpack_64len_6bw_24offset<uint32_t>, 24, 24, 48, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_476 = { SIMD_KVSE_unpack_64len_7bw_0offset<uint32_t>, 0, 0, 56, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_477 = { SIMD_KVSE_unpack_64len_7bw_8offset<uint32_t>, 8, 8, 56, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_478 = { SIMD_KVSE_unpack_64len_7bw_16offset<uint32_t>, 16, 16, 56, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_479 = { SIMD_KVSE_unpack_64len_7bw_24offset<uint32_t>, 24, 24, 56, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_480 = { SIMD_KVSE_unpack_64len_8bw_0offset<uint32_t>, 0, 0, 64, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_481 = { SIMD_KVSE_unpack_64len_8bw_8offset<uint32_t>, 8, 8, 64, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_482 = { SIMD_KVSE_unpack_64len_8bw_16offset<uint32_t>, 16, 16, 64, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_483 = { SIMD_KVSE_unpack_64len_8bw_24offset<uint32_t>, 24, 24, 64, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_484 = { SIMD_KVSE_unpack_64len_9bw_0offset<uint32_t>, 0, 0, 72, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_485 = { SIMD_KVSE_unpack_64len_9bw_8offset<uint32_t>, 8, 8, 72, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_486 = { SIMD_KVSE_unpack_64len_9bw_16offset<uint32_t>, 16, 16, 72, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_487 = { SIMD_KVSE_unpack_64len_9bw_24offset<uint32_t>, 24, 24, 72, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_488 = { SIMD_KVSE_unpack_64len_10bw_0offset<uint32_t>, 0, 0, 80, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_489 = { SIMD_KVSE_unpack_64len_10bw_8offset<uint32_t>, 8, 8, 80, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_490 = { SIMD_KVSE_unpack_64len_10bw_16offset<uint32_t>, 16, 16, 80, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_491 = { SIMD_KVSE_unpack_64len_10bw_24offset<uint32_t>, 24, 24, 80, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_492 = { SIMD_KVSE_unpack_64len_11bw_0offset<uint32_t>, 0, 0, 88, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_493 = { SIMD_KVSE_unpack_64len_11bw_8offset<uint32_t>, 8, 8, 88, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_494 = { SIMD_KVSE_unpack_64len_11bw_16offset<uint32_t>, 16, 16, 88, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_495 = { SIMD_KVSE_unpack_64len_11bw_24offset<uint32_t>, 24, 24, 88, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_496 = { SIMD_KVSE_unpack_64len_12bw_0offset<uint32_t>, 0, 0, 96, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_497 = { SIMD_KVSE_unpack_64len_12bw_8offset<uint32_t>, 8, 8, 96, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_498 = { SIMD_KVSE_unpack_64len_12bw_16offset<uint32_t>, 16, 16, 96, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_499 = { SIMD_KVSE_unpack_64len_12bw_24offset<uint32_t>, 24, 24, 96, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_500 = { SIMD_KVSE_unpack_64len_16bw_0offset<uint32_t>, 0, 0, 128, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_501 = { SIMD_KVSE_unpack_64len_16bw_8offset<uint32_t>, 8, 8, 128, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_502 = { SIMD_KVSE_unpack_64len_16bw_16offset<uint32_t>, 16, 16, 128, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_503 = { SIMD_KVSE_unpack_64len_16bw_24offset<uint32_t>, 24, 24, 128, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_504 = { SIMD_KVSE_unpack_64len_20bw_0offset<uint32_t>, 0, 0, 160, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_505 = { SIMD_KVSE_unpack_64len_20bw_8offset<uint32_t>, 8, 8, 160, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_506 = { SIMD_KVSE_unpack_64len_20bw_16offset<uint32_t>, 16, 16, 160, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_507 = { SIMD_KVSE_unpack_64len_20bw_24offset<uint32_t>, 24, 24, 160, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_508 = { SIMD_KVSE_unpack_64len_32bw_0offset<uint32_t>, 0, 0, 256, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_509 = { SIMD_KVSE_unpack_64len_32bw_8offset<uint32_t>, 8, 8, 256, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_510 = { SIMD_KVSE_unpack_64len_32bw_16offset<uint32_t>, 16, 16, 256, 256, };
static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_511 = { SIMD_KVSE_unpack_64len_32bw_24offset<uint32_t>, 24, 24, 256, 256, };

static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfoArr[512] = {
	SIMD_KVSEUnpackInfo_0, SIMD_KVSEUnpackInfo_1, SIMD_KVSEUnpackInfo_2, SIMD_KVSEUnpackInfo_3,
	SIMD_KVSEUnpackInfo_4, SIMD_KVSEUnpackInfo_5, SIMD_KVSEUnpackInfo_6, SIMD_KVSEUnpackInfo_7,
	SIMD_KVSEUnpackInfo_8, SIMD_KVSEUnpackInfo_9, SIMD_KVSEUnpackInfo_10, SIMD_KVSEUnpackInfo_11,
	SIMD_KVSEUnpackInfo_12, SIMD_KVSEUnpackInfo_13, SIMD_KVSEUnpackInfo_14, SIMD_KVSEUnpackInfo_15,
	SIMD_KVSEUnpackInfo_16, SIMD_KVSEUnpackInfo_17, SIMD_KVSEUnpackInfo_18, SIMD_KVSEUnpackInfo_19,
	SIMD_KVSEUnpackInfo_20, SIMD_KVSEUnpackInfo_21, SIMD_KVSEUnpackInfo_22, SIMD_KVSEUnpackInfo_23,
	SIMD_KVSEUnpackInfo_24, SIMD_KVSEUnpackInfo_25, SIMD_KVSEUnpackInfo_26, SIMD_KVSEUnpackInfo_27,
	SIMD_KVSEUnpackInfo_28, SIMD_KVSEUnpackInfo_29, SIMD_KVSEUnpackInfo_30, SIMD_KVSEUnpackInfo_31,
	SIMD_KVSEUnpackInfo_32, SIMD_KVSEUnpackInfo_33, SIMD_KVSEUnpackInfo_34, SIMD_KVSEUnpackInfo_35,
	SIMD_KVSEUnpackInfo_36, SIMD_KVSEUnpackInfo_37, SIMD_KVSEUnpackInfo_38, SIMD_KVSEUnpackInfo_39,
	SIMD_KVSEUnpackInfo_40, SIMD_KVSEUnpackInfo_41, SIMD_KVSEUnpackInfo_42, SIMD_KVSEUnpackInfo_43,
	SIMD_KVSEUnpackInfo_44, SIMD_KVSEUnpackInfo_45, SIMD_KVSEUnpackInfo_46, SIMD_KVSEUnpackInfo_47,
	SIMD_KVSEUnpackInfo_48, SIMD_KVSEUnpackInfo_49, SIMD_KVSEUnpackInfo_50, SIMD_KVSEUnpackInfo_51,
	SIMD_KVSEUnpackInfo_52, SIMD_KVSEUnpackInfo_53, SIMD_KVSEUnpackInfo_54, SIMD_KVSEUnpackInfo_55,
	SIMD_KVSEUnpackInfo_56, SIMD_KVSEUnpackInfo_57, SIMD_KVSEUnpackInfo_58, SIMD_KVSEUnpackInfo_59,
	SIMD_KVSEUnpackInfo_60, SIMD_KVSEUnpackInfo_61, SIMD_KVSEUnpackInfo_62, SIMD_KVSEUnpackInfo_63,
	SIMD_KVSEUnpackInfo_64, SIMD_KVSEUnpackInfo_65, SIMD_KVSEUnpackInfo_66, SIMD_KVSEUnpackInfo_67,
	SIMD_KVSEUnpackInfo_68, SIMD_KVSEUnpackInfo_69, SIMD_KVSEUnpackInfo_70, SIMD_KVSEUnpackInfo_71,
	SIMD_KVSEUnpackInfo_72, SIMD_KVSEUnpackInfo_73, SIMD_KVSEUnpackInfo_74, SIMD_KVSEUnpackInfo_75,
	SIMD_KVSEUnpackInfo_76, SIMD_KVSEUnpackInfo_77, SIMD_KVSEUnpackInfo_78, SIMD_KVSEUnpackInfo_79,
	SIMD_KVSEUnpackInfo_80, SIMD_KVSEUnpackInfo_81, SIMD_KVSEUnpackInfo_82, SIMD_KVSEUnpackInfo_83,
	SIMD_KVSEUnpackInfo_84, SIMD_KVSEUnpackInfo_85, SIMD_KVSEUnpackInfo_86, SIMD_KVSEUnpackInfo_87,
	SIMD_KVSEUnpackInfo_88, SIMD_KVSEUnpackInfo_89, SIMD_KVSEUnpackInfo_90, SIMD_KVSEUnpackInfo_91,
	SIMD_KVSEUnpackInfo_92, SIMD_KVSEUnpackInfo_93, SIMD_KVSEUnpackInfo_94, SIMD_KVSEUnpackInfo_95,
	SIMD_KVSEUnpackInfo_96, SIMD_KVSEUnpackInfo_97, SIMD_KVSEUnpackInfo_98, SIMD_KVSEUnpackInfo_99,
	SIMD_KVSEUnpackInfo_100, SIMD_KVSEUnpackInfo_101, SIMD_KVSEUnpackInfo_102, SIMD_KVSEUnpackInfo_103,
	SIMD_KVSEUnpackInfo_104, SIMD_KVSEUnpackInfo_105, SIMD_KVSEUnpackInfo_106, SIMD_KVSEUnpackInfo_107,
	SIMD_KVSEUnpackInfo_108, SIMD_KVSEUnpackInfo_109, SIMD_KVSEUnpackInfo_110, SIMD_KVSEUnpackInfo_111,
	SIMD_KVSEUnpackInfo_112, SIMD_KVSEUnpackInfo_113, SIMD_KVSEUnpackInfo_114, SIMD_KVSEUnpackInfo_115,
	SIMD_KVSEUnpackInfo_116, SIMD_KVSEUnpackInfo_117, SIMD_KVSEUnpackInfo_118, SIMD_KVSEUnpackInfo_119,
	SIMD_KVSEUnpackInfo_120, SIMD_KVSEUnpackInfo_121, SIMD_KVSEUnpackInfo_122, SIMD_KVSEUnpackInfo_123,
	SIMD_KVSEUnpackInfo_124, SIMD_KVSEUnpackInfo_125, SIMD_KVSEUnpackInfo_126, SIMD_KVSEUnpackInfo_127,
	SIMD_KVSEUnpackInfo_128, SIMD_KVSEUnpackInfo_129, SIMD_KVSEUnpackInfo_130, SIMD_KVSEUnpackInfo_131,
	SIMD_KVSEUnpackInfo_132, SIMD_KVSEUnpackInfo_133, SIMD_KVSEUnpackInfo_134, SIMD_KVSEUnpackInfo_135,
	SIMD_KVSEUnpackInfo_136, SIMD_KVSEUnpackInfo_137, SIMD_KVSEUnpackInfo_138, SIMD_KVSEUnpackInfo_139,
	SIMD_KVSEUnpackInfo_140, SIMD_KVSEUnpackInfo_141, SIMD_KVSEUnpackInfo_142, SIMD_KVSEUnpackInfo_143,
	SIMD_KVSEUnpackInfo_144, SIMD_KVSEUnpackInfo_145, SIMD_KVSEUnpackInfo_146, SIMD_KVSEUnpackInfo_147,
	SIMD_KVSEUnpackInfo_148, SIMD_KVSEUnpackInfo_149, SIMD_KVSEUnpackInfo_150, SIMD_KVSEUnpackInfo_151,
	SIMD_KVSEUnpackInfo_152, SIMD_KVSEUnpackInfo_153, SIMD_KVSEUnpackInfo_154, SIMD_KVSEUnpackInfo_155,
	SIMD_KVSEUnpackInfo_156, SIMD_KVSEUnpackInfo_157, SIMD_KVSEUnpackInfo_158, SIMD_KVSEUnpackInfo_159,
	SIMD_KVSEUnpackInfo_160, SIMD_KVSEUnpackInfo_161, SIMD_KVSEUnpackInfo_162, SIMD_KVSEUnpackInfo_163,
	SIMD_KVSEUnpackInfo_164, SIMD_KVSEUnpackInfo_165, SIMD_KVSEUnpackInfo_166, SIMD_KVSEUnpackInfo_167,
	SIMD_KVSEUnpackInfo_168, SIMD_KVSEUnpackInfo_169, SIMD_KVSEUnpackInfo_170, SIMD_KVSEUnpackInfo_171,
	SIMD_KVSEUnpackInfo_172, SIMD_KVSEUnpackInfo_173, SIMD_KVSEUnpackInfo_174, SIMD_KVSEUnpackInfo_175,
	SIMD_KVSEUnpackInfo_176, SIMD_KVSEUnpackInfo_177, SIMD_KVSEUnpackInfo_178, SIMD_KVSEUnpackInfo_179,
	SIMD_KVSEUnpackInfo_180, SIMD_KVSEUnpackInfo_181, SIMD_KVSEUnpackInfo_182, SIMD_KVSEUnpackInfo_183,
	SIMD_KVSEUnpackInfo_184, SIMD_KVSEUnpackInfo_185, SIMD_KVSEUnpackInfo_186, SIMD_KVSEUnpackInfo_187,
	SIMD_KVSEUnpackInfo_188, SIMD_KVSEUnpackInfo_189, SIMD_KVSEUnpackInfo_190, SIMD_KVSEUnpackInfo_191,
	SIMD_KVSEUnpackInfo_192, SIMD_KVSEUnpackInfo_193, SIMD_KVSEUnpackInfo_194, SIMD_KVSEUnpackInfo_195,
	SIMD_KVSEUnpackInfo_196, SIMD_KVSEUnpackInfo_197, SIMD_KVSEUnpackInfo_198, SIMD_KVSEUnpackInfo_199,
	SIMD_KVSEUnpackInfo_200, SIMD_KVSEUnpackInfo_201, SIMD_KVSEUnpackInfo_202, SIMD_KVSEUnpackInfo_203,
	SIMD_KVSEUnpackInfo_204, SIMD_KVSEUnpackInfo_205, SIMD_KVSEUnpackInfo_206, SIMD_KVSEUnpackInfo_207,
	SIMD_KVSEUnpackInfo_208, SIMD_KVSEUnpackInfo_209, SIMD_KVSEUnpackInfo_210, SIMD_KVSEUnpackInfo_211,
	SIMD_KVSEUnpackInfo_212, SIMD_KVSEUnpackInfo_213, SIMD_KVSEUnpackInfo_214, SIMD_KVSEUnpackInfo_215,
	SIMD_KVSEUnpackInfo_216, SIMD_KVSEUnpackInfo_217, SIMD_KVSEUnpackInfo_218, SIMD_KVSEUnpackInfo_219,
	SIMD_KVSEUnpackInfo_220, SIMD_KVSEUnpackInfo_221, SIMD_KVSEUnpackInfo_222, SIMD_KVSEUnpackInfo_223,
	SIMD_KVSEUnpackInfo_224, SIMD_KVSEUnpackInfo_225, SIMD_KVSEUnpackInfo_226, SIMD_KVSEUnpackInfo_227,
	SIMD_KVSEUnpackInfo_228, SIMD_KVSEUnpackInfo_229, SIMD_KVSEUnpackInfo_230, SIMD_KVSEUnpackInfo_231,
	SIMD_KVSEUnpackInfo_232, SIMD_KVSEUnpackInfo_233, SIMD_KVSEUnpackInfo_234, SIMD_KVSEUnpackInfo_235,
	SIMD_KVSEUnpackInfo_236, SIMD_KVSEUnpackInfo_237, SIMD_KVSEUnpackInfo_238, SIMD_KVSEUnpackInfo_239,
	SIMD_KVSEUnpackInfo_240, SIMD_KVSEUnpackInfo_241, SIMD_KVSEUnpackInfo_242, SIMD_KVSEUnpackInfo_243,
	SIMD_KVSEUnpackInfo_244, SIMD_KVSEUnpackInfo_245, SIMD_KVSEUnpackInfo_246, SIMD_KVSEUnpackInfo_247,
	SIMD_KVSEUnpackInfo_248, SIMD_KVSEUnpackInfo_249, SIMD_KVSEUnpackInfo_250, SIMD_KVSEUnpackInfo_251,
	SIMD_KVSEUnpackInfo_252, SIMD_KVSEUnpackInfo_253, SIMD_KVSEUnpackInfo_254, SIMD_KVSEUnpackInfo_255,
	SIMD_KVSEUnpackInfo_256, SIMD_KVSEUnpackInfo_257, SIMD_KVSEUnpackInfo_258, SIMD_KVSEUnpackInfo_259,
	SIMD_KVSEUnpackInfo_260, SIMD_KVSEUnpackInfo_261, SIMD_KVSEUnpackInfo_262, SIMD_KVSEUnpackInfo_263,
	SIMD_KVSEUnpackInfo_264, SIMD_KVSEUnpackInfo_265, SIMD_KVSEUnpackInfo_266, SIMD_KVSEUnpackInfo_267,
	SIMD_KVSEUnpackInfo_268, SIMD_KVSEUnpackInfo_269, SIMD_KVSEUnpackInfo_270, SIMD_KVSEUnpackInfo_271,
	SIMD_KVSEUnpackInfo_272, SIMD_KVSEUnpackInfo_273, SIMD_KVSEUnpackInfo_274, SIMD_KVSEUnpackInfo_275,
	SIMD_KVSEUnpackInfo_276, SIMD_KVSEUnpackInfo_277, SIMD_KVSEUnpackInfo_278, SIMD_KVSEUnpackInfo_279,
	SIMD_KVSEUnpackInfo_280, SIMD_KVSEUnpackInfo_281, SIMD_KVSEUnpackInfo_282, SIMD_KVSEUnpackInfo_283,
	SIMD_KVSEUnpackInfo_284, SIMD_KVSEUnpackInfo_285, SIMD_KVSEUnpackInfo_286, SIMD_KVSEUnpackInfo_287,
	SIMD_KVSEUnpackInfo_288, SIMD_KVSEUnpackInfo_289, SIMD_KVSEUnpackInfo_290, SIMD_KVSEUnpackInfo_291,
	SIMD_KVSEUnpackInfo_292, SIMD_KVSEUnpackInfo_293, SIMD_KVSEUnpackInfo_294, SIMD_KVSEUnpackInfo_295,
	SIMD_KVSEUnpackInfo_296, SIMD_KVSEUnpackInfo_297, SIMD_KVSEUnpackInfo_298, SIMD_KVSEUnpackInfo_299,
	SIMD_KVSEUnpackInfo_300, SIMD_KVSEUnpackInfo_301, SIMD_KVSEUnpackInfo_302, SIMD_KVSEUnpackInfo_303,
	SIMD_KVSEUnpackInfo_304, SIMD_KVSEUnpackInfo_305, SIMD_KVSEUnpackInfo_306, SIMD_KVSEUnpackInfo_307,
	SIMD_KVSEUnpackInfo_308, SIMD_KVSEUnpackInfo_309, SIMD_KVSEUnpackInfo_310, SIMD_KVSEUnpackInfo_311,
	SIMD_KVSEUnpackInfo_312, SIMD_KVSEUnpackInfo_313, SIMD_KVSEUnpackInfo_314, SIMD_KVSEUnpackInfo_315,
	SIMD_KVSEUnpackInfo_316, SIMD_KVSEUnpackInfo_317, SIMD_KVSEUnpackInfo_318, SIMD_KVSEUnpackInfo_319,
	SIMD_KVSEUnpackInfo_320, SIMD_KVSEUnpackInfo_321, SIMD_KVSEUnpackInfo_322, SIMD_KVSEUnpackInfo_323,
	SIMD_KVSEUnpackInfo_324, SIMD_KVSEUnpackInfo_325, SIMD_KVSEUnpackInfo_326, SIMD_KVSEUnpackInfo_327,
	SIMD_KVSEUnpackInfo_328, SIMD_KVSEUnpackInfo_329, SIMD_KVSEUnpackInfo_330, SIMD_KVSEUnpackInfo_331,
	SIMD_KVSEUnpackInfo_332, SIMD_KVSEUnpackInfo_333, SIMD_KVSEUnpackInfo_334, SIMD_KVSEUnpackInfo_335,
	SIMD_KVSEUnpackInfo_336, SIMD_KVSEUnpackInfo_337, SIMD_KVSEUnpackInfo_338, SIMD_KVSEUnpackInfo_339,
	SIMD_KVSEUnpackInfo_340, SIMD_KVSEUnpackInfo_341, SIMD_KVSEUnpackInfo_342, SIMD_KVSEUnpackInfo_343,
	SIMD_KVSEUnpackInfo_344, SIMD_KVSEUnpackInfo_345, SIMD_KVSEUnpackInfo_346, SIMD_KVSEUnpackInfo_347,
	SIMD_KVSEUnpackInfo_348, SIMD_KVSEUnpackInfo_349, SIMD_KVSEUnpackInfo_350, SIMD_KVSEUnpackInfo_351,
	SIMD_KVSEUnpackInfo_352, SIMD_KVSEUnpackInfo_353, SIMD_KVSEUnpackInfo_354, SIMD_KVSEUnpackInfo_355,
	SIMD_KVSEUnpackInfo_356, SIMD_KVSEUnpackInfo_357, SIMD_KVSEUnpackInfo_358, SIMD_KVSEUnpackInfo_359,
	SIMD_KVSEUnpackInfo_360, SIMD_KVSEUnpackInfo_361, SIMD_KVSEUnpackInfo_362, SIMD_KVSEUnpackInfo_363,
	SIMD_KVSEUnpackInfo_364, SIMD_KVSEUnpackInfo_365, SIMD_KVSEUnpackInfo_366, SIMD_KVSEUnpackInfo_367,
	SIMD_KVSEUnpackInfo_368, SIMD_KVSEUnpackInfo_369, SIMD_KVSEUnpackInfo_370, SIMD_KVSEUnpackInfo_371,
	SIMD_KVSEUnpackInfo_372, SIMD_KVSEUnpackInfo_373, SIMD_KVSEUnpackInfo_374, SIMD_KVSEUnpackInfo_375,
	SIMD_KVSEUnpackInfo_376, SIMD_KVSEUnpackInfo_377, SIMD_KVSEUnpackInfo_378, SIMD_KVSEUnpackInfo_379,
	SIMD_KVSEUnpackInfo_380, SIMD_KVSEUnpackInfo_381, SIMD_KVSEUnpackInfo_382, SIMD_KVSEUnpackInfo_383,
	SIMD_KVSEUnpackInfo_384, SIMD_KVSEUnpackInfo_385, SIMD_KVSEUnpackInfo_386, SIMD_KVSEUnpackInfo_387,
	SIMD_KVSEUnpackInfo_388, SIMD_KVSEUnpackInfo_389, SIMD_KVSEUnpackInfo_390, SIMD_KVSEUnpackInfo_391,
	SIMD_KVSEUnpackInfo_392, SIMD_KVSEUnpackInfo_393, SIMD_KVSEUnpackInfo_394, SIMD_KVSEUnpackInfo_395,
	SIMD_KVSEUnpackInfo_396, SIMD_KVSEUnpackInfo_397, SIMD_KVSEUnpackInfo_398, SIMD_KVSEUnpackInfo_399,
	SIMD_KVSEUnpackInfo_400, SIMD_KVSEUnpackInfo_401, SIMD_KVSEUnpackInfo_402, SIMD_KVSEUnpackInfo_403,
	SIMD_KVSEUnpackInfo_404, SIMD_KVSEUnpackInfo_405, SIMD_KVSEUnpackInfo_406, SIMD_KVSEUnpackInfo_407,
	SIMD_KVSEUnpackInfo_408, SIMD_KVSEUnpackInfo_409, SIMD_KVSEUnpackInfo_410, SIMD_KVSEUnpackInfo_411,
	SIMD_KVSEUnpackInfo_412, SIMD_KVSEUnpackInfo_413, SIMD_KVSEUnpackInfo_414, SIMD_KVSEUnpackInfo_415,
	SIMD_KVSEUnpackInfo_416, SIMD_KVSEUnpackInfo_417, SIMD_KVSEUnpackInfo_418, SIMD_KVSEUnpackInfo_419,
	SIMD_KVSEUnpackInfo_420, SIMD_KVSEUnpackInfo_421, SIMD_KVSEUnpackInfo_422, SIMD_KVSEUnpackInfo_423,
	SIMD_KVSEUnpackInfo_424, SIMD_KVSEUnpackInfo_425, SIMD_KVSEUnpackInfo_426, SIMD_KVSEUnpackInfo_427,
	SIMD_KVSEUnpackInfo_428, SIMD_KVSEUnpackInfo_429, SIMD_KVSEUnpackInfo_430, SIMD_KVSEUnpackInfo_431,
	SIMD_KVSEUnpackInfo_432, SIMD_KVSEUnpackInfo_433, SIMD_KVSEUnpackInfo_434, SIMD_KVSEUnpackInfo_435,
	SIMD_KVSEUnpackInfo_436, SIMD_KVSEUnpackInfo_437, SIMD_KVSEUnpackInfo_438, SIMD_KVSEUnpackInfo_439,
	SIMD_KVSEUnpackInfo_440, SIMD_KVSEUnpackInfo_441, SIMD_KVSEUnpackInfo_442, SIMD_KVSEUnpackInfo_443,
	SIMD_KVSEUnpackInfo_444, SIMD_KVSEUnpackInfo_445, SIMD_KVSEUnpackInfo_446, SIMD_KVSEUnpackInfo_447,
	SIMD_KVSEUnpackInfo_448, SIMD_KVSEUnpackInfo_449, SIMD_KVSEUnpackInfo_450, SIMD_KVSEUnpackInfo_451,
	SIMD_KVSEUnpackInfo_452, SIMD_KVSEUnpackInfo_453, SIMD_KVSEUnpackInfo_454, SIMD_KVSEUnpackInfo_455,
	SIMD_KVSEUnpackInfo_456, SIMD_KVSEUnpackInfo_457, SIMD_KVSEUnpackInfo_458, SIMD_KVSEUnpackInfo_459,
	SIMD_KVSEUnpackInfo_460, SIMD_KVSEUnpackInfo_461, SIMD_KVSEUnpackInfo_462, SIMD_KVSEUnpackInfo_463,
	SIMD_KVSEUnpackInfo_464, SIMD_KVSEUnpackInfo_465, SIMD_KVSEUnpackInfo_466, SIMD_KVSEUnpackInfo_467,
	SIMD_KVSEUnpackInfo_468, SIMD_KVSEUnpackInfo_469, SIMD_KVSEUnpackInfo_470, SIMD_KVSEUnpackInfo_471,
	SIMD_KVSEUnpackInfo_472, SIMD_KVSEUnpackInfo_473, SIMD_KVSEUnpackInfo_474, SIMD_KVSEUnpackInfo_475,
	SIMD_KVSEUnpackInfo_476, SIMD_KVSEUnpackInfo_477, SIMD_KVSEUnpackInfo_478, SIMD_KVSEUnpackInfo_479,
	SIMD_KVSEUnpackInfo_480, SIMD_KVSEUnpackInfo_481, SIMD_KVSEUnpackInfo_482, SIMD_KVSEUnpackInfo_483,
	SIMD_KVSEUnpackInfo_484, SIMD_KVSEUnpackInfo_485, SIMD_KVSEUnpackInfo_486, SIMD_KVSEUnpackInfo_487,
	SIMD_KVSEUnpackInfo_488, SIMD_KVSEUnpackInfo_489, SIMD_KVSEUnpackInfo_490, SIMD_KVSEUnpackInfo_491,
	SIMD_KVSEUnpackInfo_492, SIMD_KVSEUnpackInfo_493, SIMD_KVSEUnpackInfo_494, SIMD_KVSEUnpackInfo_495,
	SIMD_KVSEUnpackInfo_496, SIMD_KVSEUnpackInfo_497, SIMD_KVSEUnpackInfo_498, SIMD_KVSEUnpackInfo_499,
	SIMD_KVSEUnpackInfo_500, SIMD_KVSEUnpackInfo_501, SIMD_KVSEUnpackInfo_502, SIMD_KVSEUnpackInfo_503,
	SIMD_KVSEUnpackInfo_504, SIMD_KVSEUnpackInfo_505, SIMD_KVSEUnpackInfo_506, SIMD_KVSEUnpackInfo_507,
	SIMD_KVSEUnpackInfo_508, SIMD_KVSEUnpackInfo_509, SIMD_KVSEUnpackInfo_510, SIMD_KVSEUnpackInfo_511,
};

}
}

#endif /* SIMD_KVSEncoding_UNPACK_HPP_ */

/*
 *
#include <iostream>
#include <sstream>
#include <string>
#include <stdint.h>

using namespace std;

#ifdef ARRAYSIZE
# undef ARRAYSIZE
#endif

#define ARRAYSIZE(__x__)  \
    (sizeof(__x__) / sizeof(*(__x__)))

#define DIV_ROUNDUP(__x__, __y__) \
    ((__x__ + __y__ - 1) / __y__)

const uint32_t VSESIMPLE_LENS[8] = { 1, 2, 4, 8, 12, 16, 32, 64};
const uint32_t VSESIMPLE_LOGS[16] = { 0, 1, 2, 3, 4, 5, 6,
		7, 8, 9, 10, 11, 12, 16, 20, 32 };

string TRIPLE_TAB = "\t\t\t";
string QUOTE_END_LINE = "\\n\"\n";
int BEG_REG_IDX = 3;

void GenCode(ostringstream &oss, ostringstream &infoOss) {
	//string IDX_STR = "i";

	for (int idx2=0; idx2<ARRAYSIZE(VSESIMPLE_LENS); idx2++) {
		int num = VSESIMPLE_LENS[idx2]; //num of integers
	for (int idx1=0; idx1<ARRAYSIZE(VSESIMPLE_LOGS); idx1++) {
		int i = VSESIMPLE_LOGS[idx1]; //bitwidth

		for (int k=0; k<4; k++) {	//ori byte offset
			oss << "template<typename T>" << endl;
			ostringstream nameOss;
			nameOss << "SIMD_KVSE_unpack_" << num << "len_" << i << "bw_" << (k*8) << "offset";
			oss << "void " << nameOss.str() <<  "(T * des, const uint32_t *src) {" << endl;
			int infoIdx = (idx2 << 6) + (idx1 << 2) + k;
			infoOss << "static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfo_" << infoIdx << " = { " << nameOss.str() << "<uint32_t>, ";

			if (i > 0)
				oss << "\t__asm__ volatile(\"prefetchnta %0\"::\"m\" (src[0]));\n";

			int offsetInWord = k << 3;
			int curWordIdx = 0;
			int j = 0;
			uint32_t mask  = (1LL << i) - 1;

			int asmBlockDstQuadWordCount = 4;

			int asmBlockIdx = 0;
			int asmBlockSrcQuadWordCount = 0;
			int curBlockSrcQuadWordIdx = 0;
			int curBlockDstQuadWordIdx = 0;

			string asmBlockEndInfo = "";

			int TMP_REG_IDX;

			while (j < num) {
				if (i == 0) {
					oss << "\tZMEMCPY128(des";
					if (j > 0)
						oss << " + " << 4 * j;
					oss << ");" << endl;
					j++;
					continue;
				}

				if (j % asmBlockDstQuadWordCount == 0) {
					// open an asm block
					asmBlockSrcQuadWordCount = ((offsetInWord + i * 4 + 31) / 32);
					TMP_REG_IDX = BEG_REG_IDX + asmBlockSrcQuadWordCount;
					curBlockSrcQuadWordIdx = 0;
					curBlockDstQuadWordIdx = 0;
					oss << "\t__asm__(\n";

					// load all quadword acquired by asmBlock from mem into xmm
					for (int t=0; t<asmBlockSrcQuadWordCount; ++t) {
						oss << TRIPLE_TAB << "\"movdqu %" << (asmBlockDstQuadWordCount + t)
						<< ",%%xmm" << (BEG_REG_IDX+t) << QUOTE_END_LINE;
					}
					ostringstream tmp3;
					tmp3 << TRIPLE_TAB << ":";
					for (int t=0; t<asmBlockDstQuadWordCount; ++t) {
						tmp3 << "\"=m\"(des[" << (4 * (j + t)) << "])";
						if (t < asmBlockDstQuadWordCount-1)
							tmp3 << ", ";
						else
							tmp3 << "\n";
					}

					tmp3 << TRIPLE_TAB << ":";
					for (int t=0; t<asmBlockSrcQuadWordCount; ++t) {
						tmp3 << "\"m\"(src[" << 4 * (curWordIdx + t) << "])";
						if (t < asmBlockSrcQuadWordCount-1)
							tmp3 << ", ";
						else
							tmp3 << "\n";
					}
					tmp3 << TRIPLE_TAB << ":\"memory\");\n";
					asmBlockEndInfo = tmp3.str();
				}

				ostringstream tmp1;
				tmp1 << TRIPLE_TAB << "\"movdqa %%xmm" << (BEG_REG_IDX + curBlockSrcQuadWordIdx) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
				if (offsetInWord > 0) {
					tmp1 << TRIPLE_TAB << "\"psrld $" << offsetInWord << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
				}

				oss << tmp1.str();

				if (offsetInWord + i > 32) {
					ostringstream tmp2;
					tmp2 << TRIPLE_TAB << "\"movdqa %%xmm" << (BEG_REG_IDX + curBlockSrcQuadWordIdx + 1) << ",%%xmm" << (TMP_REG_IDX + 1) << QUOTE_END_LINE;
					tmp2 << TRIPLE_TAB << "\"pslld $" << (32 - offsetInWord) << ",%%xmm" << (TMP_REG_IDX + 1) << QUOTE_END_LINE;
					tmp2 << TRIPLE_TAB << "\"por %%xmm" << (TMP_REG_IDX + 1) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
                        		oss << tmp2.str();
				}

				if (i < 32) {
					oss << TRIPLE_TAB << "\"pslld $" << (32 - i) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
					oss << TRIPLE_TAB << "\"psrld $" << (32 - i) << ",%%xmm" << (TMP_REG_IDX) << QUOTE_END_LINE;
				}
				oss << TRIPLE_TAB << "\"movdqu %%xmm" << (TMP_REG_IDX) << ",%" << curBlockDstQuadWordIdx << QUOTE_END_LINE;

				curBlockDstQuadWordIdx ++;
				curWordIdx += (offsetInWord + i) / 32;
				curBlockSrcQuadWordIdx += (offsetInWord + i) / 32;
				offsetInWord = (offsetInWord + i) % 32;
				j++;

				if (j == num || j % asmBlockDstQuadWordCount == 0) {
					oss << asmBlockEndInfo;
				}
			}
			oss << "}" << endl;
			oss << endl;

			// aligned newOffset and workskipped by byte
			offsetInWord = 8 * DIV_ROUNDUP(offsetInWord, 8);
			curWordIdx += offsetInWord / 32;
			offsetInWord = offsetInWord % 32;

			infoOss << (k << 3) << ", "	//begOffset
				<< (offsetInWord) << ", "	//newOffset
				<< (curWordIdx << 2) << ", "	//wordskipped
				<< (num << 2) << ", "		//integer decoded
				<< "};" << endl;
		}
	}
	}
}

string printInfoArr(int arrNum) {
	ostringstream oss;
	oss << "static SIMD_KVSEUnpackInfo SIMD_KVSEUnpackInfoArr[" << arrNum << "] = {" << endl;
	for (int i=0; i<arrNum; ++i) {
		if (i % 4 == 0)
			oss << "\t";
		oss << "SIMD_KVSEUnpackInfo_" << i << ", ";
		if (i % 4 == 3)
			oss << endl;
	}
	oss << "};" << endl;
	return oss.str();
}


int main() {
	ostringstream oss, infoOss;
	GenCode(oss, infoOss);

	cout << oss.str();
	cout << endl;
	cout << infoOss.str();
	cout << endl;
	cout << printInfoArr(4 * ARRAYSIZE(VSESIMPLE_LENS) * ARRAYSIZE(VSESIMPLE_LOGS));

	return 0;
}
 *
 */

